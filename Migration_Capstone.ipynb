{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J-Nobull/ANNvsCNN/blob/main/Migration_Capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Capstone Research Project on Migration Within the USA"
      ],
      "metadata": {
        "id": "73b5grE-eCpw"
      },
      "id": "73b5grE-eCpw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d793bbe-9ae4-493e-87a9-cd3613a55070",
      "metadata": {
        "scrolled": true,
        "id": "0d793bbe-9ae4-493e-87a9-cd3613a55070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94155635-3230-445f-e62b-905cd9442a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting census\n",
            "  Downloading census-0.8.24-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: requests>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from census) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1.1.0->census) (2025.11.12)\n",
            "Downloading census-0.8.24-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: census\n",
            "Successfully installed census-0.8.24\n",
            "\n",
            "Environment Ready\n"
          ]
        }
      ],
      "source": [
        "# Setup initial environment\n",
        "!pip install census\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "from io import BytesIO\n",
        "from census import Census\n",
        "\n",
        "print('\\nEnvironment Ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Keys\n",
        "(KEY SECRETS NOT SET UP YET, USER MUST GET THEIR OWN KEY AND REPLACE Key-Here)"
      ],
      "metadata": {
        "id": "WDpra_RieDSa"
      },
      "id": "WDpra_RieDSa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get API keys:  \n",
        "https://apps.bea.gov/API/signup/  \n",
        "https://data.bls.gov/registrationEngine/  \n",
        "https://api.census.gov/data/key_signup.html"
      ],
      "metadata": {
        "id": "t1GjV13ndXCL"
      },
      "id": "t1GjV13ndXCL"
    },
    {
      "cell_type": "code",
      "source": [
        "# from getpass import getpass\n",
        "'''\n",
        "def get_api_key(name):\n",
        "    key = os.getenv(name)\n",
        "    if not key:\n",
        "        key = getpass(f\"Enter {name} (hidden input): \")\n",
        "    return key\n",
        "\n",
        "API_KEY_BEA = get_api_key('API_KEY_BEA')\n",
        "API_KEY_BLS = get_api_key('API_KEY_BLS')\n",
        "API_KEY_CENSUS = get_api_key('API_KEY_CENSUS')\n",
        "\n",
        "print('API keys loaded')\n",
        "'''"
      ],
      "metadata": {
        "id": "DUZzBQeZ_joV"
      },
      "id": "DUZzBQeZ_joV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Helper function to create FIPS  \n",
        "(common key to merge all datasets)"
      ],
      "metadata": {
        "id": "V8lro_DiDKVe"
      },
      "id": "V8lro_DiDKVe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create 5-digit FIPS codes\n",
        "def create_fips(state_fips_series, county_fips_series):\n",
        "    return state_fips_series.astype(str).str.zfill(2) + \\\n",
        "           county_fips_series.astype(str).str.zfill(3)"
      ],
      "metadata": {
        "id": "4aLqRe_bDQNq"
      },
      "id": "4aLqRe_bDQNq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import all datasets"
      ],
      "metadata": {
        "id": "UrYMnDvnd_UE"
      },
      "id": "UrYMnDvnd_UE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Import from Bureau of Economic Analysis (1 of 8)  \n",
        "The following constant variables will be dropped from the respective files:  \n",
        "PARPP-3: 'CL_UNIT' & 'UNIT_MULT'  \n",
        "MARPP-3: 'CL_UNIT' & 'UNIT_MULT'  \n",
        "CAINC1-3: 'CL_UNIT': 'Dollars', 'UNIT_MULT' & 'NoteRef'; as well as  'GeoName'  \n",
        "CAGDP1-1: 'CL_UNIT': 'Thousands of chained 2017 dollars' & 'UNIT_MULT'; as well as 'GeoName'"
      ],
      "metadata": {
        "id": "i8WVJ2GtW3pb"
      },
      "id": "i8WVJ2GtW3pb"
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY_BEA = 'Key-Here'\n",
        "BEA_URL = 'https://apps.bea.gov/api/data'\n",
        "YEARS = list(range(2011, 2022))\n",
        "\n",
        "# Define Tables with LineCodes and GeoFips\n",
        "TABLES = [\n",
        "    {'name': 'PARPP', 'linecode': '3', # Cost of living for Metro/Non-metro\n",
        "     'geofips': 'PORT', 'desc': 'RPP_portion', 'filename': 'BEA_rpp_p.csv'},\n",
        "    {'name': 'MARPP', 'linecode': '3', # Cost of living for Urban areas (MSAs)\n",
        "     'geofips': 'MSA', 'desc': 'RPP_msa', 'filename': 'BEA_rpp_m.csv'},\n",
        "    {'name': 'CAINC1', 'linecode': '3', # County Per Capita Income (PCI)\n",
        "     'geofips': 'COUNTY', 'desc': 'BEA_pci', 'filename': 'BEA_PCI.csv'},\n",
        "    {'name': 'CAGDP1', 'linecode': '1', # County Gross Domestic Product (GDP)\n",
        "     'geofips': 'COUNTY', 'desc': 'BEA_gdp', 'filename': 'BEA_GDP.csv'}]\n",
        "\n",
        "# Fetch tables\n",
        "print('Downloading BEA data (2011-2021)...')\n",
        "\n",
        "for table in TABLES:\n",
        "\n",
        "    print(f\"\\nFetching {table['desc']} ({table['name']})...\")\n",
        "\n",
        "    params = {\n",
        "        'UserID': API_KEY_BEA,\n",
        "        'method': 'GetData',\n",
        "        'datasetname': 'Regional',\n",
        "        'TableName': table['name'],\n",
        "        'LineCode': table['linecode'],\n",
        "        'Year': YEARS,\n",
        "        'GeoFips': table['geofips'],\n",
        "        'ResultFormat': 'json'}\n",
        "\n",
        "    response = requests.get(BEA_URL, params=params, timeout=120)\n",
        "    data = response.json()\n",
        "\n",
        "# Show errors\n",
        "    if 'Error' in data.get('BEAAPI', {}):\n",
        "        print(f\" ❌ Error: {data['BEAAPI']['Error']['Detail']}\")\n",
        "        continue\n",
        "\n",
        "    df = pd.DataFrame(data['BEAAPI']['Results']['Data'])\n",
        "\n",
        "# Initialize rename_map dynamically based on available columns\n",
        "    rename_map = {}\n",
        "\n",
        "# Rename 'TimePeriod' to 'YEAR'\n",
        "    if 'TimePeriod' in df.columns: rename_map['TimePeriod'] = 'YEAR'\n",
        "\n",
        "# Rename 'DataValue' to table['desc']\n",
        "    if 'DataValue' in df.columns: rename_map['DataValue'] = table['desc']\n",
        "    else:\n",
        "# If 'DataValue' not present, manually create column with NaNs\n",
        "        print(f\"  Warning: 'DataValue' column missing for {table['name']}. Creating '{table['desc']}' with NaN.\")\n",
        "        df[table['desc']] = np.nan\n",
        "\n",
        "# Conditionally rename 'GeoFips'\n",
        "    if 'GeoFips' in df.columns:\n",
        "        if table['name'] in ['CAINC1', 'CAGDP1']:\n",
        "            rename_map['GeoFips'] = 'FIPS'\n",
        "        else: # For PARPP and MARPP\n",
        "            rename_map['GeoFips'] = 'GeoFIPS' # lowercase to uppercase\n",
        "\n",
        "# Apply renaming\n",
        "    df = df.rename(columns=rename_map)\n",
        "\n",
        "# After renaming, this handles errors.\n",
        "    if 'YEAR' not in df.columns:\n",
        "        df['YEAR'] = np.nan\n",
        "        print(f\"  Warning: 'TimePeriod' or 'YEAR' column not found in {table['name']}. 'YEAR' created with NaN.\")\n",
        "    df['YEAR'] = pd.to_numeric(df['YEAR'], errors='coerce')\n",
        "\n",
        "# Convert the 'desc' column to numeric\n",
        "    if table['desc'] in df.columns:\n",
        "        df[table['desc']] = pd.to_numeric(df[table['desc']], errors='coerce')\n",
        "\n",
        "# Keep 'GeoName' and other variables based on table type\n",
        "    if table['name'] in ['PARPP', 'MARPP']:\n",
        "# Ensure 'GeoName' is present before trying to select it\n",
        "        cols_to_keep = ['GeoFIPS', 'YEAR', table['desc']]\n",
        "        if 'GeoName' in df.columns:\n",
        "            cols_to_keep.insert(1, 'GeoName') # Insert GeoName after GeoFips\n",
        "        df = df[cols_to_keep]\n",
        "    else: # For CAINC1 and CAGDP1\n",
        "        # Ensure 'FIPS' column exists after renaming\n",
        "        fips_col = 'FIPS'\n",
        "        if fips_col not in df.columns:\n",
        "            print(f\"  Warning: '{fips_col}' column not found after renaming for {table['name']}. Skipping selection.\")\n",
        "            continue # Skip saving if critical column is missing\n",
        "        df = df[[fips_col, 'YEAR', table['desc']]]\n",
        "\n",
        "# Save to CSV\n",
        "    df.to_csv(table['filename'], index=False)\n",
        "\n",
        "    print(f\"   Saved {len(df):,} rows to {table['filename']}\")\n",
        "# Add check to confirm file existence immediately after saving\n",
        "    if os.path.exists(table['filename']):\n",
        "        print(f\"    (Confirmed: {table['filename']} exists on disk)\")\n",
        "    else:\n",
        "        print(f\"    (ERROR: {table['filename']} NOT found on disk after saving!)\")\n",
        "    print(df.head())\n",
        "    time.sleep(2)\n",
        "\n",
        "print('\\n' + '='*30)\n",
        "print('BEA IMPORT COMPLETE')\n",
        "print('='*30)\n",
        "print('Files created:')\n",
        "for table in TABLES:\n",
        "    print(f\"  - {table['filename']}\")"
      ],
      "metadata": {
        "id": "KNrnDHAoLZDG"
      },
      "id": "KNrnDHAoLZDG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join BEA_PCI and BEA_GDP on FIPS and Year\n",
        "BEA_PCI = pd.read_csv('BEA_PCI.csv')\n",
        "BEA_PCI['FIPS'] = BEA_PCI['FIPS'].astype(str).str.zfill(5)\n",
        "BEA_GDP = pd.read_csv('BEA_GDP.csv')\n",
        "BEA_GDP['FIPS'] = BEA_GDP['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "BEA_join1 = pd.merge(BEA_PCI, BEA_GDP, on=['FIPS', 'YEAR'], how='inner')\n",
        "\n",
        "# Create state variable from first 2 digits of FIPS\n",
        "BEA_join1['STATE'] = BEA_join1[\n",
        "    'FIPS'].str[:2].fillna(0).astype(int).astype(str).str.zfill(2)\n",
        "\n",
        "# Display\n",
        "print(BEA_join1.head())"
      ],
      "metadata": {
        "id": "HkEywl_VS-bY"
      },
      "id": "HkEywl_VS-bY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CBSA delineation file to convert RPP_MSA to FIPS-State 2-digit\n",
        "url = 'https://www2.census.gov/programs-surveys/metro-micro/geographies/reference-files/2013/delineation-files/list1.xls'\n",
        "\n",
        "# CBSA file will be used to convert MSA into 5-digit FIPS\n",
        "print(\"Downloading Feb 2013 CBSA delineation file...\")\n",
        "response = requests.get(url)\n",
        "cbsa_file = pd.read_excel(BytesIO(response.content), skiprows=2)\n",
        "\n",
        "print(f\"Loaded {len(cbsa_file):,} records from delineation file\")\n",
        "\n",
        "# Create 5-digit FIPS\n",
        "cbsa_file['FIPS'] = create_fips(\n",
        "    cbsa_file['FIPS State Code'].fillna(0).astype(int),\n",
        "    cbsa_file['FIPS County Code'].fillna(0).astype(int))\n",
        "\n",
        "cbsa_file.rename(columns={\n",
        "    'CBSA Code': 'CBSA_code',\n",
        "    'FIPS State Code': 'STATE'}, inplace=True)\n",
        "cbsa_file['STATE'] = cbsa_file['STATE'].fillna(0).astype(int).astype(str).str.zfill(2)\n",
        "\n",
        "BEA_rpp_m = pd.read_csv('BEA_rpp_m.csv')\n",
        "BEA_rpp_m['GeoFIPS'] = BEA_rpp_m['GeoFIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "print(f\"\\nLoaded BEA file with {len(BEA_rpp_m):,} rows\")\n",
        "print(f\"BEA GeoFIPS dtype: {BEA_rpp_m['GeoFIPS'].dtype}\")\n",
        "print(f\"Crosswalk CBSA_code dtype: {cbsa_file['CBSA_code'].dtype}\")\n",
        "\n",
        "# Merge\n",
        "df_merged = BEA_rpp_m.merge(cbsa_file, left_on='GeoFIPS', right_on='CBSA_code', how='left')\n",
        "\n",
        "# Select final columns\n",
        "BEA_join2 = df_merged[['FIPS', 'YEAR', 'RPP_msa', 'STATE']]\n",
        "\n",
        "# Display\n",
        "print(BEA_join2.head())"
      ],
      "metadata": {
        "id": "Y-Z26Gs1vMNc"
      },
      "id": "Y-Z26Gs1vMNc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 22 clears unneeded columns.  \n",
        "To visually verify full.merge and .fillna completed cleanly, create docstring: delete # on lines 21 & 23."
      ],
      "metadata": {
        "id": "kznxRdgE0gzF"
      },
      "id": "kznxRdgE0gzF"
    },
    {
      "cell_type": "code",
      "source": [
        "BEA_rpp_p = pd.read_csv('BEA_rpp_p.csv', dtype={'GeoFIPS': str})\n",
        "# Create state variable from first 2 digits of FIPS\n",
        "BEA_rpp_p['FIPS'] = BEA_rpp_p['GeoFIPS'].astype(str)\n",
        "BEA_rpp_p['STATE'] = BEA_rpp_p['FIPS'].str[:2]\n",
        "BEA_rpp_p = BEA_rpp_p[BEA_rpp_p['FIPS'].str.endswith('999')].copy()\n",
        "\n",
        "# Merge BEA_join1 (PCI + GDP) with BEA_join2 (MSA/metro RPP)\n",
        "BEA_full = BEA_join1.merge(BEA_join2[['FIPS', 'YEAR', 'RPP_msa']],\n",
        "                            on=['FIPS', 'YEAR'],\n",
        "                            how='left')\n",
        "\n",
        "# Merge state-level RPP for filling NaN values\n",
        "BEA_import = BEA_full.merge(BEA_rpp_p[['STATE', 'YEAR', 'RPP_portion']],\n",
        "                          on=['STATE', 'YEAR'],\n",
        "                          how='left')\n",
        "\n",
        "# Fill null RPP values with RPP_portion\n",
        "BEA_import['RPP'] = BEA_import['RPP_msa'].fillna(BEA_import['RPP_portion'])\n",
        "\n",
        "# Drop the unneeded columns\n",
        "# '''\n",
        "BEA_import.drop(columns=['RPP_msa', 'RPP_portion', 'STATE'], inplace=True)\n",
        "# '''\n",
        "print(f\"BEA_import complete with {len(BEA_import):,} rows\")\n",
        "print(f\"RPP values filled: {BEA_import['RPP'].notna().sum():,}\")\n",
        "\n",
        "BEA_import.to_csv('BEA_import.csv', index=False)\n",
        "\n",
        "# Display\n",
        "print(BEA_import.head(35))"
      ],
      "metadata": {
        "id": "bJsQSneQkB4d"
      },
      "id": "bJsQSneQkB4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import from Census Bureau (2 of 8)  \n",
        "import selected variables from Census \"Detailed Tables\""
      ],
      "metadata": {
        "id": "O8D2xIYykGkx"
      },
      "id": "O8D2xIYykGkx"
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY_CENSUS = 'Key-Here'\n",
        "CENSUS_URL = 'https://api.census.gov/data'\n",
        "YEARS = list(range(2011, 2022))\n",
        "\n",
        "# ACS variable definitions\n",
        "ACS_VARS = {\n",
        "# Population\n",
        "    'B01003_001E': 'total_population',\n",
        "# Age\n",
        "    'B01002_001E': 'median_age',\n",
        "# Housing\n",
        "    'B25003_001E': 'housing_total',\n",
        "    'B25003_002E': 'owner_occupied',\n",
        "    'B25003_003E': 'renter_occupied',\n",
        "    'B25002_003E': 'vacant',\n",
        "    'B25077_001E': 'median_home_value',\n",
        "# Households\n",
        "    'B11001_002E': 'family_households',\n",
        "# Marital Status\n",
        "    'B12001_001E': 'marital_total',\n",
        "    'B12001_003E': 'never_married_male',\n",
        "    'B12001_004E': 'now_married_male',\n",
        "    'B12001_010E': 'divorced_male',\n",
        "    'B12001_009E': 'widowed_male',\n",
        "    'B12001_012E': 'never_married_female',\n",
        "    'B12001_013E': 'now_married_female',\n",
        "    'B12001_018E': 'widowed_female',\n",
        "    'B12001_019E': 'divorced_female',\n",
        "# Children (all under 18)\n",
        "    'B09001_002E': 'under_18_in_hh',\n",
        "# Race/Ethnicity (sums to total)\n",
        "    'B03002_003E': 'white',\n",
        "    'B03002_004E': 'black',\n",
        "    'B03002_005E': 'native',\n",
        "    'B03002_006E': 'asian',\n",
        "    'B03002_007E': 'pacific_islander',\n",
        "    'B03002_008E': 'other_race',\n",
        "    'B03002_009E': 'mixed_non_h',\n",
        "    'B03002_012E': 'hispanic',\n",
        "# Education\n",
        "    'B15002_001E': 'education_total_sex',\n",
        "    'B15002_011E': 'male_complete_hs',\n",
        "    'B15002_012E': 'male_some_college<1',\n",
        "    'B15002_013E': 'male_some_college>1',\n",
        "    'B15002_014E': 'male_associates',\n",
        "    'B15002_015E': 'male_bachelors',\n",
        "    'B15002_016E': 'male_masters',\n",
        "    'B15002_017E': 'male_professional',\n",
        "    'B15002_018E': 'male_doctorate',\n",
        "    'B15002_028E': 'female_complete_hs',\n",
        "    'B15002_029E': 'female_some_college<1',\n",
        "    'B15002_030E': 'female_some_college>1',\n",
        "    'B15002_031E': 'female_associates',\n",
        "    'B15002_032E': 'female_bachelors',\n",
        "    'B15002_033E': 'female_masters',\n",
        "    'B15002_034E': 'female_professional',\n",
        "    'B15002_035E': 'female_doctorate',\n",
        "# Income\n",
        "    'B19013_001E': 'median_hh_income',\n",
        "# Employment\n",
        "    'B23025_004E': 'employed',\n",
        "    'B23025_005E': 'unemployed',\n",
        "    'B23025_007E': 'not_in_labor_force',\n",
        "# Commute Time\n",
        "    'B08303_002E': 'commute_less_5min',\n",
        "    'B08303_003E': 'commute_5_9min',\n",
        "    'B08303_004E': 'commute_10_14min',\n",
        "    'B08303_005E': 'commute_15_19min',\n",
        "    'B08303_006E': 'commute_20_24min',\n",
        "    'B08303_007E': 'commute_25_29min',\n",
        "    'B08303_008E': 'commute_30_34min',\n",
        "    'B08303_009E': 'commute_35_39min',\n",
        "    'B08303_010E': 'commute_40_44min',\n",
        "    'B08303_011E': 'commute_45_59min',\n",
        "    'B08303_012E': 'commute_60_89min',\n",
        "    'B08303_013E': 'commute_90_plus_min',\n",
        "# Worked from home\n",
        "    'B08137_020E': 'work_in_owned_home',\n",
        "    'B08137_021E': 'work_in_rental',\n",
        "# Estate taxes paid\n",
        "    'B25103_001E': 'median_property_taxes',\n",
        "# Industry\n",
        "    'C24060_001E': 'occupation_total',\n",
        "    'C24060_002E': 'Mgmt_Biz_Sci_Arts',\n",
        "    'C24060_003E': 'Services',\n",
        "    'C24060_004E': 'Sales_Admin',\n",
        "    'C24060_005E': 'Nat-rsrc_Constr_Maint',\n",
        "    'C24060_006E': 'Prod_Transp_Mvng'}\n",
        "\n",
        "def fetch_census_batch(year, variables):\n",
        "    # Fetch one batch of Census variables for all counties.\n",
        "    var_list = ','.join(variables)\n",
        "    params = {\n",
        "        'get': var_list,\n",
        "        'for': 'county:*',\n",
        "        'key': API_KEY_CENSUS}\n",
        "\n",
        "    url = f'{CENSUS_URL}/{year}/acs/acs5'\n",
        "    response = requests.get(url, params=params, timeout=120)\n",
        "\n",
        "    # Check for HTTP errors first\n",
        "    if response.status_code != 200:\n",
        "        print(f\"❌ HTTP Error for {year}: Status Code {response.status_code}\")\n",
        "        print(f\"Response content: {response.text}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        data = response.json()\n",
        "    except requests.exceptions.JSONDecodeError:\n",
        "        print(f\"❌JSON Decode Error in {year}: Could not parse response as JSON\")\n",
        "        print(f\"Response content: {response.text}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Show errors based on parsed JSON (if any)\n",
        "    if 'error' in data or len(data) <= 1:\n",
        "        print(f\"❌ Error: No data returned or API error for {year}\")\n",
        "        if 'error' in data:\n",
        "            print(f\"API error details: {data['error']}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    df = pd.DataFrame(data[1:], columns=data[0])\n",
        "    return df\n",
        "\n",
        "# Fetch data\n",
        "print('Downloading Census data (2011-2021)...\\n')\n",
        "\n",
        "all_years = []\n",
        "all_vars = list(ACS_VARS.keys())\n",
        "batch1 = all_vars[:45]  # Census API limit is 50 variables\n",
        "batch2 = all_vars[45:]\n",
        "\n",
        "for year in YEARS:\n",
        "    print(f\"Fetching year {year}...\")\n",
        "\n",
        "    # Fetch both batches\n",
        "    df1 = fetch_census_batch(year, batch1)\n",
        "    df2 = fetch_census_batch(year, batch2)\n",
        "\n",
        "    if df1.empty:\n",
        "        continue\n",
        "\n",
        "    # Merge batches on state and county\n",
        "    if not df2.empty:\n",
        "        year_df = pd.merge(df1, df2, on=['state', 'county'], how='outer')\n",
        "    else:\n",
        "        year_df = df1\n",
        "\n",
        "    # Rename variables\n",
        "    year_df = year_df.rename(columns=ACS_VARS)\n",
        "\n",
        "    # Create FIPS\n",
        "    year_df['FIPS'] = create_fips(year_df['state'], year_df['county'])\n",
        "    year_df['YEAR'] = year\n",
        "\n",
        "    # Convert to numeric\n",
        "    for col in ACS_VARS.values():\n",
        "        if col in year_df.columns:\n",
        "            year_df[col] = pd.to_numeric(year_df[col], errors='coerce')\n",
        "\n",
        "    all_years.append(year_df)\n",
        "    print(f\"Saved {len(year_df):,} rows\")\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Combine all years\n",
        "if all_years:\n",
        "    CEN_df = pd.concat(all_years, ignore_index=True)\n",
        "\n",
        "    # Keep only needed columns\n",
        "    keep_cols = ['FIPS', 'YEAR'] + [col for col in ACS_VARS.values()\n",
        "                                     if col in CEN_df.columns]\n",
        "    CEN_df = CEN_df[keep_cols]\n",
        "\n",
        "    # Save to CSV\n",
        "    CEN_df.to_csv('Census_import.csv', index=False)\n",
        "\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 30)\n",
        "    print('CENSUS IMPORT COMPLETE')\n",
        "    print(\"\\n\" + \"=\" * 30)\n",
        "    print(f\"\\n --Saved {len(CEN_df):,} rows\")\n",
        "    print(f\"   Counties: {CEN_df['FIPS'].nunique()}\")\n",
        "    print(f\"   Years: {CEN_df['YEAR'].min()}-{CEN_df['YEAR'].max()}\")\n",
        "    print(f\"   Variables: {len(ACS_VARS)}\")\n",
        "else:\n",
        "    print('\\n❌ Error: No data was downloaded')"
      ],
      "metadata": {
        "id": "tJUfSZ66R--x"
      },
      "id": "tJUfSZ66R--x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import from Bureau of Labor Statistics (3 of 8)  \n",
        "only import 'unemployment rate'"
      ],
      "metadata": {
        "id": "j8-56UJUAtHr"
      },
      "id": "j8-56UJUAtHr"
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY_BLS = 'Key-Here'\n",
        "BLS_URL = 'https://api.bls.gov/publicAPI/v2/timeseries/data/'\n",
        "YEARS = list(range(2011, 2022))\n",
        "\n",
        "print('Building BLS series IDs from Census FIPS codes...\\n')\n",
        "\n",
        "# Get FIPS from Census data, ensure FIPS is string and zero-filled\n",
        "census_df = pd.read_csv('Census_import.csv', dtype={'FIPS': str})\n",
        "census_df['FIPS'] = census_df['FIPS'].str.zfill(5)\n",
        "unique_fips = sorted(census_df['FIPS'].unique())\n",
        "\n",
        "# Build series IDs for matching counties\n",
        "all_series = [f'LAUCN{fips}0000000003' for fips in unique_fips]\n",
        "\n",
        "print(f'Found {len(all_series):,} counties from Census data')\n",
        "print(f'Will require {(len(all_series) + 49) // 50} batches\\n')\n",
        "\n",
        "# Download in batches of 50\n",
        "batch_size = 50\n",
        "all_data = []\n",
        "\n",
        "print('Downloading BLS unemployment rate data (2011-2021)...\\n')\n",
        "\n",
        "for i in range(0, len(all_series), batch_size):\n",
        "    batch = all_series[i:i+batch_size]\n",
        "    batch_num = i // batch_size + 1\n",
        "    total_batches = (len(all_series) + 49) // 50\n",
        "\n",
        "    payload = {\n",
        "        'seriesid': batch,\n",
        "        'startyear': '2011',\n",
        "        'endyear': '2021',\n",
        "        'registrationkey': API_KEY_BLS,\n",
        "        'annualaverage': True}\n",
        "\n",
        "    response = requests.post(BLS_URL, json=payload, timeout=120)\n",
        "    data = response.json()\n",
        "\n",
        "# Check for errors\n",
        "    if data.get('status') != 'REQUEST_SUCCEEDED':\n",
        "        print(f'❌ Batch {batch_num}/{total_batches} error: {data.get(\"message\", \"Unknown\")}')\n",
        "        continue\n",
        "\n",
        "# Parse response\n",
        "    for series in data['Results']['series']:\n",
        "        series_id = series['seriesID']\n",
        "        fips = series_id[5:10]  # Extract FIPS\n",
        "\n",
        "        for item in series['data']:\n",
        "            if item['period'] == 'M13':  # Average unemployment rate for year\n",
        "                value = item['value']\n",
        "\n",
        "                # Handle missing data (represented as '-')\n",
        "                if value == '-':\n",
        "                    unemployment_rate = None\n",
        "                else:\n",
        "                    unemployment_rate = float(value)\n",
        "\n",
        "                all_data.append({\n",
        "                    'FIPS': fips,\n",
        "                    'YEAR': int(item['year']),\n",
        "                    'unemploy_rate': unemployment_rate})\n",
        "\n",
        "    print(f'  Batch {batch_num}/{total_batches}')\n",
        "    time.sleep(2)\n",
        "\n",
        "# Save to CSV\n",
        "if all_data:\n",
        "    BLS_import = pd.DataFrame(all_data)\n",
        "    BLS_import.to_csv('BLS_import.csv', index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 30)\n",
        "    print('BLS IMPORT COMPLETE')\n",
        "    print(\"=\" * 30)\n",
        "    print(f'\\n Saved {len(BLS_import):,} rows')\n",
        "    print(f'  Counties: {BLS_import[\"FIPS\"].nunique()}')\n",
        "    print(f'  YEARS: {BLS_import[\"YEAR\"].min()}-{BLS_import[\"YEAR\"].max()}')\n",
        "    print(f'  Missing values: {BLS_import[\"unemploy_rate\"].isna().sum()}')\n",
        "else:\n",
        "    print('\\n❌ Error: No data downloaded')\n",
        "\n",
        "# Display\n",
        "print(BLS_import.head(25))"
      ],
      "metadata": {
        "id": "qZ6kvSELDe4j"
      },
      "id": "qZ6kvSELDe4j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data from IRS (4 of 8)  \n",
        "download 11 State-to-state inflow files for 2011-2021 at:  \n",
        "https://www.irs.gov/statistics/soi-tax-stats-migration-data  \n",
        "IRS n2=number of exemptions, labeling that variable n_movers,  \n",
        "assumes numbers of people that moved attached to one tax return (n1)."
      ],
      "metadata": {
        "id": "De2cLDxBbYMJ"
      },
      "id": "De2cLDxBbYMJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the years and file paths\n",
        "years = list(range(2011, 2022))\n",
        "year_mapping = {\n",
        "    2011: 'countyinflow1112.csv',\n",
        "    2012: 'countyinflow1213.csv',\n",
        "    2013: 'countyinflow1314.csv',\n",
        "    2014: 'countyinflow1415.csv',\n",
        "    2015: 'countyinflow1516.csv',\n",
        "    2016: 'countyinflow1617.csv',\n",
        "    2017: 'countyinflow1718.csv',\n",
        "    2018: 'countyinflow1819.csv',\n",
        "    2019: 'countyinflow1920.csv',\n",
        "    2020: 'countyinflow2021.csv',\n",
        "    2021: 'countyinflow2122.csv'}\n",
        "\n",
        "print(\"Starting IRS Migration Data Import...\")\n",
        "\n",
        "all_data = []\n",
        "\n",
        "for year, filepath in year_mapping.items():\n",
        "    print(f\"Processing {year}...\")\n",
        "\n",
        "    IRS_df = pd.read_csv(filepath, encoding='latin-1')\n",
        "    IRS_df['YEAR'] = year\n",
        "\n",
        "    IRS_df['out_FIPS'] = create_fips(IRS_df['y1_statefips'], IRS_df['y1_countyfips'])\n",
        "    IRS_df['in_FIPS'] = create_fips(IRS_df['y2_statefips'], IRS_df['y2_countyfips'])\n",
        "# Rename n2 = Number of Exemptions on that calendar years' returns\n",
        "    IRS_df = IRS_df.rename(columns={'n2': 'Movers'})\n",
        "    IRS_df.replace(-1, np.nan, inplace=True)\n",
        "\n",
        "    print(f\"  Rows: {len(IRS_df):,}\")\n",
        "\n",
        "    all_data.append(IRS_df)\n",
        "\n",
        "IRS_full = pd.concat(all_data, ignore_index=True)\n",
        "\n",
        "# Order variables\n",
        "final_cols = ['out_FIPS', 'in_FIPS', 'YEAR', 'Movers', 'agi']\n",
        "\n",
        "# Create the dataframe\n",
        "IRS_import = IRS_full[final_cols]\n",
        "IRS_import.to_csv('IRS_import.csv', index=False)\n",
        "\n",
        "\n",
        "print('\\n' + '='*30)\n",
        "print(\"\\n Saved to IRS_import.csv\")\n",
        "print('\\n' + '='*30)\n",
        "print(f\"\\nTotal rows: {len(IRS_import):,}\")\n",
        "\n",
        "# Display\n",
        "IRS_import.head(10)"
      ],
      "metadata": {
        "id": "TNkixxod-o6S"
      },
      "id": "TNkixxod-o6S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read 4 datafiles from USDA (8 of 8)  \n",
        "download 4 files (names are top line in each cell) from:  \n",
        "https://www.ers.usda.gov/data-products"
      ],
      "metadata": {
        "id": "kXt6YeL7bkKR"
      },
      "id": "kXt6YeL7bkKR"
    },
    {
      "cell_type": "code",
      "source": [
        "# 5: County Typology Codes, 2015 Edition\n",
        "# --------------------------------------------------\n",
        "typology = pd.read_csv('erscountytypology2015edition.csv')\n",
        "\n",
        "# Ensure FIPS is 5-digit string\n",
        "typology['FIPStxt'] = typology['FIPStxt'].astype(str).str.zfill(5)\n",
        "\n",
        "# Rename columns\n",
        "typology.rename(columns={\n",
        "    'FIPStxt': 'FIPS',\n",
        "    'Economic Types Type_2015_Update non-overlapping': 'Industry_type',\n",
        "    'Farming_2015_Update': 'Farming',\n",
        "    'Mining_2015-Update': 'Mining',\n",
        "    'Manufacturing_2015_Update': 'Mfging',\n",
        "    'Government_2015_Update': 'Govt',\n",
        "    'Recreation_2015_Update': 'Rec',\n",
        "    'Nonspecialized_2015_Update': 'Nonspec',\n",
        "    'Low_Education_2015_Update': 'Low_Ed_cnty',\n",
        "    'Low_Employment_Cnty_2008_2012_25_64': 'Low_emp_cnty',\n",
        "    'Retirement_Dest_2015_Update': 'Retire_dest_cnty',\n",
        "    'Persistent_Poverty_2013': 'Persistent_Pov_cnty',\n",
        "    'Persistent_Related_Child_Poverty_2013': 'Pers_chld_pov_cnty'}, inplace=True)\n",
        "\n",
        "# Drop variables to avoid duplication\n",
        "typology = typology.drop(columns=['State', 'County_name',\n",
        "    'Metro-nonmetro status, 2013 0=Nonmetro 1=Metro',\n",
        "    'Economic_Type_Label'])\n",
        "\n",
        "print(f\"Economic Typology 2015: {len(typology):,} counties\")\n",
        "# Display\n",
        "typology.head(10)"
      ],
      "metadata": {
        "id": "0Dp-wGzFBm8x"
      },
      "id": "0Dp-wGzFBm8x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6: Natural Amenities Scale\n",
        "# --------------------------------------------------\n",
        "# Data starts at row 105\n",
        "amenities = pd.read_excel('natamenf_1_.xls', skiprows=104, engine='xlrd')\n",
        "\n",
        "# Ensure FIPS is 5-digit string\n",
        "amenities['FIPS Code'] = amenities['FIPS Code'].astype(str).str.zfill(5)\n",
        "\n",
        "# Rename variables\n",
        "amenities.rename(columns={\n",
        "    'FIPS Code': 'FIPS',\n",
        "    'Scale': 'Amenity_score',\n",
        "    ' 1=Low  7=High': 'Amenity_rank'}, inplace=True)\n",
        "\n",
        "# Select only Amenity variables, drop the component variables\n",
        "amenities = amenities[['FIPS', 'Amenity_score', 'Amenity_rank']]\n",
        "\n",
        "print(f\"Natural Amenities: {len(amenities):,} counties\")\n",
        "# Display\n",
        "amenities.head(10)"
      ],
      "metadata": {
        "id": "0IWAWe3aBcFT"
      },
      "id": "0IWAWe3aBcFT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7: Rural-Urban Continuum Codes (RUCC) 2013\n",
        "# --------------------------------------------------\n",
        "rucc2013 = pd.read_excel('ruralurbancodes2013.xls')\n",
        "\n",
        "# Ensure FIPS is 5-digit string\n",
        "rucc2013['FIPS'] = rucc2013['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# Rename Population variable\n",
        "rucc2013 = rucc2013.rename(columns={'Population_2010': 'POP_2010'})\n",
        "\n",
        "# Select only RUCC code and population (drop 3 variables)\n",
        "rucc2013 = rucc2013.drop(columns=['Description', 'State', 'County_Name'])\n",
        "\n",
        "print(f\"RUCC 2013: {len(rucc2013):,} counties\")\n",
        "# Display\n",
        "rucc2013.head(10)"
      ],
      "metadata": {
        "id": "1lKVqnIbA_Q9"
      },
      "id": "1lKVqnIbA_Q9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8: Rural-Urban Continuum Codes (RUCC) 2023\n",
        "# --------------------------------------------------\n",
        "# Data is long format - 3 rows (Population, RUCC code, Description)\n",
        "ruccode2023 = pd.read_csv('Ruralurbancontinuumcodes2023.csv', encoding='latin-1')\n",
        "\n",
        "# Pivot from long to wide\n",
        "rucc2023 = ruccode2023.pivot(\n",
        "    index='FIPS',\n",
        "    columns='Attribute',\n",
        "    values='Value')\n",
        "\n",
        "# Reset the index to turn pivoted index into a regular column\n",
        "rucc2023 = rucc2023.reset_index()\n",
        "\n",
        "# Clear the columns name attribute after pivoting\n",
        "rucc2023.columns.name = None\n",
        "\n",
        "# Ensure FIPS is 5-digit string\n",
        "rucc2023['FIPS'] = rucc2023['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# Rename Population variable\n",
        "rucc2023 = rucc2023.rename(columns={'Population_2020': 'POP_2020'})\n",
        "\n",
        "# Select only RUCC code and population (drop description)\n",
        "rucc2023 = rucc2023[['FIPS', 'POP_2020', 'RUCC_2023']]\n",
        "\n",
        "print(f\"RUCC 2023: {len(rucc2023):,} counties\")\n",
        "# Display\n",
        "rucc2023.head(10)"
      ],
      "metadata": {
        "id": "8j4ui1tbBRLO"
      },
      "id": "8j4ui1tbBRLO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge all USDA data together"
      ],
      "metadata": {
        "id": "v0qjGjsyB7yd"
      },
      "id": "v0qjGjsyB7yd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge All USDA and Create County-Year Panel, with RUCC2013 as base\n",
        "usda_base = rucc2013[['FIPS', 'POP_2010', 'RUCC_2013']].copy()\n",
        "\n",
        "# Merge all classification variables\n",
        "usda_base = usda_base.merge(rucc2023, on='FIPS', how='left')\n",
        "usda_base = usda_base.merge(amenities, on='FIPS', how='left')\n",
        "usda_base = usda_base.merge(typology, on='FIPS', how='left')\n",
        "\n",
        "print(f\"\\nMerged USDA classifications: {len(usda_base):,} counties\")\n",
        "print(f\"Total variables: {len(usda_base.columns)}\")\n",
        "\n",
        "# Expand to county-year panel (2011-2021)\n",
        "usda_panel = []\n",
        "for year in range(2011, 2022):\n",
        "    df_year = usda_base.copy()\n",
        "    df_year['YEAR'] = year\n",
        "# Move YEAR to second column\n",
        "    cols = df_year.columns.tolist()\n",
        "    cols = [cols[0], 'YEAR'] + [c for c in cols[1:] if c != 'YEAR']\n",
        "    df_year = df_year[cols]\n",
        "    usda_panel.append(df_year)\n",
        "\n",
        "usda_import = pd.concat(usda_panel, ignore_index=True)\n",
        "\n",
        "# Save single consolidated panel\n",
        "usda_import.to_csv('USDA_import.csv', index=False)\n",
        "\n",
        "print('\\n' + '='*30)\n",
        "print(\"USDA MERGE COMPLETE\")\n",
        "print('\\n' + '='*30)\n",
        "print(f\"\\nTotal county-year observations: {len(usda_import):,}\")\n",
        "print(f\"Unique counties: {usda_import['FIPS'].nunique():,}\")\n",
        "print(f\"Total variables: {len(usda_import.columns)}\")\n",
        "# Display\n",
        "usda_import.head(10)"
      ],
      "metadata": {
        "id": "yF9MLTwSBvuf"
      },
      "id": "yF9MLTwSBvuf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect and Clean datasets  \n",
        "Look for min, max, nulls  \n",
        "negative values and other outliers"
      ],
      "metadata": {
        "id": "QFi0Nv9hor_Z"
      },
      "id": "QFi0Nv9hor_Z"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inspect BEA\n",
        "\n",
        "\n",
        "change (15901) to (15009)"
      ],
      "metadata": {
        "id": "gMJrNv3rP4T6"
      },
      "id": "gMJrNv3rP4T6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbda4e6b",
        "outputId": "2d29ebc4-2111-4e1b-cbec-baebc67af118"
      },
      "source": [
        "BEA_clean = pd.read_csv('BEA_import.csv')\n",
        "\n",
        "# Convert 'FIPS' to 5-digit string\n",
        "BEA_clean['FIPS'] = BEA_clean['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "print('\\nBEA first rows')\n",
        "print(BEA_clean.head())\n",
        "print('\\nBEA variable info')\n",
        "print(BEA_clean.info())\n",
        "print('\\nBEA descriptive stats')\n",
        "print(BEA_clean.describe())\n",
        "print('\\n BEA nulls')\n",
        "print(BEA_clean.isnull().sum())"
      ],
      "id": "bbda4e6b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BEA first rows\n",
            "    FIPS  YEAR  BEA_pci  BEA_gdp     RPP\n",
            "0  01001  2020    45068  1746979  87.517\n",
            "1  01001  2021    49174  1736001  88.497\n",
            "2  01001  2011    34430  1493906  91.098\n",
            "3  01001  2012    35151  1726577  93.269\n",
            "4  01001  2013    35348  1618151  91.394\n",
            "\n",
            "BEA variable info\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34298 entries, 0 to 34297\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   FIPS     34298 non-null  object \n",
            " 1   YEAR     34298 non-null  int64  \n",
            " 2   BEA_pci  34298 non-null  int64  \n",
            " 3   BEA_gdp  34298 non-null  int64  \n",
            " 4   RPP      34298 non-null  float64\n",
            "dtypes: float64(1), int64(3), object(1)\n",
            "memory usage: 1.3+ MB\n",
            "None\n",
            "\n",
            "BEA descriptive stats\n",
            "               YEAR        BEA_pci       BEA_gdp           RPP\n",
            "count  34298.000000   34298.000000  3.429800e+04  34298.000000\n",
            "mean    2016.000000   42470.220188  6.115655e+06     90.968153\n",
            "std        3.162324   12990.093071  2.665519e+07      6.529244\n",
            "min     2011.000000       0.000000  0.000000e+00      0.000000\n",
            "25%     2013.000000   34387.250000  3.731842e+05     86.128000\n",
            "50%     2016.000000   40145.500000  9.669475e+05     89.021000\n",
            "75%     2019.000000   47569.000000  2.850464e+06     94.674000\n",
            "max     2021.000000  353263.000000  7.735713e+08    122.740000\n",
            "\n",
            " BEA nulls\n",
            "FIPS       0\n",
            "YEAR       0\n",
            "BEA_pci    0\n",
            "BEA_gdp    0\n",
            "RPP        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply FIPS remapping: change '15901' to '15009' in BEA_clean\n",
        "BEA_clean['FIPS'] = BEA_clean['FIPS'].replace({'15901': '15009'})\n",
        "\n",
        "#Save\n",
        "BEA_clean.to_csv('BEA_import.csv', index=False)"
      ],
      "metadata": {
        "id": "fzDYTCAwOMFJ"
      },
      "id": "fzDYTCAwOMFJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLS Inspection  \n",
        "78 MVs\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  \n",
        "Puerto Rico is missing 2020 values\n",
        "Drop Puerto Rico (72000 Series)"
      ],
      "metadata": {
        "id": "WW-ali40KbGR"
      },
      "id": "WW-ali40KbGR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81010bd6",
        "outputId": "396f9c26-4b66-465d-82c2-c7085bafae10"
      },
      "source": [
        "BLS_clean = pd.read_csv('BLS_import.csv')\n",
        "\n",
        "# Convert 'FIPS' to 5-digit string\n",
        "BLS_clean['FIPS'] = BLS_clean['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "print('\\nBLS first rows')\n",
        "print(BLS_clean.head())\n",
        "print('\\nBLS variable info')\n",
        "print(BLS_clean.info())\n",
        "print('\\nBLS descriptive stats')\n",
        "print(BLS_clean.describe())\n",
        "print('\\nBLS nulls')\n",
        "print(BLS_clean.isnull().sum())"
      ],
      "id": "81010bd6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BLS first rows\n",
            "    FIPS  YEAR  unemploy_rate\n",
            "0  01001  2021            2.7\n",
            "1  01001  2020            5.3\n",
            "2  01001  2019            2.9\n",
            "3  01001  2018            3.6\n",
            "4  01001  2017            4.0\n",
            "\n",
            "BLS variable info\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35323 entries, 0 to 35322\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   FIPS           35323 non-null  object \n",
            " 1   YEAR           35323 non-null  int64  \n",
            " 2   unemploy_rate  35245 non-null  float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 828.0+ KB\n",
            "None\n",
            "\n",
            "BLS descriptive stats\n",
            "               YEAR  unemploy_rate\n",
            "count  35323.000000   35245.000000\n",
            "mean    2016.000255       6.104962\n",
            "std        3.162416       2.960603\n",
            "min     2011.000000       1.100000\n",
            "25%     2013.000000       4.000000\n",
            "50%     2016.000000       5.400000\n",
            "75%     2019.000000       7.500000\n",
            "max     2021.000000      28.900000\n",
            "\n",
            "BLS nulls\n",
            "FIPS              0\n",
            "YEAR              0\n",
            "unemploy_rate    78\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6a3550c",
        "outputId": "7379dea3-6d0c-452a-b6fe-bde1a0e7080b"
      },
      "source": [
        "# Exclude Puerto Rico (FIPS codes starting with '72')\n",
        "BLS_clean = BLS_clean[~BLS_clean['FIPS'].astype(str).str.startswith('72')]\n",
        "\n",
        "print('\\nBLS missing values after cleaning:')\n",
        "print(BLS_clean.isnull().sum())\n",
        "print(BLS_clean.tail())\n",
        "print(BLS_clean.info())"
      ],
      "id": "b6a3550c",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BLS missing values after cleaning:\n",
            "FIPS             0\n",
            "YEAR             0\n",
            "unemploy_rate    0\n",
            "dtype: int64\n",
            "        FIPS  YEAR  unemploy_rate\n",
            "34460  56045  2015            3.4\n",
            "34461  56045  2014            3.5\n",
            "34462  56045  2013            3.6\n",
            "34463  56045  2012            4.1\n",
            "34464  56045  2011            4.8\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 34465 entries, 0 to 34464\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   FIPS           34465 non-null  object \n",
            " 1   YEAR           34465 non-null  int64  \n",
            " 2   unemploy_rate  34465 non-null  float64\n",
            "dtypes: float64(1), int64(1), object(1)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Census Inspection  \n",
        "inspect 23 vars with 1MV  \n",
        "inspect 1 var with 2 MVs  \n",
        "inspect 1 var with 11 MVs  \n",
        "inspect med_home_value -666666666 values  \n",
        "inspect med_hh_income -666666666 values  \n",
        "inspect med_prop_taxes -666666666 values  \n",
        "\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "Kalawao, HI(15005): DROP ALL  \n",
        "total_population averages 105 from 2011-2021.  \n",
        "BEA.gov: \"Kalawao County, Hawaii is combined with Maui County.  \n",
        "Separate estimates for the jurisdictions making up the combination areas are not available\"  \n",
        "(0.002% of Maui population)\n",
        "\n",
        "Rio Arriba, New Mexico(35039):  \n",
        "23 MVs in 2018: Fill with average of 2017 and 2019.  \n",
        "\n",
        "(46017)(46095)(48243)(48261)(48301) NaN's:  \n",
        "2014 med_hm_value appears to be an error [166700]  \n",
        "Fill with average 2011-2021.  \n",
        "or ave of year before and year after."
      ],
      "metadata": {
        "id": "FWBx0AMFLMAZ"
      },
      "id": "FWBx0AMFLMAZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c1201ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0057ac-49db-4a02-f052-24e8ff16d42e"
      },
      "source": [
        "Census_clean = pd.read_csv('Census_import.csv')\n",
        "\n",
        "# Convert 'FIPS' to 5-digit string\n",
        "Census_clean['FIPS'] = Census_clean['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# Exclude Puerto Rico\n",
        "Census_clean = Census_clean[\n",
        "    ~Census_clean['FIPS'].astype(str).str.startswith('72')]\n",
        "\n",
        "# Drop Kalawao, HI (FIPS code 15005)\n",
        "Census_clean = Census_clean[\n",
        "    ~Census_clean['FIPS'].astype(str).str.startswith('15005')]\n",
        "\n",
        "print('\\nCensus first rows:')\n",
        "print(Census_clean.head())\n",
        "pd.set_option('display.max_columns', None) # Display ALL variable info/stats\n",
        "print('\\nCensus variable info:')\n",
        "print(Census_clean.info())\n",
        "print('\\nCensus descriptive stats:')\n",
        "print(Census_clean.describe())\n",
        "print('\\nCensus nulls:')\n",
        "print(Census_clean.isnull().sum())\n",
        "pd.reset_option('display.max_columns') # Reset display to default"
      ],
      "id": "9c1201ab",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Census first rows:\n",
            "    FIPS  YEAR  total_population  median_age  housing_total  owner_occupied  \\\n",
            "0  01001  2011             53944        36.4          19998           15548   \n",
            "1  01003  2011            179523        41.4          70757           53939   \n",
            "2  01005  2011             27546        38.3           9589            6371   \n",
            "3  01007  2011             22746        39.1           7225            5998   \n",
            "4  01009  2011             57140        38.8          20954           16747   \n",
            "\n",
            "   renter_occupied  vacant  median_home_value  family_households  ...  \\\n",
            "0             4450    1861           137500.0              14631  ...   \n",
            "1            16818   32221           175700.0              50922  ...   \n",
            "2             3218    2314            91600.0               6634  ...   \n",
            "3             1227    1708            87500.0               5334  ...   \n",
            "4             4207    2774           111500.0              15473  ...   \n",
            "\n",
            "   commute_90_plus_min  work_in_owned_home  work_in_rental  \\\n",
            "0                276.0               428.0           171.0   \n",
            "1               1667.0              2304.0           236.0   \n",
            "2                238.0               184.0            42.0   \n",
            "3                199.0               169.0             0.0   \n",
            "4                757.0               598.0            87.0   \n",
            "\n",
            "   median_property_taxes  occupation_total  Mgmt_Biz_Sci_Arts  Services  \\\n",
            "0                  392.0           24139.0             7524.0    3905.0   \n",
            "1                  574.0           79963.0            25808.0   14124.0   \n",
            "2                  314.0            9637.0             2600.0    1419.0   \n",
            "3                  225.0            9353.0             2007.0    1267.0   \n",
            "4                  368.0           24174.0             6098.0    3892.0   \n",
            "\n",
            "   Sales_Admin  Nat-rsrc_Constr_Maint  Prod_Transp_Mvng  \n",
            "0       6653.0                 2587.0            3470.0  \n",
            "1      22252.0                10110.0            7669.0  \n",
            "2       2372.0                  865.0            2381.0  \n",
            "3       2384.0                 1560.0            2135.0  \n",
            "4       5970.0                 3847.0            4367.0  \n",
            "\n",
            "[5 rows x 70 columns]\n",
            "\n",
            "Census variable info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 34556 entries, 0 to 35346\n",
            "Data columns (total 70 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   FIPS                   34556 non-null  object \n",
            " 1   YEAR                   34556 non-null  int64  \n",
            " 2   total_population       34556 non-null  int64  \n",
            " 3   median_age             34556 non-null  float64\n",
            " 4   housing_total          34556 non-null  int64  \n",
            " 5   owner_occupied         34556 non-null  int64  \n",
            " 6   renter_occupied        34556 non-null  int64  \n",
            " 7   vacant                 34556 non-null  int64  \n",
            " 8   median_home_value      34555 non-null  float64\n",
            " 9   family_households      34556 non-null  int64  \n",
            " 10  marital_total          34556 non-null  int64  \n",
            " 11  never_married_male     34556 non-null  int64  \n",
            " 12  now_married_male       34556 non-null  int64  \n",
            " 13  divorced_male          34556 non-null  int64  \n",
            " 14  widowed_male           34556 non-null  int64  \n",
            " 15  never_married_female   34556 non-null  int64  \n",
            " 16  now_married_female     34556 non-null  int64  \n",
            " 17  widowed_female         34556 non-null  int64  \n",
            " 18  divorced_female        34556 non-null  int64  \n",
            " 19  under_18_in_hh         34556 non-null  int64  \n",
            " 20  white                  34556 non-null  int64  \n",
            " 21  black                  34556 non-null  int64  \n",
            " 22  native                 34556 non-null  int64  \n",
            " 23  asian                  34556 non-null  int64  \n",
            " 24  pacific_islander       34556 non-null  int64  \n",
            " 25  other_race             34556 non-null  int64  \n",
            " 26  mixed_non_h            34556 non-null  int64  \n",
            " 27  hispanic               34556 non-null  int64  \n",
            " 28  education_total_sex    34556 non-null  int64  \n",
            " 29  male_complete_hs       34556 non-null  int64  \n",
            " 30  male_some_college<1    34556 non-null  int64  \n",
            " 31  male_some_college>1    34556 non-null  int64  \n",
            " 32  male_associates        34556 non-null  int64  \n",
            " 33  male_bachelors         34556 non-null  int64  \n",
            " 34  male_masters           34556 non-null  int64  \n",
            " 35  male_professional      34556 non-null  int64  \n",
            " 36  male_doctorate         34556 non-null  int64  \n",
            " 37  female_complete_hs     34556 non-null  int64  \n",
            " 38  female_some_college<1  34556 non-null  int64  \n",
            " 39  female_some_college>1  34556 non-null  int64  \n",
            " 40  female_associates      34556 non-null  int64  \n",
            " 41  female_bachelors       34556 non-null  int64  \n",
            " 42  female_masters         34556 non-null  int64  \n",
            " 43  female_professional    34556 non-null  int64  \n",
            " 44  female_doctorate       34556 non-null  int64  \n",
            " 45  median_hh_income       34554 non-null  float64\n",
            " 46  employed               34555 non-null  float64\n",
            " 47  unemployed             34555 non-null  float64\n",
            " 48  not_in_labor_force     34555 non-null  float64\n",
            " 49  commute_less_5min      34555 non-null  float64\n",
            " 50  commute_5_9min         34555 non-null  float64\n",
            " 51  commute_10_14min       34555 non-null  float64\n",
            " 52  commute_15_19min       34555 non-null  float64\n",
            " 53  commute_20_24min       34555 non-null  float64\n",
            " 54  commute_25_29min       34555 non-null  float64\n",
            " 55  commute_30_34min       34555 non-null  float64\n",
            " 56  commute_35_39min       34555 non-null  float64\n",
            " 57  commute_40_44min       34555 non-null  float64\n",
            " 58  commute_45_59min       34555 non-null  float64\n",
            " 59  commute_60_89min       34555 non-null  float64\n",
            " 60  commute_90_plus_min    34555 non-null  float64\n",
            " 61  work_in_owned_home     34555 non-null  float64\n",
            " 62  work_in_rental         34555 non-null  float64\n",
            " 63  median_property_taxes  34545 non-null  float64\n",
            " 64  occupation_total       34555 non-null  float64\n",
            " 65  Mgmt_Biz_Sci_Arts      34555 non-null  float64\n",
            " 66  Services               34555 non-null  float64\n",
            " 67  Sales_Admin            34555 non-null  float64\n",
            " 68  Nat-rsrc_Constr_Maint  34555 non-null  float64\n",
            " 69  Prod_Transp_Mvng       34555 non-null  float64\n",
            "dtypes: float64(27), int64(42), object(1)\n",
            "memory usage: 18.7+ MB\n",
            "None\n",
            "\n",
            "Census descriptive stats:\n",
            "               YEAR  total_population    median_age  housing_total  \\\n",
            "count  34556.000000      3.455600e+04  34556.000000   3.455600e+04   \n",
            "mean    2015.999913      1.013242e+05     40.953256   3.768169e+04   \n",
            "std        3.162511      3.241876e+05      5.306183   1.142320e+05   \n",
            "min     2011.000000      6.200000e+01     21.400000   2.700000e+01   \n",
            "25%     2013.000000      1.099950e+04     37.800000   4.229750e+03   \n",
            "50%     2016.000000      2.577200e+04     40.900000   9.839000e+03   \n",
            "75%     2019.000000      6.739475e+04     44.000000   2.586500e+04   \n",
            "max     2021.000000      1.010572e+07     68.100000   3.342811e+06   \n",
            "\n",
            "       owner_occupied  renter_occupied         vacant  median_home_value  \\\n",
            "count    3.455600e+04     3.455600e+04   34556.000000       3.455500e+04   \n",
            "mean     2.428937e+04     1.339232e+04    5210.086295      -6.944683e+04   \n",
            "std      6.387617e+04     5.298456e+04   12939.369194       1.189575e+07   \n",
            "min      5.000000e+00     1.100000e+01      17.000000      -6.666667e+08   \n",
            "25%      3.146000e+03     1.057000e+03     936.000000       8.900000e+04   \n",
            "50%      7.162000e+03     2.604000e+03    1985.000000       1.186000e+05   \n",
            "75%      1.833025e+04     7.498500e+03    4565.250000       1.650000e+05   \n",
            "max      1.545929e+06     1.798032e+06  245069.000000       1.225900e+06   \n",
            "\n",
            "       family_households  marital_total  never_married_male  now_married_male  \\\n",
            "count       3.455600e+04   3.455600e+04        3.455600e+04      3.455600e+04   \n",
            "mean        2.484054e+04   8.189434e+04        1.438334e+04      2.074233e+04   \n",
            "std         7.473446e+04   2.613386e+05        5.248891e+04      6.236350e+04   \n",
            "min         1.500000e+01   5.200000e+01        0.000000e+00      1.100000e+01   \n",
            "25%         2.832000e+03   8.935000e+03        1.323000e+03      2.459000e+03   \n",
            "50%         6.645000e+03   2.102250e+04        3.192000e+03      5.621500e+03   \n",
            "75%         1.727700e+04   5.491925e+04        8.700750e+03      1.446325e+04   \n",
            "max         2.216821e+06   8.246401e+06        1.826250e+06      1.869773e+06   \n",
            "\n",
            "       divorced_male  widowed_male  never_married_female  now_married_female  \\\n",
            "count   34556.000000  34556.000000          3.455600e+04        3.455600e+04   \n",
            "mean     3800.675744   1032.058195          1.249688e+04        2.059408e+04   \n",
            "std     10345.130925   2849.224946          4.739155e+04        6.188334e+04   \n",
            "min         0.000000      0.000000          0.000000e+00        1.200000e+01   \n",
            "25%       518.000000    150.000000          9.360000e+02        2.409000e+03   \n",
            "50%      1212.000000    339.000000          2.415500e+03        5.600000e+03   \n",
            "75%      2949.000000    817.000000          6.873250e+03        1.437500e+04   \n",
            "max    272667.000000  83020.000000          1.639775e+06        1.859232e+06   \n",
            "\n",
            "       widowed_female  divorced_female  under_18_in_hh         white  \\\n",
            "count    34556.000000     34556.000000    3.455600e+04  3.455600e+04   \n",
            "mean      3768.979714      5075.999479    2.340385e+04  6.268913e+04   \n",
            "std      10975.415004     15210.639925    7.621831e+04  1.425503e+05   \n",
            "min          0.000000         0.000000    0.000000e+00  1.000000e+00   \n",
            "25%        522.750000       521.000000    2.464750e+03  8.151000e+03   \n",
            "50%       1169.000000      1301.000000    5.866500e+03  2.016400e+04   \n",
            "75%       2829.000000      3543.000000    1.516950e+04  5.354300e+04   \n",
            "max     326385.000000    411578.000000    2.421031e+06  2.749159e+06   \n",
            "\n",
            "              black        native         asian  pacific_islander  \\\n",
            "count  3.455600e+04  34556.000000  3.455600e+04      34556.000000   \n",
            "mean   1.241477e+04    660.219499  5.235190e+03        162.809035   \n",
            "std    5.354643e+04   2884.450296  3.894223e+04       1869.703024   \n",
            "min    0.000000e+00      0.000000  0.000000e+00          0.000000   \n",
            "25%    9.100000e+01     23.000000  2.900000e+01          0.000000   \n",
            "50%    7.430000e+02     89.000000  1.320000e+02          1.000000   \n",
            "75%    5.384750e+03    341.000000  7.010000e+02         29.000000   \n",
            "max    1.275928e+06  70012.000000  1.467279e+06      96600.000000   \n",
            "\n",
            "         other_race    mixed_non_h      hispanic  education_total_sex  \\\n",
            "count  34556.000000   34556.000000  3.455600e+04         3.455600e+04   \n",
            "mean     239.849722    2364.481913  1.755772e+04         6.801909e+04   \n",
            "std     1280.708850    8597.158899  1.220501e+05         2.167840e+05   \n",
            "min        0.000000       0.000000  0.000000e+00         5.200000e+01   \n",
            "25%        0.000000     133.000000  3.090000e+02         7.567250e+03   \n",
            "50%       11.000000     391.000000  1.015000e+03         1.768750e+04   \n",
            "75%       80.000000    1389.000000  4.724750e+03         4.560325e+04   \n",
            "max    47388.000000  281399.000000  4.893603e+06         6.922061e+06   \n",
            "\n",
            "       male_complete_hs  male_some_college<1  male_some_college>1  \\\n",
            "count      34556.000000         34556.000000         34556.000000   \n",
            "mean        9269.204132          1975.050903          4750.861327   \n",
            "std        24296.670414          5414.904854         15348.602109   \n",
            "min            0.000000             0.000000             0.000000   \n",
            "25%         1474.000000           238.000000           518.000000   \n",
            "50%         3313.000000           562.000000          1180.500000   \n",
            "75%         7758.250000          1532.000000          3234.000000   \n",
            "max       718153.000000        156091.000000        500334.000000   \n",
            "\n",
            "       male_associates  male_bachelors   male_masters  male_professional  \\\n",
            "count     34556.000000    34556.000000   34556.000000       34556.000000   \n",
            "mean       2392.956216     6161.018434    2479.458878         805.989090   \n",
            "std        7178.846262    22547.938607    9294.981489        3284.240641   \n",
            "min           0.000000        0.000000       0.000000           0.000000   \n",
            "25%         237.000000      351.000000     107.000000          28.000000   \n",
            "50%         599.000000      913.000000     311.000000          91.000000   \n",
            "75%        1739.000000     2961.250000    1075.000000         333.000000   \n",
            "max      220648.000000   736487.000000  247142.000000       96306.000000   \n",
            "\n",
            "       male_doctorate  female_complete_hs  female_some_college<1  \\\n",
            "count    34556.000000        34556.000000           34556.000000   \n",
            "mean       544.610111         9440.290601            2291.806430   \n",
            "std       2108.090643        25531.727941            6339.945272   \n",
            "min          0.000000            0.000000               0.000000   \n",
            "25%         15.000000         1314.000000             271.000000   \n",
            "50%         57.000000         3078.500000             644.000000   \n",
            "75%        233.000000         7427.000000            1731.000000   \n",
            "max      53348.000000       710405.000000          168559.000000   \n",
            "\n",
            "       female_some_college>1  female_associates  female_bachelors  \\\n",
            "count           34556.000000       34556.000000      34556.000000   \n",
            "mean             5121.383233        3167.058977       6748.225026   \n",
            "std             16340.826733        9058.331380      24290.202469   \n",
            "min                 0.000000           0.000000          0.000000   \n",
            "25%               563.000000         341.000000        425.000000   \n",
            "50%              1312.000000         845.000000       1070.000000   \n",
            "75%              3470.250000        2376.000000       3348.000000   \n",
            "max            511463.000000      266773.000000     793588.000000   \n",
            "\n",
            "       female_masters  female_professional  female_doctorate  \\\n",
            "count    34556.000000         34556.000000      34556.000000   \n",
            "mean      3130.497916           582.678985        369.594716   \n",
            "std      11121.816794          2534.606624       1489.482729   \n",
            "min          0.000000             0.000000          0.000000   \n",
            "25%        168.000000            17.000000          8.000000   \n",
            "50%        465.500000            61.000000         36.000000   \n",
            "75%       1527.000000           220.000000        150.000000   \n",
            "max     306712.000000         78783.000000      44206.000000   \n",
            "\n",
            "       median_hh_income      employed     unemployed  not_in_labor_force  \\\n",
            "count      3.455400e+04  3.455500e+04   34555.000000        3.455500e+04   \n",
            "mean       1.106804e+04  4.729982e+04    3749.022660        2.916172e+04   \n",
            "std        5.072269e+06  1.546092e+05   14006.252164        8.909269e+04   \n",
            "min       -6.666667e+08  2.600000e+01       0.000000        2.000000e+00   \n",
            "25%        4.055625e+04  4.548500e+03     306.000000        3.855000e+03   \n",
            "50%        4.757250e+04  1.077100e+04     823.000000        8.832000e+03   \n",
            "75%        5.590000e+04  2.956850e+04    2320.000000        2.172300e+04   \n",
            "max        1.568210e+05  4.929863e+06  580531.000000        2.886707e+06   \n",
            "\n",
            "       commute_less_5min  commute_5_9min  commute_10_14min  commute_15_19min  \\\n",
            "count       34555.000000    34555.000000      34555.000000      34555.000000   \n",
            "mean         1333.933931     4365.859731       6087.062509       6775.485169   \n",
            "std          2365.702265     9768.026717      16384.732531      20427.691745   \n",
            "min             0.000000        0.000000          0.000000          0.000000   \n",
            "25%           336.000000      653.000000        525.500000        469.000000   \n",
            "50%           667.000000     1643.000000       1530.000000       1346.000000   \n",
            "75%          1357.000000     3967.000000       4670.000000       4409.000000   \n",
            "max         63968.000000   290428.000000     487202.000000     603852.000000   \n",
            "\n",
            "       commute_20_24min  commute_25_29min  commute_30_34min  commute_35_39min  \\\n",
            "count      34555.000000      34555.000000      34555.000000      34555.000000   \n",
            "mean        6435.058950       2787.621039       6035.077847       1283.625785   \n",
            "std        21402.441233       9225.386839      24138.925764       4548.836186   \n",
            "min            0.000000          0.000000          0.000000          0.000000   \n",
            "25%          399.000000        174.000000        415.000000         80.000000   \n",
            "50%         1126.000000        489.000000       1062.000000        249.000000   \n",
            "75%         3588.000000       1563.000000       3007.000000        737.000000   \n",
            "max       609648.000000     246791.000000     804468.000000     129438.000000   \n",
            "\n",
            "       commute_40_44min  commute_45_59min  commute_60_89min  \\\n",
            "count      34555.000000      34555.000000      34555.000000   \n",
            "mean        1688.288352       3508.463551       2644.017798   \n",
            "std         7087.073777      14663.949799      13172.011288   \n",
            "min            0.000000          0.000000          0.000000   \n",
            "25%           99.000000        249.000000        171.000000   \n",
            "50%          291.000000        688.000000        476.000000   \n",
            "75%          855.000000       1850.500000       1217.000000   \n",
            "max       235434.000000     494867.000000     489665.000000   \n",
            "\n",
            "       commute_90_plus_min  work_in_owned_home  work_in_rental  \\\n",
            "count         34555.000000        34555.000000    34555.000000   \n",
            "mean           1188.052438         1797.822312      602.654001   \n",
            "std            5011.355604         6222.496658     3679.374817   \n",
            "min               0.000000            0.000000        0.000000   \n",
            "25%              98.000000          153.000000       22.000000   \n",
            "50%             260.000000          353.000000       66.000000   \n",
            "75%             662.000000          998.000000      213.000000   \n",
            "max          181075.000000       269951.000000   245393.000000   \n",
            "\n",
            "       median_property_taxes  occupation_total  Mgmt_Biz_Sci_Arts  \\\n",
            "count           3.454500e+04      3.455500e+04       3.455500e+04   \n",
            "mean           -7.704774e+05      4.729982e+04       1.771914e+04   \n",
            "std             2.267262e+07      1.546092e+05       6.108225e+04   \n",
            "min            -6.666667e+08      2.600000e+01       8.000000e+00   \n",
            "25%             7.490000e+02      4.548500e+03       1.294000e+03   \n",
            "50%             1.180000e+03      1.077100e+04       3.119000e+03   \n",
            "75%             1.762000e+03      2.956850e+04       9.400500e+03   \n",
            "max             1.000100e+04      4.929863e+06       1.929372e+06   \n",
            "\n",
            "            Services   Sales_Admin  Nat-rsrc_Constr_Maint  Prod_Transp_Mvng  \n",
            "count   34555.000000  3.455500e+04           34555.000000      34555.000000  \n",
            "mean     8414.327594  1.099626e+04            4243.946752       5926.146925  \n",
            "std     28456.573115  3.664784e+04           12419.335554      18294.830334  \n",
            "min         0.000000  2.000000e+00               0.000000          0.000000  \n",
            "25%       810.000000  9.220000e+02             631.000000        738.000000  \n",
            "50%      1950.000000  2.320000e+03            1394.000000       1901.000000  \n",
            "75%      5479.500000  6.677500e+03            3351.000000       4824.500000  \n",
            "max    934749.000000  1.160343e+06          374366.000000     673695.000000  \n",
            "\n",
            "Census nulls:\n",
            "FIPS                     0\n",
            "YEAR                     0\n",
            "total_population         0\n",
            "median_age               0\n",
            "housing_total            0\n",
            "                        ..\n",
            "Mgmt_Biz_Sci_Arts        1\n",
            "Services                 1\n",
            "Sales_Admin              1\n",
            "Nat-rsrc_Constr_Maint    1\n",
            "Prod_Transp_Mvng         1\n",
            "Length: 70, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be55e73b"
      },
      "source": [
        "## Calculate Percentage Variables\n",
        "\n",
        "Convert `housing_occupied`,`marital_status`, and `race/ethnicity` to percentage scale.\n"
      ],
      "id": "be55e73b"
    },
    {
      "cell_type": "code",
      "source": [
        "print(Census_clean.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CstXzCvga9vP",
        "outputId": "be3e2249-dd82-49e0-b5c4-bf4a5f85df99"
      },
      "id": "CstXzCvga9vP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 34556 entries, 0 to 35346\n",
            "Data columns (total 70 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   FIPS                   34556 non-null  object \n",
            " 1   YEAR                   34556 non-null  int64  \n",
            " 2   total_population       34556 non-null  int64  \n",
            " 3   median_age             34556 non-null  float64\n",
            " 4   housing_total          34556 non-null  int64  \n",
            " 5   owner_occupied         34556 non-null  int64  \n",
            " 6   renter_occupied        34556 non-null  int64  \n",
            " 7   vacant                 34556 non-null  int64  \n",
            " 8   median_home_value      34555 non-null  float64\n",
            " 9   family_households      34556 non-null  int64  \n",
            " 10  marital_total          34556 non-null  int64  \n",
            " 11  never_married_male     34556 non-null  int64  \n",
            " 12  now_married_male       34556 non-null  int64  \n",
            " 13  divorced_male          34556 non-null  int64  \n",
            " 14  widowed_male           34556 non-null  int64  \n",
            " 15  never_married_female   34556 non-null  int64  \n",
            " 16  now_married_female     34556 non-null  int64  \n",
            " 17  widowed_female         34556 non-null  int64  \n",
            " 18  divorced_female        34556 non-null  int64  \n",
            " 19  under_18_in_hh         34556 non-null  int64  \n",
            " 20  white                  34556 non-null  int64  \n",
            " 21  black                  34556 non-null  int64  \n",
            " 22  native                 34556 non-null  int64  \n",
            " 23  asian                  34556 non-null  int64  \n",
            " 24  pacific_islander       34556 non-null  int64  \n",
            " 25  other_race             34556 non-null  int64  \n",
            " 26  mixed_non_h            34556 non-null  int64  \n",
            " 27  hispanic               34556 non-null  int64  \n",
            " 28  education_total_sex    34556 non-null  int64  \n",
            " 29  male_complete_hs       34556 non-null  int64  \n",
            " 30  male_some_college<1    34556 non-null  int64  \n",
            " 31  male_some_college>1    34556 non-null  int64  \n",
            " 32  male_associates        34556 non-null  int64  \n",
            " 33  male_bachelors         34556 non-null  int64  \n",
            " 34  male_masters           34556 non-null  int64  \n",
            " 35  male_professional      34556 non-null  int64  \n",
            " 36  male_doctorate         34556 non-null  int64  \n",
            " 37  female_complete_hs     34556 non-null  int64  \n",
            " 38  female_some_college<1  34556 non-null  int64  \n",
            " 39  female_some_college>1  34556 non-null  int64  \n",
            " 40  female_associates      34556 non-null  int64  \n",
            " 41  female_bachelors       34556 non-null  int64  \n",
            " 42  female_masters         34556 non-null  int64  \n",
            " 43  female_professional    34556 non-null  int64  \n",
            " 44  female_doctorate       34556 non-null  int64  \n",
            " 45  median_hh_income       34554 non-null  float64\n",
            " 46  employed               34555 non-null  float64\n",
            " 47  unemployed             34555 non-null  float64\n",
            " 48  not_in_labor_force     34555 non-null  float64\n",
            " 49  commute_less_5min      34555 non-null  float64\n",
            " 50  commute_5_9min         34555 non-null  float64\n",
            " 51  commute_10_14min       34555 non-null  float64\n",
            " 52  commute_15_19min       34555 non-null  float64\n",
            " 53  commute_20_24min       34555 non-null  float64\n",
            " 54  commute_25_29min       34555 non-null  float64\n",
            " 55  commute_30_34min       34555 non-null  float64\n",
            " 56  commute_35_39min       34555 non-null  float64\n",
            " 57  commute_40_44min       34555 non-null  float64\n",
            " 58  commute_45_59min       34555 non-null  float64\n",
            " 59  commute_60_89min       34555 non-null  float64\n",
            " 60  commute_90_plus_min    34555 non-null  float64\n",
            " 61  work_in_owned_home     34555 non-null  float64\n",
            " 62  work_in_rental         34555 non-null  float64\n",
            " 63  median_property_taxes  34545 non-null  float64\n",
            " 64  occupation_total       34555 non-null  float64\n",
            " 65  Mgmt_Biz_Sci_Arts      34555 non-null  float64\n",
            " 66  Services               34555 non-null  float64\n",
            " 67  Sales_Admin            34555 non-null  float64\n",
            " 68  Nat-rsrc_Constr_Maint  34555 non-null  float64\n",
            " 69  Prod_Transp_Mvng       34555 non-null  float64\n",
            "dtypes: float64(27), int64(42), object(1)\n",
            "memory usage: 18.7+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bee65e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6cecdc78-cdeb-4d0f-be35-2f3ecbc9446e"
      },
      "source": [
        "Census_clean['%owner_occupied'] = (\n",
        "    Census_clean['owner_occupied'] / Census_clean['housing_total']) * 100\n",
        "Census_clean['%renter_occupied'] = (\n",
        "    Census_clean['renter_occupied'] / Census_clean['housing_total']) * 100\n",
        "'''\n",
        "# Fill any NaN values that may have resulted from the percentage calculations with 0\n",
        "Census_clean['%owner_occupied'] = Census_clean['%owner_occupied'].fillna(0)\n",
        "Census_clean['%renter_occupied'] = Census_clean['%renter_occupied'].fillna(0)\n",
        "'''\n",
        "#print(Census_clean.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Fill any NaN values that may have resulted from the percentage calculations with 0\\nCensus_clean['%owner_occupied'] = Census_clean['%owner_occupied'].fillna(0)\\nCensus_clean['%renter_occupied'] = Census_clean['%renter_occupied'].fillna(0)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "id": "bee65e20"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80dcd217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9016cbb1-7895-4f69-99ee-9259147e207c"
      },
      "source": [
        "Census1 = Census_clean['marital_total'] # create division variable\n",
        "\n",
        "Census_clean['%never_married_male'] = (\n",
        "    Census_clean['never_married_male'] / Census1) * 100\n",
        "Census_clean['%now_married_male'] = (\n",
        "    Census_clean['now_married_male'] / Census1) * 100\n",
        "Census_clean['%divorced_male'] = (\n",
        "    Census_clean['divorced_male'] / Census1) * 100\n",
        "Census_clean['%widowed_male'] = (\n",
        "    Census_clean['widowed_male'] / Census1) * 100\n",
        "Census_clean['%never_married_female'] = (\n",
        "    Census_clean['never_married_female'] / Census1) * 100\n",
        "Census_clean['%now_married_female'] = (\n",
        "    Census_clean['now_married_female'] / Census1) * 100\n",
        "Census_clean['%divorced_female'] = (\n",
        "    Census_clean['divorced_female'] / Census1) * 100\n",
        "Census_clean['%widowed_female'] = (\n",
        "    Census_clean['widowed_female'] / Census1) * 100\n",
        "'''\n",
        "# Fill any NaN values that may have resulted from the percentage calculations with 0\n",
        "marital_pct_cols = [\n",
        "    '%never_married_male', '%now_married_male', '%divorced_male', '%widowed_male',\n",
        "    '%never_married_female', '%now_married_female', '%divorced_female', '%widowed_female']\n",
        "for col in marital_pct_cols:\n",
        "    Census_clean[col] = Census_clean[col].fillna(0)\n",
        "'''\n",
        "#print(Census_clean.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Fill any NaN values that may have resulted from the percentage calculations with 0\\nmarital_pct_cols = [\\n    '%never_married_male', '%now_married_male', '%divorced_male', '%widowed_male',\\n    '%never_married_female', '%now_married_female', '%divorced_female', '%widowed_female']\\nfor col in marital_pct_cols:\\n    Census_clean[col] = Census_clean[col].fillna(0)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "id": "80dcd217"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40edc8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b766f368-33ff-45e2-93c1-a71109745521"
      },
      "source": [
        "Census2 = Census_clean['total_population'] # create division variable\n",
        "\n",
        "Census_clean['%white'] = (\n",
        "    Census_clean['white'] / Census2) * 100\n",
        "Census_clean['%black'] = (\n",
        "    Census_clean['black'] / Census2) * 100\n",
        "Census_clean['%native'] = (\n",
        "    Census_clean['native'] / Census2) * 100\n",
        "Census_clean['%asian'] = (\n",
        "    Census_clean['asian'] / Census2) * 100\n",
        "Census_clean['%pacific_islander'] = (\n",
        "    Census_clean['pacific_islander'] / Census2) * 100\n",
        "Census_clean['%other_race'] = (\n",
        "    Census_clean['other_race'] / Census2) * 100\n",
        "Census_clean['%mixed_non_h'] = (\n",
        "    Census_clean['mixed_non_h'] / Census2) * 100\n",
        "Census_clean['%hispanic'] = (\n",
        "    Census_clean['hispanic'] / Census2) * 100\n",
        "'''\n",
        "# Fill any NaN values that may have resulted from the percentage calculations with 0\n",
        "race_pct_cols = [\n",
        "    '%white', '%black', '%native', '%asian', '%pacific_islander',\n",
        "    '%other_race', '%mixed_non_h', '%hispanic']\n",
        "for col in race_pct_cols:\n",
        "    Census_clean[col] = Census_clean[col].fillna(0)\n",
        "'''\n",
        "#print(Census_clean.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Fill any NaN values that may have resulted from the percentage calculations with 0\\nrace_pct_cols = [\\n    '%white', '%black', '%native', '%asian', '%pacific_islander',\\n    '%other_race', '%mixed_non_h', '%hispanic']\\nfor col in race_pct_cols:\\n    Census_clean[col] = Census_clean[col].fillna(0)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "id": "40edc8d9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform Education Variables\n",
        "Combine sex-separated `education` categories"
      ],
      "metadata": {
        "id": "BMki6h-MwdT_"
      },
      "id": "BMki6h-MwdT_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d448080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "09a3cf27-9834-493f-c429-12f6063fdebe"
      },
      "source": [
        "Census_clean['complete_hs'] = Census_clean[\n",
        "    'male_complete_hs'] + Census_clean['female_complete_hs']\n",
        "Census_clean['some_college'] = Census_clean[\n",
        "    'male_some_college<1'] + Census_clean[\n",
        "    'female_some_college<1'] + Census_clean[\n",
        "    'male_some_college>1'] + Census_clean[\n",
        "    'female_some_college>1']\n",
        "Census_clean['associates'] = Census_clean[\n",
        "    'male_associates'] + Census_clean['female_associates']\n",
        "Census_clean['bachelors'] = Census_clean[\n",
        "    'male_bachelors'] + Census_clean['female_bachelors']\n",
        "Census_clean['masters'] = Census_clean[\n",
        "    'male_masters'] + Census_clean['female_masters']\n",
        "Census_clean['professional'] = Census_clean[\n",
        "    'male_professional'] + Census_clean['female_professional']\n",
        "Census_clean['doctorate'] = Census_clean[\n",
        "    'male_doctorate'] + Census_clean['female_doctorate']\n",
        "'''\n",
        "# Fill any NaN values that may have resulted from the percentage calculations with 0\n",
        "education_pct_cols = [\n",
        "    '%complete_hs', '%some_college_lt1', '%some_college_gt1', '%associates',\n",
        "    '%bachelors', '%masters', '%professional', '%doctorate']\n",
        "for col in education_pct_cols:\n",
        "    Census_clean[col] = Census_clean[col].fillna(0)\n",
        "'''\n",
        "#print(Census_clean.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Fill any NaN values that may have resulted from the percentage calculations with 0\\neducation_pct_cols = [\\n    '%complete_hs', '%some_college_lt1', '%some_college_gt1', '%associates',\\n    '%bachelors', '%masters', '%professional', '%doctorate']\\nfor col in education_pct_cols:\\n    Census_clean[col] = Census_clean[col].fillna(0)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "id": "0d448080"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30f10dcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee74db06-a56b-4443-ac75-03165966c87c"
      },
      "source": [
        "# remove converted variables\n",
        "housing_cols_to_drop = [\n",
        "    'owner_occupied', 'renter_occupied']\n",
        "marital_cols_to_drop = [\n",
        "    'never_married_male', 'now_married_male',\n",
        "    'divorced_male', 'widowed_male',\n",
        "    'never_married_female', 'now_married_female',\n",
        "    'widowed_female', 'divorced_female']\n",
        "race_ethnicity_cols_to_drop = [\n",
        "    'white', 'black', 'native', 'asian',\n",
        "    'pacific_islander', 'other_race', 'mixed_non_h', 'hispanic']\n",
        "education_cols_to_drop = [\n",
        "    'male_complete_hs', 'male_some_college<1', 'male_some_college>1',\n",
        "    'male_associates', 'male_bachelors', 'male_masters',\n",
        "    'male_professional', 'male_doctorate',\n",
        "    'female_complete_hs', 'female_some_college<1', 'female_some_college>1',\n",
        "    'female_associates', 'female_bachelors', 'female_masters',\n",
        "    'female_professional', 'female_doctorate']\n",
        "\n",
        "Census_clean.drop(\n",
        "    columns=housing_cols_to_drop + marital_cols_to_drop + \\\n",
        "            race_ethnicity_cols_to_drop + education_cols_to_drop,\n",
        "    inplace=True, errors='ignore')\n",
        "\n",
        "print(Census_clean.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               YEAR  total_population    median_age  housing_total  \\\n",
            "count  34556.000000      3.455600e+04  34556.000000   3.455600e+04   \n",
            "mean    2015.999913      1.013242e+05     40.953256   3.768169e+04   \n",
            "std        3.162511      3.241876e+05      5.306183   1.142320e+05   \n",
            "min     2011.000000      6.200000e+01     21.400000   2.700000e+01   \n",
            "25%     2013.000000      1.099950e+04     37.800000   4.229750e+03   \n",
            "50%     2016.000000      2.577200e+04     40.900000   9.839000e+03   \n",
            "75%     2019.000000      6.739475e+04     44.000000   2.586500e+04   \n",
            "max     2021.000000      1.010572e+07     68.100000   3.342811e+06   \n",
            "\n",
            "              vacant  median_home_value  family_households  marital_total  \\\n",
            "count   34556.000000       3.455500e+04       3.455600e+04   3.455600e+04   \n",
            "mean     5210.086295      -6.944683e+04       2.484054e+04   8.189434e+04   \n",
            "std     12939.369194       1.189575e+07       7.473446e+04   2.613386e+05   \n",
            "min        17.000000      -6.666667e+08       1.500000e+01   5.200000e+01   \n",
            "25%       936.000000       8.900000e+04       2.832000e+03   8.935000e+03   \n",
            "50%      1985.000000       1.186000e+05       6.645000e+03   2.102250e+04   \n",
            "75%      4565.250000       1.650000e+05       1.727700e+04   5.491925e+04   \n",
            "max    245069.000000       1.225900e+06       2.216821e+06   8.246401e+06   \n",
            "\n",
            "       under_18_in_hh  education_total_sex  ...   %other_race  %mixed_non_h  \\\n",
            "count    3.455600e+04         3.455600e+04  ...  34556.000000  34556.000000   \n",
            "mean     2.340385e+04         6.801909e+04  ...      0.112243      1.923335   \n",
            "std      7.621831e+04         2.167840e+05  ...      0.220033      1.752092   \n",
            "min      0.000000e+00         5.200000e+01  ...      0.000000      0.000000   \n",
            "25%      2.464750e+03         7.567250e+03  ...      0.000000      1.002747   \n",
            "50%      5.866500e+03         1.768750e+04  ...      0.042313      1.556485   \n",
            "75%      1.516950e+04         4.560325e+04  ...      0.146217      2.304006   \n",
            "max      2.421031e+06         6.922061e+06  ...     10.506567     23.738799   \n",
            "\n",
            "          %hispanic   complete_hs  some_college     associates     bachelors  \\\n",
            "count  34556.000000  3.455600e+04  3.455600e+04   34556.000000  3.455600e+04   \n",
            "mean       8.951683  1.870949e+04  1.413910e+04    5560.015193  1.290924e+04   \n",
            "std       13.596843  4.979828e+04  4.328943e+04   16218.360973  4.682337e+04   \n",
            "min        0.000000  9.000000e+00  0.000000e+00       0.000000  0.000000e+00   \n",
            "25%        1.948257  2.788750e+03  1.620000e+03     586.000000  7.740000e+02   \n",
            "50%        3.816154  6.398000e+03  3.713500e+03    1437.000000  1.984000e+03   \n",
            "75%        9.151894  1.521350e+04  1.000125e+04    4104.250000  6.289500e+03   \n",
            "max       99.184800  1.419449e+06  1.314543e+06  486941.000000  1.530075e+06   \n",
            "\n",
            "             masters   professional     doctorate  \n",
            "count   34556.000000   34556.000000  34556.000000  \n",
            "mean     5609.956795    1388.668075    914.204827  \n",
            "std     20359.560902    5803.039446   3581.186843  \n",
            "min         0.000000       0.000000      0.000000  \n",
            "25%       282.000000      50.000000     26.000000  \n",
            "50%       776.000000     153.000000     95.000000  \n",
            "75%      2603.000000     553.000000    383.000000  \n",
            "max    553854.000000  175089.000000  97554.000000  \n",
            "\n",
            "[8 rows x 60 columns]\n"
          ]
        }
      ],
      "id": "30f10dcb"
    },
    {
      "cell_type": "code",
      "source": [
        "#print(Census_clean.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZZl4Jhobttm",
        "outputId": "41a8405b-171c-451d-879d-a65088759897"
      },
      "id": "TZZl4Jhobttm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 34556 entries, 0 to 35346\n",
            "Data columns (total 61 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   FIPS                   34556 non-null  object \n",
            " 1   YEAR                   34556 non-null  int64  \n",
            " 2   total_population       34556 non-null  int64  \n",
            " 3   median_age             34556 non-null  float64\n",
            " 4   housing_total          34556 non-null  int64  \n",
            " 5   vacant                 34556 non-null  int64  \n",
            " 6   median_home_value      34555 non-null  float64\n",
            " 7   family_households      34556 non-null  int64  \n",
            " 8   marital_total          34556 non-null  int64  \n",
            " 9   under_18_in_hh         34556 non-null  int64  \n",
            " 10  education_total_sex    34556 non-null  int64  \n",
            " 11  median_hh_income       34554 non-null  float64\n",
            " 12  employed               34555 non-null  float64\n",
            " 13  unemployed             34555 non-null  float64\n",
            " 14  not_in_labor_force     34555 non-null  float64\n",
            " 15  commute_less_5min      34555 non-null  float64\n",
            " 16  commute_5_9min         34555 non-null  float64\n",
            " 17  commute_10_14min       34555 non-null  float64\n",
            " 18  commute_15_19min       34555 non-null  float64\n",
            " 19  commute_20_24min       34555 non-null  float64\n",
            " 20  commute_25_29min       34555 non-null  float64\n",
            " 21  commute_30_34min       34555 non-null  float64\n",
            " 22  commute_35_39min       34555 non-null  float64\n",
            " 23  commute_40_44min       34555 non-null  float64\n",
            " 24  commute_45_59min       34555 non-null  float64\n",
            " 25  commute_60_89min       34555 non-null  float64\n",
            " 26  commute_90_plus_min    34555 non-null  float64\n",
            " 27  work_in_owned_home     34555 non-null  float64\n",
            " 28  work_in_rental         34555 non-null  float64\n",
            " 29  median_property_taxes  34545 non-null  float64\n",
            " 30  occupation_total       34555 non-null  float64\n",
            " 31  Mgmt_Biz_Sci_Arts      34555 non-null  float64\n",
            " 32  Services               34555 non-null  float64\n",
            " 33  Sales_Admin            34555 non-null  float64\n",
            " 34  Nat-rsrc_Constr_Maint  34555 non-null  float64\n",
            " 35  Prod_Transp_Mvng       34555 non-null  float64\n",
            " 36  %owner_occupied        34556 non-null  float64\n",
            " 37  %renter_occupied       34556 non-null  float64\n",
            " 38  %never_married_male    34556 non-null  float64\n",
            " 39  %now_married_male      34556 non-null  float64\n",
            " 40  %divorced_male         34556 non-null  float64\n",
            " 41  %widowed_male          34556 non-null  float64\n",
            " 42  %never_married_female  34556 non-null  float64\n",
            " 43  %now_married_female    34556 non-null  float64\n",
            " 44  %divorced_female       34556 non-null  float64\n",
            " 45  %widowed_female        34556 non-null  float64\n",
            " 46  %white                 34556 non-null  float64\n",
            " 47  %black                 34556 non-null  float64\n",
            " 48  %native                34556 non-null  float64\n",
            " 49  %asian                 34556 non-null  float64\n",
            " 50  %pacific_islander      34556 non-null  float64\n",
            " 51  %other_race            34556 non-null  float64\n",
            " 52  %mixed_non_h           34556 non-null  float64\n",
            " 53  %hispanic              34556 non-null  float64\n",
            " 54  complete_hs            34556 non-null  int64  \n",
            " 55  some_college           34556 non-null  int64  \n",
            " 56  associates             34556 non-null  int64  \n",
            " 57  bachelors              34556 non-null  int64  \n",
            " 58  masters                34556 non-null  int64  \n",
            " 59  professional           34556 non-null  int64  \n",
            " 60  doctorate              34556 non-null  int64  \n",
            "dtypes: float64(45), int64(15), object(1)\n",
            "memory usage: 16.3+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle NaNs:  \n",
        "As described at Inspection"
      ],
      "metadata": {
        "id": "rTi_0RWe2QV_"
      },
      "id": "rTi_0RWe2QV_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "474ce1fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "510606d6-803d-4977-8580-09aa32759291"
      },
      "source": [
        "        ## some code attributed to Colab Gemini\n",
        "\n",
        "# For FIPS '35039' (Rio Arriba, NM)\n",
        "fips_35039_mask = (Census_clean['FIPS'] == '35039')\n",
        "\n",
        "# Identify columns with NaNs in 2018 for this FIPS\n",
        "rows_2018_35039 = Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2018)]\n",
        "\n",
        "if not rows_2018_35039.empty:\n",
        "  for col in rows_2018_35039.columns:\n",
        "    if rows_2018_35039[col].isnull().any():\n",
        "    # Check if there is an NaN in this column for 2018\n",
        "      # Get values for 2017 and 2019\n",
        "      val_2017 = Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2017)][col].iloc[0] if not Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2017)].empty else np.nan\n",
        "      val_2019 = Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2019)][col].iloc[0] if not Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2019)].empty else np.nan\n",
        "\n",
        "# Calculate average and fill if both values are available\n",
        "if pd.notna(val_2017) and pd.notna(val_2019):\n",
        "                imputed_value = (val_2017 + val_2019) / 2\n",
        "                Census_clean.loc[fips_35039_mask & (Census_clean['YEAR'] == 2018), col] = imputed_value\n",
        "\n",
        "# For FIPS '46017' (Buffalo, SD)\n",
        "fips_46017_mask = (Census_clean['FIPS'] == '46017')\n",
        "\n",
        "# Calculate average for median_home_value (2011-2021)\n",
        "avg_mhv_46017 = Census_clean[fips_46017_mask & (Census_clean['YEAR'].between(2011, 2021))]['median_home_value'].replace(-666666666, np.nan).mean()\n",
        "Census_clean.loc[fips_46017_mask & (Census_clean['YEAR'] == 2020), 'median_home_value'] = avg_mhv_46017\n",
        "\n",
        "# Calculate average for median_property_taxes (2011-2021)\n",
        "avg_mpt_46017 = Census_clean[fips_46017_mask & (Census_clean['YEAR'].between(2011, 2021))]['median_property_taxes'].replace(-666666666, np.nan).mean()\n",
        "Census_clean.loc[fips_46017_mask & (Census_clean['YEAR'] == 2020), 'median_property_taxes'] = avg_mpt_46017\n",
        "\n",
        "# For FIPS '46095' (Mellette, SD)\n",
        "fips_46095_mask = (Census_clean['FIPS'] == '46095')\n",
        "\n",
        "# median_home_value in 2020: average of 2019 and 2021\n",
        "val_mhv_2019_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2019)]['median_home_value'].iloc[0]\n",
        "val_mhv_2021_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2021)]['median_home_value'].iloc[0]\n",
        "imputed_mhv_2020_46095 = (val_mhv_2019_46095 + val_mhv_2021_46095) / 2\n",
        "Census_clean.loc[fips_46095_mask & (Census_clean['YEAR'] == 2020), 'median_home_value'] = imputed_mhv_2020_46095\n",
        "\n",
        "# median_property_taxes in 2019 and 2020: average of 2018 and 2021\n",
        "val_mpt_2018_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2018)]['median_property_taxes'].iloc[0]\n",
        "val_mpt_2021_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2021)]['median_property_taxes'].iloc[0]\n",
        "imputed_mpt_46095 = (val_mpt_2018_46095 + val_mpt_2021_46095) / 2\n",
        "Census_clean.loc[fips_46095_mask & (Census_clean['YEAR'].isin([2019, 2020])), 'median_property_taxes'] = imputed_mpt_46095\n",
        "\n",
        "# For FIPS '48243' (Jeff Davis, TX)\n",
        "fips_48243_mask = (Census_clean['FIPS'] == '48243')\n",
        "\n",
        "# median_hh_income (2011-2019 average) for 2020\n",
        "avg_mhi_48243 = Census_clean[fips_48243_mask & (Census_clean['YEAR'].between(2011, 2019))]['median_hh_income'].mean()\n",
        "Census_clean.loc[fips_48243_mask & (Census_clean['YEAR'] == 2020), 'median_hh_income'] = avg_mhi_48243\n",
        "\n",
        "# median_property_taxes (2011-2019 average) for 2020\n",
        "avg_mpt_48243 = Census_clean[fips_48243_mask & (Census_clean['YEAR'].between(2011, 2019))]['median_property_taxes'].replace(-666666666, np.nan).mean()\n",
        "Census_clean.loc[fips_48243_mask & (Census_clean['YEAR'] == 2020), 'median_property_taxes'] = avg_mpt_48243\n",
        "\n",
        "# For FIPS '48261' (Kenedy, TX)\n",
        "fips_48261_mask = (Census_clean['FIPS'] == '48261')\n",
        "\n",
        "# Calculate average for median_home_value (2011-2019)\n",
        "avg_mhv_48261 = Census_clean[fips_48261_mask & (Census_clean['YEAR'].between(2011, 2019))]['median_home_value'].replace(-666666666, np.nan).mean()\n",
        "\n",
        "# Replace 2014 median_home_value if 166700.0\n",
        "if not Census_clean[fips_48261_mask & (Census_clean['YEAR'] == 2014) & (Census_clean['median_home_value'] == 166700.0)].empty:\n",
        "    Census_clean.loc[fips_48261_mask & (Census_clean['YEAR'] == 2014), 'median_home_value'] = avg_mhv_48261\n",
        "\n",
        "# Fill 2015-2021 missing median_home_value with the same average\n",
        "Census_clean.loc[fips_48261_mask & (Census_clean['YEAR'].between(2015, 2021)), 'median_home_value'] = Census_clean.loc[fips_48261_mask & (Census_clean['YEAR'].between(2015, 2021)), 'median_home_value'].fillna(avg_mhv_48261)\n",
        "\n",
        "# For FIPS '48301' (Loving, TX)\n",
        "fips_48301_mask = (Census_clean['FIPS'] == '48301')\n",
        "\n",
        "# median_hh_income\n",
        "# Fill 2015 with average of 2014 and 2016\n",
        "val_mhi_2014_48301 = Census_clean[fips_48301_mask & (Census_clean['YEAR'] == 2014)]['median_hh_income'].iloc[0]\n",
        "val_mhi_2016_48301 = Census_clean[fips_48301_mask & (Census_clean['YEAR'] == 2016)]['median_hh_income'].iloc[0]\n",
        "imputed_mhi_2015_48301 = (val_mhi_2014_48301 + val_mhi_2016_48301) / 2\n",
        "Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == 2015), 'median_hh_income'] = imputed_mhi_2015_48301\n",
        "\n",
        "# Fill 2021 with average of 2011-2020\n",
        "avg_mhi_2011_2020_48301 = Census_clean[fips_48301_mask & (Census_clean['YEAR'].between(2011, 2020))]['median_hh_income'].mean()\n",
        "Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == 2021), 'median_hh_income'] = avg_mhi_2011_2020_48301\n",
        "\n",
        "# median_home_value (impute specific values)\n",
        "imputed_mhv_values_48301 = {2016: 101750, 2017: 119100, 2018: 131700, 2019: 128300, 2020: 169400, 2021: 178700}\n",
        "for year, value in imputed_mhv_values_48301.items():\n",
        "    Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == year), 'median_home_value'] = value\n",
        "\n",
        "# median_property_taxes (impute specific values)\n",
        "imputed_mpt_values_48301 = {2015: 1350, 2016: 1480, 2017: 1568, 2018: 1960, 2019: 2156, 2020: 2105, 2021: 2200}\n",
        "for year, value in imputed_mpt_values_48301.items():\n",
        "    Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == year), 'median_property_taxes'] = value\n",
        "\n",
        "# For FIPS '22091', '22107', and '35011', fill missing median_property_taxes in 2015 with the average of 2014 and 2016.\n",
        "fips_to_impute_2015 = ['22091', '22107', '35011']\n",
        "for fips_code in fips_to_impute_2015:\n",
        "    mask_fips = (Census_clean['FIPS'] == fips_code)\n",
        "    val_mpt_2014 = Census_clean[mask_fips & (Census_clean['YEAR'] == 2014)]['median_property_taxes'].replace(-666666666, np.nan).iloc[0] if not Census_clean[mask_fips & (Census_clean['YEAR'] == 2014)].empty else np.nan\n",
        "    val_mpt_2016 = Census_clean[mask_fips & (Census_clean['YEAR'] == 2016)]['median_property_taxes'].replace(-666666666, np.nan).iloc[0] if not Census_clean[mask_fips & (Census_clean['YEAR'] == 2016)].empty else np.nan\n",
        "    if pd.notna(val_mpt_2014) and pd.notna(val_mpt_2016):\n",
        "      imputed_val_2015 = (val_mpt_2014 + val_mpt_2016) / 2\n",
        "      Census_clean.loc[mask_fips & (Census_clean['YEAR'] == 2015), 'median_property_taxes'] = imputed_val_2015\n",
        "\n",
        "# For FIPS '48263', fill missing median_property_taxes in 2019 with the average of 2018 and 2020.\n",
        "fips_48263_mask = (Census_clean['FIPS'] == '48263')\n",
        "val_mpt_2018 = Census_clean[fips_48263_mask & (Census_clean['YEAR'] == 2018)]['median_property_taxes'].replace(-666666666, np.nan).iloc[0] if not Census_clean[fips_48263_mask & (Census_clean['YEAR'] == 2018)].empty else np.nan\n",
        "val_mpt_2020 = Census_clean[fips_48263_mask & (Census_clean['YEAR'] == 2020)]['median_property_taxes'].replace(-666666666, np.nan).iloc[0] if not Census_clean[fips_48263_mask & (Census_clean['YEAR'] == 2020)].empty else np.nan\n",
        "if pd.notna(val_mpt_2018) and pd.notna(val_mpt_2020):\n",
        "    imputed_val_2019 = (val_mpt_2018 + val_mpt_2020) / 2\n",
        "    Census_clean.loc[fips_48263_mask & (Census_clean['YEAR'] == 2019), 'median_property_taxes'] = imputed_val_2019\n",
        "\n",
        "# Display null counts after imputation\n",
        "print('\\nCensus nulls after imputation:')\n",
        "print(Census_clean.isnull().sum())\n",
        "\n",
        "# Display info after imputation to check data types and non-null counts\n",
        "print('\\nCensus info after imputation:')\n",
        "print(Census_clean[['median_home_value', 'median_hh_income', 'median_property_taxes']].describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Census nulls after imputation:\n",
            "FIPS                0\n",
            "YEAR                0\n",
            "total_population    0\n",
            "median_age          0\n",
            "housing_total       0\n",
            "                   ..\n",
            "associates          0\n",
            "bachelors           0\n",
            "masters             0\n",
            "professional        0\n",
            "doctorate           0\n",
            "Length: 61, dtype: int64\n",
            "\n",
            "Census info after imputation:\n",
            "       median_home_value  median_hh_income  median_property_taxes\n",
            "count       3.455600e+04      34555.000000           3.454900e+04\n",
            "mean        8.491942e+04      49658.691719          -5.967213e+05\n",
            "std         6.213440e+06      13775.104857           1.996109e+07\n",
            "min        -6.666667e+08      17109.000000          -6.666667e+08\n",
            "25%         8.910000e+04      40559.500000           7.490000e+02\n",
            "50%         1.186000e+05      47574.000000           1.180000e+03\n",
            "75%         1.650000e+05      55901.500000           1.762000e+03\n",
            "max         1.225900e+06     156821.000000           1.000100e+04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2202100554.py:20: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1063.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  Census_clean.loc[fips_35039_mask & (Census_clean['YEAR'] == 2018), col] = imputed_value\n"
          ]
        }
      ],
      "id": "474ce1fd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## USDA Inspection  \n",
        "Amenity_score & Amenity_rank  MV=396  \n",
        "POP_2020 & RUCC_2023          MV=132  \n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "* Alaska and Hawaii are not part of USDA Amenities Scale  \n",
        "[fill score=0 (average) and rank=0 (outside 1-7 ranking)]  \n",
        "\n",
        "* 09xxx CT 8 counties became 9 planning regions.  \n",
        "* 46113 renamed 46102 in 2015  \n",
        "* 51515 (Bedford city) folded into 51019 (Bedford County) in 2014  \n",
        "[Use POP_2010 and RUCC_2013 values]\n",
        "\n"
      ],
      "metadata": {
        "id": "wIJMNwxivnWE"
      },
      "id": "wIJMNwxivnWE"
    },
    {
      "cell_type": "code",
      "source": [
        "USDA_clean = pd.read_csv('USDA_import.csv')\n",
        "\n",
        "# Convert 'FIPS' to 5-digit string\n",
        "USDA_clean['FIPS'] = USDA_clean['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# Exclude Puerto Rico and territories; FIPS codes greater than '56999'\n",
        "USDA_clean = USDA_clean[USDA_clean['FIPS'].astype(int) <= 56999]\n",
        "\n",
        "print('\\nUSDA descriptive stats:')\n",
        "print(USDA_clean.describe())\n",
        "print('\\nUSDA nulls:')\n",
        "print(USDA_clean.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp5_SFMq20tU",
        "outputId": "1ff6b7d4-c193-4e75-fd82-c48a28a3ef65"
      },
      "id": "rp5_SFMq20tU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "USDA descriptive stats:\n",
            "               YEAR      POP_2010     RUCC_2013      POP_2020     RUCC_2023  \\\n",
            "count  34573.000000  3.457300e+04  34573.000000  3.444100e+04  34441.000000   \n",
            "mean    2016.000000  9.823275e+04      5.007636  1.046987e+05      5.252954   \n",
            "std        3.162323  3.128559e+05      2.708120  3.353982e+05      2.927225   \n",
            "min     2011.000000  8.200000e+01      1.000000  6.400000e+01      1.000000   \n",
            "25%     2013.000000  1.109600e+04      2.000000  1.082900e+04      2.000000   \n",
            "50%     2016.000000  2.585700e+04      6.000000  2.565600e+04      6.000000   \n",
            "75%     2019.000000  6.686100e+04      7.000000  6.765400e+04      8.000000   \n",
            "max     2021.000000  9.818605e+06      9.000000  1.001401e+07      9.000000   \n",
            "\n",
            "       Amenity_score  Amenity_rank  Industry_type       Farming        Mining  \\\n",
            "count   34177.000000  34177.000000   34573.000000  34573.000000  34573.000000   \n",
            "mean        0.052359      3.491149       1.807827      0.161311      0.081451   \n",
            "std         2.277218      1.041867       1.819244      0.367823      0.273530   \n",
            "min        -6.400000      1.000000       0.000000      0.000000      0.000000   \n",
            "25%        -1.420000      3.000000       0.000000      0.000000      0.000000   \n",
            "50%        -0.140000      3.000000       1.000000      0.000000      0.000000   \n",
            "75%         1.090000      4.000000       3.000000      0.000000      0.000000   \n",
            "max        11.170000      7.000000       5.000000      1.000000      1.000000   \n",
            "\n",
            "             Mfging          Govt           Rec       Nonspec   Low_Ed_cnty  \\\n",
            "count  34573.000000  34573.000000  34573.000000  34573.000000  34573.000000   \n",
            "mean       0.164174      0.146675      0.136176      0.393573      0.148584   \n",
            "std        0.370439      0.353787      0.342980      0.488549      0.355683   \n",
            "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
            "75%        0.000000      0.000000      0.000000      1.000000      0.000000   \n",
            "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
            "\n",
            "       Low_emp_cnty  Pop_Loss_2010  Retire_dest_cnty  Persistent_Pov_cnty  \\\n",
            "count  34573.000000   34573.000000      34573.000000         34573.000000   \n",
            "mean       0.288260       0.168311          0.140630             0.112313   \n",
            "std        0.452959       0.374147          0.347644             0.315756   \n",
            "min        0.000000       0.000000          0.000000             0.000000   \n",
            "25%        0.000000       0.000000          0.000000             0.000000   \n",
            "50%        0.000000       0.000000          0.000000             0.000000   \n",
            "75%        1.000000       0.000000          0.000000             0.000000   \n",
            "max        1.000000       1.000000          1.000000             1.000000   \n",
            "\n",
            "       Pers_chld_pov_cnty  \n",
            "count        34573.000000  \n",
            "mean             0.225262  \n",
            "std              0.417761  \n",
            "min              0.000000  \n",
            "25%              0.000000  \n",
            "50%              0.000000  \n",
            "75%              0.000000  \n",
            "max              1.000000  \n",
            "\n",
            "USDA nulls:\n",
            "FIPS                     0\n",
            "YEAR                     0\n",
            "POP_2010                 0\n",
            "RUCC_2013                0\n",
            "POP_2020               132\n",
            "RUCC_2023              132\n",
            "Amenity_score          396\n",
            "Amenity_rank           396\n",
            "Industry_type            0\n",
            "Farming                  0\n",
            "Mining                   0\n",
            "Mfging                   0\n",
            "Govt                     0\n",
            "Rec                      0\n",
            "Nonspec                  0\n",
            "Low_Ed_cnty              0\n",
            "Low_emp_cnty             0\n",
            "Pop_Loss_2010            0\n",
            "Retire_dest_cnty         0\n",
            "Persistent_Pov_cnty      0\n",
            "Pers_chld_pov_cnty       0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "179da6f7",
        "outputId": "39c53002-081b-485c-9917-f6d1a1d8c4c0"
      },
      "source": [
        "# Fill Alaska and Hawaii Amenity variables\n",
        "USDA_clean['Amenity_score'] = USDA_clean['Amenity_score'].fillna(0)\n",
        "USDA_clean['Amenity_rank'] = USDA_clean['Amenity_rank'].fillna(0)\n",
        "\n",
        "# Impute missing 2020s data with 2010s data\n",
        "USDA_clean['POP_2020'] = USDA_clean[\n",
        "    'POP_2020'].fillna(USDA_clean['POP_2010'])\n",
        "USDA_clean['RUCC_2023'] = USDA_clean[\n",
        "    'RUCC_2023'].fillna(USDA_clean['RUCC_2013'])\n",
        "\n",
        "# Drop Kalawao, HI (15005)\n",
        "USDA_clean = USDA_clean[USDA_clean['FIPS'] != '15005'].copy()\n",
        "\n",
        "# Convert float64 columns to int64, excluding 'Amenity_score'\n",
        "float_cols_to_convert = USDA_clean.select_dtypes(\n",
        "    include='float64').columns.tolist()\n",
        "if 'Amenity_score' in float_cols_to_convert:\n",
        "    float_cols_to_convert.remove('Amenity_score')\n",
        "for col in float_cols_to_convert:\n",
        "    USDA_clean[col] = USDA_clean[col].astype('int64')\n",
        "\n",
        "print(USDA_clean.info())"
      ],
      "id": "179da6f7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 34562 entries, 0 to 35482\n",
            "Data columns (total 21 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   FIPS                 34562 non-null  object \n",
            " 1   YEAR                 34562 non-null  int64  \n",
            " 2   POP_2010             34562 non-null  int64  \n",
            " 3   RUCC_2013            34562 non-null  int64  \n",
            " 4   POP_2020             34562 non-null  int64  \n",
            " 5   RUCC_2023            34562 non-null  int64  \n",
            " 6   Amenity_score        34562 non-null  float64\n",
            " 7   Amenity_rank         34562 non-null  int64  \n",
            " 8   Industry_type        34562 non-null  int64  \n",
            " 9   Farming              34562 non-null  int64  \n",
            " 10  Mining               34562 non-null  int64  \n",
            " 11  Mfging               34562 non-null  int64  \n",
            " 12  Govt                 34562 non-null  int64  \n",
            " 13  Rec                  34562 non-null  int64  \n",
            " 14  Nonspec              34562 non-null  int64  \n",
            " 15  Low_Ed_cnty          34562 non-null  int64  \n",
            " 16  Low_emp_cnty         34562 non-null  int64  \n",
            " 17  Pop_Loss_2010        34562 non-null  int64  \n",
            " 18  Retire_dest_cnty     34562 non-null  int64  \n",
            " 19  Persistent_Pov_cnty  34562 non-null  int64  \n",
            " 20  Pers_chld_pov_cnty   34562 non-null  int64  \n",
            "dtypes: float64(1), int64(19), object(1)\n",
            "memory usage: 5.8+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IRS Inspection  \n",
        "in_FIPS that are an issue:  \n",
        "* xx000 = state totals, drop  \n",
        "* 15005, drop  \n",
        "\n",
        "out_fips:  \n",
        "* 57000-98000, drop"
      ],
      "metadata": {
        "id": "oSe_LpYO4RUy"
      },
      "id": "oSe_LpYO4RUy"
    },
    {
      "cell_type": "code",
      "source": [
        "#IRS_trim = pd.read_csv('IRS_import.csv')\n",
        "\n",
        "# Convert to integer for filtering\n",
        "IRS_trim['FIPS_int'] = pd.to_numeric(\n",
        "    IRS_trim['in_FIPS'], errors='coerce')\n",
        "IRS_trim['out_FIPS_int'] = pd.to_numeric(\n",
        "    IRS_trim['out_FIPS'], errors='coerce')\n",
        "\n",
        "# Keep Alaska (out_FIPS=97000, in_FIPS=02000) records ---\n",
        "# 1. Identify rows where out_FIPS is 97000 and in_FIPS is 02000\n",
        "mask_specific_records = (\n",
        "    IRS_trim['out_FIPS_int'] == 97000) & (IRS_trim['FIPS_int'] == 2000)\n",
        "print(f\"\\nNumber of records matching 97000->02000 before remapping: {mask_specific_records.sum()}\")\n",
        "\n",
        "# For these specific records, change in_FIPS to 02001\n",
        "IRS_trim.loc[mask_specific_records, 'FIPS_int'] = 2001\n",
        "print(f\"Number of records with in_FIPS=02001 after remapping: {(IRS_trim['FIPS_int'] == 2001).sum()}\")\n",
        "\n",
        "# Will use state values, drop all Alaska FIPS_int between 2011 and 2299\n",
        "alaska_range_drop = (IRS_trim['FIPS_int'] >= 2011) & (IRS_trim['FIPS_int'] < 2299)\n",
        "\n",
        "# Drop territories/foreign origins (57000-98000), but EXCLUDE the specific 97000->02001 flow\n",
        "foreign_origin = (IRS_trim['out_FIPS_int'] >= 57000) & ~((IRS_trim['out_FIPS_int'] == 97000) & (IRS_trim['FIPS_int'] == 2001))\n",
        "\n",
        "# Drop state totals (xx000), but keep 02000 and exclude the specific 97000->02001 flow\n",
        "state_totals_dest = (IRS_trim['FIPS_int'] % 1000 == 0) & (IRS_trim['FIPS_int'] != 2000)\n",
        "state_totals_origin = ((IRS_trim['out_FIPS_int'] % 1000 == 0) & (IRS_trim['out_FIPS_int'] != 2000)) & \\\n",
        "                      ~((IRS_trim['out_FIPS_int'] == 97000) & (IRS_trim['FIPS_int'] == 2001))\n",
        "\n",
        "# Drop non-movers (same origin and destination)\n",
        "non_movers = (IRS_trim['out_FIPS_int'] == IRS_trim['FIPS_int'])\n",
        "# Drop Kalawao, HI (15005)\n",
        "kalawao = (IRS_trim['FIPS_int'] == 15005)\n",
        "# Combined drop mask\n",
        "drop_mask = (state_totals_dest | state_totals_origin | alaska_range_drop |\n",
        "             kalawao | foreign_origin | non_movers)\n",
        "\n",
        "print(f\"Number of records dropped by combined mask: {drop_mask.sum()}\")\n",
        "\n",
        "IRS_inspect = IRS_trim[~drop_mask].copy()\n",
        "print(f\"Number of records with in_FIPS=02001 in IRS_inspect: {(IRS_inspect['FIPS_int'] == 2001).sum()}\")\n",
        "\n",
        "IRS_inspect['in_FIPS'] = IRS_inspect[\n",
        "    'FIPS_int'].astype(int).astype(str).str.zfill(5)\n",
        "IRS_inspect['out_FIPS'] = IRS_inspect[\n",
        "    'out_FIPS_int'].astype(int).astype(str).str.zfill(5)\n",
        "IRS_inspect = IRS_inspect.drop(columns=['FIPS_int', 'out_FIPS_int'])\n",
        "\n",
        "IRS_inspect.to_csv('IRS_inspect.csv', index=False)\n",
        "\n",
        "print('\\nIRS variable info:')\n",
        "print(IRS_inspect.info())\n",
        "print('\\nIRS descriptive stats:')\n",
        "print(IRS_inspect.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce-P4rcUOUk1",
        "outputId": "9b08efff-3846-4298-d512-dba853ecff92"
      },
      "id": "ce-P4rcUOUk1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of records matching 97000->02000 before remapping: 7\n",
            "Number of records with in_FIPS=02001 after remapping: 7\n",
            "Number of records dropped by combined mask: 423364\n",
            "Number of records with in_FIPS=02001 in IRS_inspect: 7\n",
            "\n",
            "IRS variable info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 625186 entries, 11 to 1048532\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count   Dtype  \n",
            "---  ------    --------------   -----  \n",
            " 0   out_FIPS  625186 non-null  object \n",
            " 1   in_FIPS   625186 non-null  object \n",
            " 2   YEAR      625186 non-null  int64  \n",
            " 3   Movers    625186 non-null  float64\n",
            " 4   agi       625184 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(2)\n",
            "memory usage: 28.6+ MB\n",
            "None\n",
            "\n",
            "IRS descriptive stats:\n",
            "                YEAR         Movers           agi\n",
            "count  625186.000000  625186.000000  6.251840e+05\n",
            "mean     2015.548355     195.571468  7.059314e+03\n",
            "std         3.366152     812.746995  3.490482e+04\n",
            "min      2011.000000      10.000000 -1.283400e+06\n",
            "25%      2012.000000      41.000000  1.071000e+03\n",
            "50%      2016.000000      65.000000  1.979000e+03\n",
            "75%      2019.000000     130.000000  4.271000e+03\n",
            "max      2021.000000   51368.000000  3.015639e+06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create 2 IRS datafiles:  \n",
        "* Create 'net_movers' to add to panel   \n",
        "* Keep one county-to-county for deeper flow analysis."
      ],
      "metadata": {
        "id": "pRq-fFj1kZC1"
      },
      "id": "pRq-fFj1kZC1"
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate net migration per county-year\n",
        "inflows = IRS_inspect.groupby(['in_FIPS', 'YEAR']).agg({\n",
        "    'Movers': 'sum',\n",
        "    'agi': 'sum'}).rename(columns={'Movers': 'move_in', 'agi': 'agi_in'})\n",
        "outflows = IRS_inspect.groupby(['out_FIPS', 'YEAR']).agg({\n",
        "    'Movers': 'sum',\n",
        "    'agi': 'sum'}).rename(columns={'Movers': 'move_out', 'agi': 'agi_out'})\n",
        "inflows.index.names = ['FIPS', 'YEAR']\n",
        "outflows.index.names = ['FIPS', 'YEAR']\n",
        "\n",
        "# Merge and calculate net\n",
        "IRS_clean = inflows.join(outflows, how='outer').fillna(0).reset_index()\n",
        "IRS_clean['net_movers'] = IRS_clean['move_in'] - IRS_clean['move_out']\n",
        "IRS_clean['net_agi'] = IRS_clean['agi_in'] - IRS_clean['agi_out']\n",
        "\n",
        "# Reorder\n",
        "cols = ['FIPS', 'YEAR', 'move_in', 'move_out', 'net_movers', 'agi_in', 'agi_out', 'net_agi']\n",
        "IRS_clean = IRS_clean[cols]\n",
        "\n",
        "# Display\n",
        "print(f\"  Panel rows: {len(IRS_clean):,}\")\n",
        "print(f\"  Unique counties: {IRS_clean['FIPS'].nunique():,}\")\n",
        "print(IRS_clean.head())\n",
        "\n",
        "IRS_clean = IRS_clean.drop(columns=[\n",
        "    'move_in', 'move_out',\n",
        "    'agi_in', 'agi_out'])\n",
        "# Save\n",
        "IRS_clean.to_csv('IRS_clean.csv', index=False)\n",
        "\n",
        "# Display change\n",
        "print(f\"  Saved IRS_clean.csv ({len(IRS_clean):,} rows)\")\n",
        "print(IRS_clean.info())"
      ],
      "metadata": {
        "id": "H9qvbQa0WH4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d04f69-0723-4b19-9936-36b7273dc6a9"
      },
      "id": "H9qvbQa0WH4f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Panel rows: 31,759\n",
            "  Unique counties: 3,081\n",
            "    FIPS  YEAR  move_in  move_out  net_movers   agi_in  agi_out  net_agi\n",
            "0  01001  2011   2799.0    2990.0      -191.0  47439.0  52984.0  -5545.0\n",
            "1  01001  2012   2795.0    2447.0       348.0  47844.0  42578.0   5266.0\n",
            "2  01001  2013   2148.0    2304.0      -156.0  38359.0  41002.0  -2643.0\n",
            "3  01001  2014   1794.0    1542.0       252.0  29566.0  28110.0   1456.0\n",
            "4  01001  2015   2109.0    1965.0       144.0  39484.0  42049.0  -2565.0\n",
            "  Saved IRS_clean.csv (31,759 rows)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 31759 entries, 0 to 31758\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   FIPS        31759 non-null  object \n",
            " 1   YEAR        31759 non-null  int64  \n",
            " 2   net_movers  31759 non-null  float64\n",
            " 3   net_agi     31759 non-null  float64\n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 992.6+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IRS_inspect = pd.read_csv('IRS_inspect.csv')\n",
        "IRS_dyadic = IRS_inspect[[\n",
        "    'out_FIPS', 'in_FIPS', 'YEAR', 'Movers', 'agi']].copy()\n",
        "IRS_dyadic = IRS_dyadic.rename(columns={\n",
        "    'Movers': 'N_movers',\n",
        "    'agi': 'AGI_movers'})\n",
        "\n",
        "# Save\n",
        "IRS_dyadic.to_csv('IRS_dyadic.csv', index=False)\n",
        "\n",
        "# Display\n",
        "print(f\"  Saved IRS_dyadic.csv ({len(IRS_dyadic):,} rows)\")\n",
        "print(IRS_dyadic.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEUA2rDqkSIh",
        "outputId": "73660e09-c1aa-468d-c68f-cb086b73b032"
      },
      "id": "WEUA2rDqkSIh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Saved IRS_dyadic.csv (625,186 rows)\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 625186 entries, 0 to 625185\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   out_FIPS    625186 non-null  int64  \n",
            " 1   in_FIPS     625186 non-null  int64  \n",
            " 2   YEAR        625186 non-null  int64  \n",
            " 3   N_movers    625186 non-null  float64\n",
            " 4   AGI_movers  625184 non-null  float64\n",
            "dtypes: float64(2), int64(3)\n",
            "memory usage: 23.8 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "BEA_clean.to_csv('BEA_clean.csv', index=False)\n",
        "BLS_clean.to_csv('BLS_clean.csv', index=False)\n",
        "Census_clean.to_csv('Census_clean.csv', index=False)\n",
        "IRS_clean.to_csv('IRS_clean.csv', index=False)\n",
        "USDA_clean.to_csv('USDA_clean.csv', index=False)"
      ],
      "metadata": {
        "id": "IDuFhLAehG88"
      },
      "id": "IDuFhLAehG88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "BEA_clean = pd.read_csv('BEA_clean.csv')\n",
        "BLS_clean = pd.read_csv('BLS_clean.csv')\n",
        "USDA_clean = pd.read_csv('USDA_clean.csv')\n",
        "Census_clean = pd.read_csv('Census_clean.csv')"
      ],
      "metadata": {
        "id": "JMUYPwT8aGVM"
      },
      "id": "JMUYPwT8aGVM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Extract Unique FIPS-YEAR Combinations\n",
        "bea_fips_year = set(tuple(row) for row in BEA_clean[['FIPS', 'YEAR']].drop_duplicates().to_numpy())\n",
        "bls_fips_year = set(tuple(row) for row in BLS_clean[['FIPS', 'YEAR']].drop_duplicates().to_numpy())\n",
        "census_fips_year = set(tuple(row) for row in Census_clean[['FIPS', 'YEAR']].drop_duplicates().to_numpy())\n",
        "usda_fips_year = set(tuple(row) for row in USDA_clean[['FIPS', 'YEAR']].drop_duplicates().to_numpy())\n",
        "\n",
        "# Create a comprehensive set of all unique ('FIPS', 'YEAR') combinations\n",
        "all_fips_year = bea_fips_year.union(bls_fips_year, census_fips_year, usda_fips_year)\n",
        "\n",
        "# 3. Compare FIPS-YEAR Combinations\n",
        "# Counts of unique FIPS-YEAR pairs for each dataset\n",
        "print(\"\\n--- Unique FIPS-YEAR Counts ---\")\n",
        "print(f\"BEA: {len(bea_fips_year):,} unique (FIPS, YEAR) pairs\")\n",
        "print(f\"BLS: {len(bls_fips_year):,} unique (FIPS, YEAR) pairs\")\n",
        "print(f\"Census: {len(census_fips_year):,} unique (FIPS, YEAR) pairs\")\n",
        "print(f\"USDA: {len(usda_fips_year):,} unique (FIPS, YEAR) pairs\")\n",
        "print(f\"Comprehensive (all datasets): {len(all_fips_year):,} unique (FIPS, YEAR) pairs\")\n",
        "\n",
        "# Compare against comprehensive set\n",
        "print(\"\\n--- Discrepancies vs. Comprehensive Set ---\")\n",
        "print(f\"BEA missing from all: {len(all_fips_year - bea_fips_year):,} pairs\")\n",
        "print(f\"BLS missing from all: {len(all_fips_year - bls_fips_year):,} pairs\")\n",
        "print(f\"Census missing from all: {len(all_fips_year - census_fips_year):,} pairs\")\n",
        "print(f\"USDA missing from all: {len(all_fips_year - usda_fips_year):,} pairs\")\n",
        "\n",
        "# Compare against USDA_clean\n",
        "print(\"\\n--- Discrepancies vs. USDA_clean ---\")\n",
        "print(f\"BEA pairs not in USDA: {len(bea_fips_year - usda_fips_year):,} pairs\")\n",
        "print(f\"USDA pairs not in BEA: {len(usda_fips_year - bea_fips_year):,} pairs\")\n",
        "print(f\"BLS pairs not in USDA: {len(bls_fips_year - usda_fips_year):,} pairs\")\n",
        "print(f\"USDA pairs not in BLS: {len(usda_fips_year - bls_fips_year):,} pairs\")\n",
        "print(f\"Census pairs not in USDA: {len(census_fips_year - usda_fips_year):,} pairs\")\n",
        "print(f\"USDA pairs not in Census: {len(usda_fips_year - census_fips_year):,} pairs\")\n",
        "\n",
        "# 4. Display Discrepancy Report\n",
        "print(\"\\n--- Detailed Discrepancy Report (FIPS-YEAR Combinations) ---\")\n",
        "\n",
        "data_sets = {\n",
        "    \"BEA\": bea_fips_year,\n",
        "    \"BLS\": bls_fips_year,\n",
        "    \"Census\": census_fips_year,\n",
        "    \"USDA\": usda_fips_year,\n",
        "}\n",
        "\n",
        "for name1, set1 in data_sets.items():\n",
        "    print(f\"\\nComparing {name1} (Total: {len(set1):,})\")\n",
        "    for name2, set2 in data_sets.items():\n",
        "        if name1 == name2:\n",
        "            continue\n",
        "        intersection = set1.intersection(set2)\n",
        "        diff1_not_in_2 = set1 - set2\n",
        "        diff2_not_in_1 = set2 - set1\n",
        "        print(f\"  vs {name2}:\")\n",
        "        print(f\"    - Overlap: {len(intersection):,} pairs\")\n",
        "        print(f\"    - {name1} has {len(diff1_not_in_2):,} pairs not in {name2}\")\n",
        "        print(f\"    - {name2} has {len(diff2_not_in_1):,} pairs not in {name1}\")\n",
        "\n",
        "print(\"\\n--- Summary of Unique FIPS-YEAR records per dataset ---\")\n",
        "for name, fips_year_set in data_sets.items():\n",
        "    print(f\"{name}: {len(fips_year_set):,} unique FIPS-YEAR combinations.\")\n",
        "\n",
        "print(f\"\\nTotal unique FIPS-YEAR combinations across all datasets: {len(all_fips_year):,}\")"
      ],
      "metadata": {
        "id": "-mnxoe2EzybU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f57fe87-9032-4f44-b7f1-f6f2d5d1db78"
      },
      "id": "-mnxoe2EzybU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unique FIPS-YEAR Counts ---\n",
            "BEA: 34,298 unique (FIPS, YEAR) pairs\n",
            "BLS: 34,465 unique (FIPS, YEAR) pairs\n",
            "Census: 34,556 unique (FIPS, YEAR) pairs\n",
            "USDA: 34,573 unique (FIPS, YEAR) pairs\n",
            "Comprehensive (all datasets): 34,903 unique (FIPS, YEAR) pairs\n",
            "\n",
            "--- Discrepancies vs. Comprehensive Set ---\n",
            "BEA missing from all: 605 pairs\n",
            "BLS missing from all: 438 pairs\n",
            "Census missing from all: 347 pairs\n",
            "USDA missing from all: 330 pairs\n",
            "\n",
            "--- Discrepancies vs. USDA_clean ---\n",
            "BEA pairs not in USDA: 330 pairs\n",
            "USDA pairs not in BEA: 605 pairs\n",
            "BLS pairs not in USDA: 26 pairs\n",
            "USDA pairs not in BLS: 134 pairs\n",
            "Census pairs not in USDA: 18 pairs\n",
            "USDA pairs not in Census: 35 pairs\n",
            "\n",
            "--- Detailed Discrepancy Report (FIPS-YEAR Combinations) ---\n",
            "\n",
            "Comparing BEA (Total: 34,298)\n",
            "  vs BLS:\n",
            "    - Overlap: 33,904 pairs\n",
            "    - BEA has 394 pairs not in BLS\n",
            "    - BLS has 561 pairs not in BEA\n",
            "  vs Census:\n",
            "    - Overlap: 33,984 pairs\n",
            "    - BEA has 314 pairs not in Census\n",
            "    - Census has 572 pairs not in BEA\n",
            "  vs USDA:\n",
            "    - Overlap: 33,968 pairs\n",
            "    - BEA has 330 pairs not in USDA\n",
            "    - USDA has 605 pairs not in BEA\n",
            "\n",
            "Comparing BLS (Total: 34,465)\n",
            "  vs BEA:\n",
            "    - Overlap: 33,904 pairs\n",
            "    - BLS has 561 pairs not in BEA\n",
            "    - BEA has 394 pairs not in BLS\n",
            "  vs Census:\n",
            "    - Overlap: 34,457 pairs\n",
            "    - BLS has 8 pairs not in Census\n",
            "    - Census has 99 pairs not in BLS\n",
            "  vs USDA:\n",
            "    - Overlap: 34,439 pairs\n",
            "    - BLS has 26 pairs not in USDA\n",
            "    - USDA has 134 pairs not in BLS\n",
            "\n",
            "Comparing Census (Total: 34,556)\n",
            "  vs BEA:\n",
            "    - Overlap: 33,984 pairs\n",
            "    - Census has 572 pairs not in BEA\n",
            "    - BEA has 314 pairs not in Census\n",
            "  vs BLS:\n",
            "    - Overlap: 34,457 pairs\n",
            "    - Census has 99 pairs not in BLS\n",
            "    - BLS has 8 pairs not in Census\n",
            "  vs USDA:\n",
            "    - Overlap: 34,538 pairs\n",
            "    - Census has 18 pairs not in USDA\n",
            "    - USDA has 35 pairs not in Census\n",
            "\n",
            "Comparing USDA (Total: 34,573)\n",
            "  vs BEA:\n",
            "    - Overlap: 33,968 pairs\n",
            "    - USDA has 605 pairs not in BEA\n",
            "    - BEA has 330 pairs not in USDA\n",
            "  vs BLS:\n",
            "    - Overlap: 34,439 pairs\n",
            "    - USDA has 134 pairs not in BLS\n",
            "    - BLS has 26 pairs not in USDA\n",
            "  vs Census:\n",
            "    - Overlap: 34,538 pairs\n",
            "    - USDA has 35 pairs not in Census\n",
            "    - Census has 18 pairs not in USDA\n",
            "\n",
            "--- Summary of Unique FIPS-YEAR records per dataset ---\n",
            "BEA: 34,298 unique FIPS-YEAR combinations.\n",
            "BLS: 34,465 unique FIPS-YEAR combinations.\n",
            "Census: 34,556 unique FIPS-YEAR combinations.\n",
            "USDA: 34,573 unique FIPS-YEAR combinations.\n",
            "\n",
            "Total unique FIPS-YEAR combinations across all datasets: 34,903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8671f91e"
      },
      "source": [
        "Problem FIPS from discrepancy list\n"
      ],
      "id": "8671f91e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ecf3dfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37676a58-67bf-4b3c-c26d-2388bcb33f31"
      },
      "source": [
        "'''\n",
        "# Identify missing FIPS-YEAR pairs for each dataset (excluding IRS)\n",
        "bea_missing_pairs = all_fips_year - bea_fips_year\n",
        "bls_missing_pairs = all_fips_year - bls_fips_year\n",
        "census_missing_pairs = all_fips_year - census_fips_year\n",
        "usda_missing_pairs = all_fips_year - usda_fips_year\n",
        "\n",
        "# Extract unique FIPS codes from these missing pairs\n",
        "unique_fips_bea_missing = sorted(list(set([fips_year[0] for fips_year in bea_missing_pairs])))\n",
        "unique_fips_bls_missing = sorted(list(set([fips_year[0] for fips_year in bls_missing_pairs])))\n",
        "unique_fips_census_missing = sorted(list(set([fips_year[0] for fips_year in census_missing_pairs])))\n",
        "unique_fips_usda_missing = sorted(list(set([fips_year[0] for fips_year in usda_missing_pairs])))\n",
        "\n",
        "print(\"\\n--- Unique FIPS from Discrepancies (ignoring IRS) ---\")\n",
        "print(f\"FIPS present in comprehensive set but missing from BEA: {len(unique_fips_bea_missing)} unique FIPS\")\n",
        "print(f\"  {unique_fips_bea_missing}\")\n",
        "print(f\"FIPS present in comprehensive set but missing from BLS: {len(unique_fips_bls_missing)} unique FIPS\")\n",
        "print(f\"  {unique_fips_bls_missing}\")\n",
        "print(f\"FIPS present in comprehensive set but missing from Census: {len(unique_fips_census_missing)} unique FIPS\")\n",
        "print(f\"  {unique_fips_census_missing}\")\n",
        "print(f\"FIPS present in comprehensive set but missing from USDA: {len(unique_fips_usda_missing)} unique FIPS\")\n",
        "print(f\"  {unique_fips_usda_missing}\")\n"
      ],
      "id": "5ecf3dfd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Unique FIPS from Discrepancies (ignoring IRS) ---\n",
            "FIPS present in comprehensive set but missing from BEA: 55 unique FIPS\n",
            "  ['02270', '15005', '46113', '51003', '51005', '51015', '51031', '51035', '51053', '51059', '51069', '51081', '51089', '51095', '51121', '51143', '51149', '51153', '51161', '51163', '51165', '51175', '51177', '51191', '51195', '51199', '51515', '51520', '51530', '51540', '51570', '51580', '51590', '51595', '51600', '51610', '51620', '51630', '51640', '51660', '51670', '51678', '51680', '51683', '51685', '51690', '51720', '51730', '51735', '51750', '51775', '51790', '51820', '51830', '51840']\n",
            "FIPS present in comprehensive set but missing from BLS: 41 unique FIPS\n",
            "  ['02063', '02066', '02201', '02232', '02261', '02270', '02280', '09001', '09003', '09005', '09007', '09009', '09011', '09013', '09015', '15005', '46113', '51515', '51901', '51903', '51907', '51911', '51913', '51918', '51919', '51921', '51923', '51929', '51931', '51933', '51939', '51941', '51942', '51944', '51945', '51947', '51949', '51951', '51953', '51955', '51958']\n",
            "FIPS present in comprehensive set but missing from Census: 35 unique FIPS\n",
            "  ['02063', '02066', '02158', '02201', '02232', '02261', '02270', '02280', '15005', '46102', '46113', '51515', '51901', '51903', '51907', '51911', '51913', '51918', '51919', '51921', '51923', '51929', '51931', '51933', '51939', '51941', '51942', '51944', '51945', '51947', '51949', '51951', '51953', '51955', '51958']\n",
            "FIPS present in comprehensive set but missing from USDA: 30 unique FIPS\n",
            "  ['02063', '02066', '02158', '02201', '02232', '02280', '46102', '51901', '51903', '51907', '51911', '51913', '51918', '51919', '51921', '51923', '51929', '51931', '51933', '51939', '51941', '51942', '51944', '51945', '51947', '51949', '51951', '51953', '51955', '51958']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "print(BEA_clean.info())\n",
        "print(BLS_clean.info())\n",
        "print(Census_clean.info())\n",
        "print(USDA_clean.info())"
      ],
      "metadata": {
        "id": "Nt7RFGMi7fJZ"
      },
      "id": "Nt7RFGMi7fJZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incentives Inspection  \n",
        "Remove variables that will not be utilized in regression analysis"
      ],
      "metadata": {
        "id": "XkH22GS5KT0K"
      },
      "id": "XkH22GS5KT0K"
    },
    {
      "cell_type": "code",
      "source": [
        "Incentive_import = pd.read_csv('Incentives.csv')\n",
        "\n",
        "Incentive_import['FIPS'] = Incentive_import['FIPS'].astype(str).str.zfill(5)\n",
        " # Inspect\n",
        "print(Incentive_import.info())\n",
        "\n",
        "# Clean for Merge\n",
        "Incentive_clean = Incentive_import.copy()\n",
        "Incentive_clean = Incentive_clean[['FIPS', 'YEAR', 'Incentive_CAT']]\n",
        "\n",
        "print(Incentive_clean.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDO1h8I3pPuR",
        "outputId": "dff2886a-4016-4fea-aeb0-1938d919d7b3"
      },
      "id": "IDO1h8I3pPuR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5160 entries, 0 to 5159\n",
            "Data columns (total 9 columns):\n",
            " #   Column                            Non-Null Count  Dtype \n",
            "---  ------                            --------------  ----- \n",
            " 0   FIPS                              5160 non-null   object\n",
            " 1   YEAR                              5160 non-null   int64 \n",
            " 2   State                             5160 non-null   object\n",
            " 3   County                            5153 non-null   object\n",
            " 4   Program                           5160 non-null   object\n",
            " 5   Category                          5157 non-null   object\n",
            " 6   Benefit Type                      5157 non-null   object\n",
            " 7   Funding Level / Amount (Approx.)  5160 non-null   object\n",
            " 8   Incentive_CAT                     5160 non-null   int64 \n",
            "dtypes: int64(2), object(7)\n",
            "memory usage: 362.9+ KB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5160 entries, 0 to 5159\n",
            "Data columns (total 3 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   FIPS           5160 non-null   object\n",
            " 1   YEAR           5160 non-null   int64 \n",
            " 2   Incentive_CAT  5160 non-null   int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 121.1+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge datafiles into Migration panel  \n",
        "\n",
        "Combine all cleaned dataframes (`BEA_clean`, `BLS_clean`, `Census_clean`, `IRS_clean`, `USDA_clean`, and `Incentive_clean`) into a single DataFrame named `migration_df` by performing a series of outer merges on 'FIPS' and 'YEAR'."
      ],
      "metadata": {
        "id": "VVwlFKrYKqgb"
      },
      "id": "VVwlFKrYKqgb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f09dc94b",
        "outputId": "1f316f09-7ea4-4842-e78e-aa16de375b16"
      },
      "source": [
        "BEA_clean['FIPS'] = BEA_clean['FIPS'].astype(str).str.zfill(5)\n",
        "BLS_clean['FIPS'] = BLS_clean['FIPS'].astype(str).str.zfill(5)\n",
        "Census_clean['FIPS'] = Census_clean['FIPS'].astype(str).str.zfill(5)\n",
        "IRS_clean['FIPS'] = IRS_clean['FIPS'].astype(str).str.zfill(5)\n",
        "USDA_clean['FIPS'] = USDA_clean['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# Perform a series of outer merges\n",
        "migration_df = pd.merge(\n",
        "    Census_clean, USDA_clean, on=['FIPS', 'YEAR'], how='outer')\n",
        "migration_df = pd.merge(\n",
        "    migration_df, BLS_clean, on=['FIPS', 'YEAR'], how='outer')\n",
        "migration_df = pd.merge(\n",
        "    migration_df, BEA_clean[['FIPS', 'YEAR', 'BEA_pci', 'BEA_gdp', 'RPP']], on=['FIPS', 'YEAR'], how='left')\n",
        "migration_df = pd.merge(\n",
        "    migration_df, IRS_clean, on=['FIPS', 'YEAR'], how='outer')\n",
        "\n",
        "print('Migration DataFrame created successfully.')\n",
        "print(migration_df.isnull().sum())\n",
        "\n",
        "# migration_df.to_csv('migration_df.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FIPS                   0\n",
            "YEAR                   0\n",
            "total_population       0\n",
            "median_age             0\n",
            "housing_total          0\n",
            "                    ... \n",
            "BEA_pci              561\n",
            "BEA_gdp              561\n",
            "RPP                  561\n",
            "net_movers          2576\n",
            "net_agi             2576\n",
            "Length: 86, dtype: int64\n"
          ]
        }
      ],
      "id": "f09dc94b"
    },
    {
      "cell_type": "code",
      "source": [
        "Incentive_clean = pd.read_csv('Incentives.csv')\n",
        "Incentive_clean['FIPS'] = Incentive_clean['FIPS'].astype(str).str.zfill(5)\n",
        "Incentive_clean = Incentive_clean[['FIPS', 'YEAR', 'Incentive_CAT']]\n",
        "\n",
        "migration_df = pd.merge(migration_df, Incentive_clean, on=['FIPS', 'YEAR'], how='outer')\n"
      ],
      "metadata": {
        "id": "ovt-hWnTk50Y"
      },
      "id": "ovt-hWnTk50Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merged Inspection  \n",
        "Combine 02xxx (Make All Alaska one record)  \n",
        "Change '15901' to '15009'  \n",
        "remove '15005'  \n",
        "Change '46102' to '46113'\n"
      ],
      "metadata": {
        "id": "Oh6vI6INKDAJ"
      },
      "id": "Oh6vI6INKDAJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3881dc48",
        "outputId": "70a4e0a4-ed38-43ea-fe6a-32a7bcd324ab"
      },
      "source": [
        "# 1. Drop specific FIPS codes\n",
        "fips_to_drop = ['46113', '51515', '97000']\n",
        "\n",
        "# Add the range 09110-09190\n",
        "for i in range(9110, 9191):\n",
        "    fips_to_drop.append(f'0{i}')\n",
        "\n",
        "original_rows = len(migration_df)\n",
        "migration_df = migration_df[~migration_df['FIPS'].isin(fips_to_drop)].copy()\n",
        "print(f\"Dropped {original_rows - len(migration_df)} rows corresponding to FIPS codes: {fips_to_drop}\")\n",
        "\n",
        "# 2. Fill '48261' median_home_value with average 2011-2015\n",
        "fips_48261_mask = (migration_df['FIPS'] == '48261')\n",
        "# Calculate average for median_home_value (2011-2015)\n",
        "avg_mhv_48261_2011_2015 = migration_df[fips_48261_mask & (migration_df['YEAR'].between(2011, 2015))]['median_home_value'].mean()\n",
        "# Fill any NaNs in the specified period with this average\n",
        "migration_df.loc[fips_48261_mask & (migration_df['YEAR'].between(2011, 2015)), 'median_home_value'] = migration_df.loc[fips_48261_mask & (migration_df['YEAR'].between(2011, 2015)), 'median_home_value'].fillna(avg_mhv_48261_2011_2015)\n",
        "print(f\"Filled median_home_value for FIPS '48261' (2011-2015) with average: {avg_mhv_48261_2011_2015:.2f}\")\n",
        "\n",
        "# 3. Re-run fix for FIPS '35039' (Rio Arriba, NM) - fill 2018 NaNs with avg of 2017 and 2019\n",
        "fips_35039_mask = (migration_df['FIPS'] == '35039')\n",
        "rows_2018_35039 = migration_df[fips_35039_mask & (migration_df['YEAR'] == 2018)]\n",
        "\n",
        "if not rows_2018_35039.empty:\n",
        "    # Iterate through all columns in the 2018 row to find NaNs\n",
        "    for col in rows_2018_35039.columns:\n",
        "        if rows_2018_35039[col].isnull().any():\n",
        "            val_2017 = migration_df[fips_35039_mask & (migration_df['YEAR'] == 2017)][col].iloc[0] if not migration_df[fips_35039_mask & (migration_df['YEAR'] == 2017)].empty else np.nan\n",
        "            val_2019 = migration_df[fips_35039_mask & (migration_df['YEAR'] == 2019)][col].iloc[0] if not migration_df[fips_35039_mask & (migration_df['YEAR'] == 2019)].empty else np.nan\n",
        "\n",
        "            if pd.notna(val_2017) and pd.notna(val_2019):\n",
        "                imputed_value = (val_2017 + val_2019) / 2\n",
        "                migration_df.loc[fips_35039_mask & (migration_df['YEAR'] == 2018), col] = imputed_value\n",
        "                print(f\"Filled NaN in column '{col}' for FIPS '35039' in 2018 with {imputed_value:.2f}\")\n",
        "\n",
        "\n",
        "print('\\n--- Cleaning steps applied. Re-running final inspection ---')\n",
        "\n",
        "# Re-run the final inspection to confirm changes\n",
        "print('\\nMigration DataFrame Info:')\n",
        "print(migration_df.info())\n",
        "\n",
        "print('\\nMigration DataFrame Head:')\n",
        "display(migration_df.head())\n",
        "\n",
        "print('\\nMigration DataFrame Descriptive Statistics:')\n",
        "display(migration_df.describe())\n",
        "\n",
        "print('\\nMigration DataFrame Null Values:')\n",
        "display(migration_df.isnull().sum().sort_values(ascending=False))"
      ],
      "id": "3881dc48",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dropped 42 rows corresponding to FIPS codes: ['46113', '51515', '97000', '09110', '09111', '09112', '09113', '09114', '09115', '09116', '09117', '09118', '09119', '09120', '09121', '09122', '09123', '09124', '09125', '09126', '09127', '09128', '09129', '09130', '09131', '09132', '09133', '09134', '09135', '09136', '09137', '09138', '09139', '09140', '09141', '09142', '09143', '09144', '09145', '09146', '09147', '09148', '09149', '09150', '09151', '09152', '09153', '09154', '09155', '09156', '09157', '09158', '09159', '09160', '09161', '09162', '09163', '09164', '09165', '09166', '09167', '09168', '09169', '09170', '09171', '09172', '09173', '09174', '09175', '09176', '09177', '09178', '09179', '09180', '09181', '09182', '09183', '09184', '09185', '09186', '09187', '09188', '09189', '09190']\n",
            "Filled median_home_value for FIPS '48261' (2011-2015) with average: 56051.43\n",
            "Filled NaN in column 'median_hh_income' for FIPS '35039' in 2018 with 36687.00\n",
            "Filled NaN in column 'employed' for FIPS '35039' in 2018 with 13944.50\n",
            "Filled NaN in column 'unemployed' for FIPS '35039' in 2018 with 1275.50\n",
            "Filled NaN in column 'not_in_labor_force' for FIPS '35039' in 2018 with 15906.50\n",
            "Filled NaN in column 'commute_less_5min' for FIPS '35039' in 2018 with 631.00\n",
            "Filled NaN in column 'commute_5_9min' for FIPS '35039' in 2018 with 1532.00\n",
            "Filled NaN in column 'commute_10_14min' for FIPS '35039' in 2018 with 1555.50\n",
            "Filled NaN in column 'commute_15_19min' for FIPS '35039' in 2018 with 1212.00\n",
            "Filled NaN in column 'commute_20_24min' for FIPS '35039' in 2018 with 981.00\n",
            "Filled NaN in column 'commute_25_29min' for FIPS '35039' in 2018 with 316.50\n",
            "Filled NaN in column 'commute_30_34min' for FIPS '35039' in 2018 with 2438.50\n",
            "Filled NaN in column 'commute_35_39min' for FIPS '35039' in 2018 with 374.50\n",
            "Filled NaN in column 'commute_40_44min' for FIPS '35039' in 2018 with 1146.50\n",
            "Filled NaN in column 'commute_45_59min' for FIPS '35039' in 2018 with 2094.00\n",
            "Filled NaN in column 'commute_60_89min' for FIPS '35039' in 2018 with 747.00\n",
            "Filled NaN in column 'commute_90_plus_min' for FIPS '35039' in 2018 with 269.00\n",
            "Filled NaN in column 'work_in_owned_home' for FIPS '35039' in 2018 with 329.50\n",
            "Filled NaN in column 'work_in_rental' for FIPS '35039' in 2018 with 53.50\n",
            "Filled NaN in column 'occupation_total' for FIPS '35039' in 2018 with 13944.50\n",
            "Filled NaN in column 'Mgmt_Biz_Sci_Arts' for FIPS '35039' in 2018 with 5263.50\n",
            "Filled NaN in column 'Services' for FIPS '35039' in 2018 with 3317.00\n",
            "Filled NaN in column 'Sales_Admin' for FIPS '35039' in 2018 with 3107.00\n",
            "Filled NaN in column 'Nat-rsrc_Constr_Maint' for FIPS '35039' in 2018 with 1193.50\n",
            "Filled NaN in column 'Prod_Transp_Mvng' for FIPS '35039' in 2018 with 1063.50\n",
            "\n",
            "--- Cleaning steps applied. Re-running final inspection ---\n",
            "\n",
            "Migration DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 34232 entries, 0 to 34273\n",
            "Data columns (total 86 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   FIPS                   34232 non-null  object \n",
            " 1   YEAR                   34232 non-null  int64  \n",
            " 2   total_population       34232 non-null  float64\n",
            " 3   median_age             34232 non-null  float64\n",
            " 4   housing_total          34232 non-null  float64\n",
            " 5   vacant                 34232 non-null  float64\n",
            " 6   median_home_value      34229 non-null  float64\n",
            " 7   family_households      34232 non-null  float64\n",
            " 8   marital_total          34232 non-null  float64\n",
            " 9   under_18_in_hh         34232 non-null  float64\n",
            " 10  education_total_sex    34232 non-null  float64\n",
            " 11  median_hh_income       34232 non-null  float64\n",
            " 12  employed               34232 non-null  float64\n",
            " 13  unemployed             34232 non-null  float64\n",
            " 14  not_in_labor_force     34232 non-null  float64\n",
            " 15  commute_less_5min      34232 non-null  float64\n",
            " 16  commute_5_9min         34232 non-null  float64\n",
            " 17  commute_10_14min       34232 non-null  float64\n",
            " 18  commute_15_19min       34232 non-null  float64\n",
            " 19  commute_20_24min       34232 non-null  float64\n",
            " 20  commute_25_29min       34232 non-null  float64\n",
            " 21  commute_30_34min       34232 non-null  float64\n",
            " 22  commute_35_39min       34232 non-null  float64\n",
            " 23  commute_40_44min       34232 non-null  float64\n",
            " 24  commute_45_59min       34232 non-null  float64\n",
            " 25  commute_60_89min       34232 non-null  float64\n",
            " 26  commute_90_plus_min    34232 non-null  float64\n",
            " 27  work_in_owned_home     34232 non-null  float64\n",
            " 28  work_in_rental         34232 non-null  float64\n",
            " 29  median_property_taxes  34224 non-null  float64\n",
            " 30  occupation_total       34232 non-null  float64\n",
            " 31  Mgmt_Biz_Sci_Arts      34232 non-null  float64\n",
            " 32  Services               34232 non-null  float64\n",
            " 33  Sales_Admin            34232 non-null  float64\n",
            " 34  Nat-rsrc_Constr_Maint  34232 non-null  float64\n",
            " 35  Prod_Transp_Mvng       34232 non-null  float64\n",
            " 36  %owner_occupied        34232 non-null  float64\n",
            " 37  %renter_occupied       34232 non-null  float64\n",
            " 38  %never_married_male    34232 non-null  float64\n",
            " 39  %now_married_male      34232 non-null  float64\n",
            " 40  %divorced_male         34232 non-null  float64\n",
            " 41  %widowed_male          34232 non-null  float64\n",
            " 42  %never_married_female  34232 non-null  float64\n",
            " 43  %now_married_female    34232 non-null  float64\n",
            " 44  %divorced_female       34232 non-null  float64\n",
            " 45  %widowed_female        34232 non-null  float64\n",
            " 46  %white                 34232 non-null  float64\n",
            " 47  %black                 34232 non-null  float64\n",
            " 48  %native                34232 non-null  float64\n",
            " 49  %asian                 34232 non-null  float64\n",
            " 50  %pacific_islander      34232 non-null  float64\n",
            " 51  %other_race            34232 non-null  float64\n",
            " 52  %mixed_non_h           34232 non-null  float64\n",
            " 53  %hispanic              34232 non-null  float64\n",
            " 54  complete_hs            34232 non-null  float64\n",
            " 55  some_college           34232 non-null  float64\n",
            " 56  associates             34232 non-null  float64\n",
            " 57  bachelors              34232 non-null  float64\n",
            " 58  masters                34232 non-null  float64\n",
            " 59  professional           34232 non-null  float64\n",
            " 60  doctorate              34232 non-null  float64\n",
            " 61  POP_2010               34232 non-null  float64\n",
            " 62  RUCC_2013              34232 non-null  float64\n",
            " 63  POP_2020               34232 non-null  float64\n",
            " 64  RUCC_2023              34232 non-null  float64\n",
            " 65  Amenity_score          34232 non-null  float64\n",
            " 66  Amenity_rank           34232 non-null  float64\n",
            " 67  Industry_type          34232 non-null  float64\n",
            " 68  Farming                34232 non-null  float64\n",
            " 69  Mining                 34232 non-null  float64\n",
            " 70  Mfging                 34232 non-null  float64\n",
            " 71  Govt                   34232 non-null  float64\n",
            " 72  Rec                    34232 non-null  float64\n",
            " 73  Nonspec                34232 non-null  float64\n",
            " 74  Low_Ed_cnty            34232 non-null  float64\n",
            " 75  Low_emp_cnty           34232 non-null  float64\n",
            " 76  Pop_Loss_2010          34232 non-null  float64\n",
            " 77  Retire_dest_cnty       34232 non-null  float64\n",
            " 78  Persistent_Pov_cnty    34232 non-null  float64\n",
            " 79  Pers_chld_pov_cnty     34232 non-null  float64\n",
            " 80  unemploy_rate          34144 non-null  float64\n",
            " 81  BEA_pci                33671 non-null  float64\n",
            " 82  BEA_gdp                33671 non-null  float64\n",
            " 83  RPP                    33671 non-null  float64\n",
            " 84  net_movers             31656 non-null  float64\n",
            " 85  net_agi                31656 non-null  float64\n",
            "dtypes: float64(84), int64(1), object(1)\n",
            "memory usage: 22.7+ MB\n",
            "None\n",
            "\n",
            "Migration DataFrame Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    FIPS  YEAR  total_population  median_age  housing_total  vacant  \\\n",
              "0  01001  2011           53944.0        36.4        19998.0  1861.0   \n",
              "1  01001  2012           54590.0        37.0        19934.0  2143.0   \n",
              "2  01001  2013           54907.0        37.5        20071.0  2149.0   \n",
              "3  01001  2014           55136.0        37.9        20304.0  2127.0   \n",
              "4  01001  2015           55221.0        37.7        20396.0  2186.0   \n",
              "\n",
              "   median_home_value  family_households  marital_total  under_18_in_hh  ...  \\\n",
              "0           137500.0            14631.0        42072.0         14708.0  ...   \n",
              "1           137900.0            14258.0        42705.0         14637.0  ...   \n",
              "2           136200.0            14132.0        43115.0         14392.0  ...   \n",
              "3           136600.0            14272.0        43469.0         14214.0  ...   \n",
              "4           141300.0            14213.0        43775.0         14044.0  ...   \n",
              "\n",
              "   Pop_Loss_2010  Retire_dest_cnty  Persistent_Pov_cnty  Pers_chld_pov_cnty  \\\n",
              "0            0.0               1.0                  0.0                 0.0   \n",
              "1            0.0               1.0                  0.0                 0.0   \n",
              "2            0.0               1.0                  0.0                 0.0   \n",
              "3            0.0               1.0                  0.0                 0.0   \n",
              "4            0.0               1.0                  0.0                 0.0   \n",
              "\n",
              "   unemploy_rate  BEA_pci    BEA_gdp     RPP  net_movers  net_agi  \n",
              "0            8.3  34430.0  1493906.0  91.098      -191.0  -5545.0  \n",
              "1            7.1  35151.0  1726577.0  93.269       348.0   5266.0  \n",
              "2            6.3  35348.0  1618151.0  91.394      -156.0  -2643.0  \n",
              "3            5.8  36329.0  1629762.0  90.675       252.0   1456.0  \n",
              "4            5.2  38107.0  1765826.0  90.622       144.0  -2565.0  \n",
              "\n",
              "[5 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85d90bd5-7c0b-43d9-822f-1b8eed91e4fb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIPS</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>total_population</th>\n",
              "      <th>median_age</th>\n",
              "      <th>housing_total</th>\n",
              "      <th>vacant</th>\n",
              "      <th>median_home_value</th>\n",
              "      <th>family_households</th>\n",
              "      <th>marital_total</th>\n",
              "      <th>under_18_in_hh</th>\n",
              "      <th>...</th>\n",
              "      <th>Pop_Loss_2010</th>\n",
              "      <th>Retire_dest_cnty</th>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <th>unemploy_rate</th>\n",
              "      <th>BEA_pci</th>\n",
              "      <th>BEA_gdp</th>\n",
              "      <th>RPP</th>\n",
              "      <th>net_movers</th>\n",
              "      <th>net_agi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01001</td>\n",
              "      <td>2011</td>\n",
              "      <td>53944.0</td>\n",
              "      <td>36.4</td>\n",
              "      <td>19998.0</td>\n",
              "      <td>1861.0</td>\n",
              "      <td>137500.0</td>\n",
              "      <td>14631.0</td>\n",
              "      <td>42072.0</td>\n",
              "      <td>14708.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>34430.0</td>\n",
              "      <td>1493906.0</td>\n",
              "      <td>91.098</td>\n",
              "      <td>-191.0</td>\n",
              "      <td>-5545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01001</td>\n",
              "      <td>2012</td>\n",
              "      <td>54590.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>19934.0</td>\n",
              "      <td>2143.0</td>\n",
              "      <td>137900.0</td>\n",
              "      <td>14258.0</td>\n",
              "      <td>42705.0</td>\n",
              "      <td>14637.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>35151.0</td>\n",
              "      <td>1726577.0</td>\n",
              "      <td>93.269</td>\n",
              "      <td>348.0</td>\n",
              "      <td>5266.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01001</td>\n",
              "      <td>2013</td>\n",
              "      <td>54907.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>20071.0</td>\n",
              "      <td>2149.0</td>\n",
              "      <td>136200.0</td>\n",
              "      <td>14132.0</td>\n",
              "      <td>43115.0</td>\n",
              "      <td>14392.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>35348.0</td>\n",
              "      <td>1618151.0</td>\n",
              "      <td>91.394</td>\n",
              "      <td>-156.0</td>\n",
              "      <td>-2643.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01001</td>\n",
              "      <td>2014</td>\n",
              "      <td>55136.0</td>\n",
              "      <td>37.9</td>\n",
              "      <td>20304.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>136600.0</td>\n",
              "      <td>14272.0</td>\n",
              "      <td>43469.0</td>\n",
              "      <td>14214.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>36329.0</td>\n",
              "      <td>1629762.0</td>\n",
              "      <td>90.675</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1456.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01001</td>\n",
              "      <td>2015</td>\n",
              "      <td>55221.0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>20396.0</td>\n",
              "      <td>2186.0</td>\n",
              "      <td>141300.0</td>\n",
              "      <td>14213.0</td>\n",
              "      <td>43775.0</td>\n",
              "      <td>14044.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>38107.0</td>\n",
              "      <td>1765826.0</td>\n",
              "      <td>90.622</td>\n",
              "      <td>144.0</td>\n",
              "      <td>-2565.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85d90bd5-7c0b-43d9-822f-1b8eed91e4fb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85d90bd5-7c0b-43d9-822f-1b8eed91e4fb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85d90bd5-7c0b-43d9-822f-1b8eed91e4fb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a666fed6-7e4e-434f-8992-5fd80a8c9fdd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a666fed6-7e4e-434f-8992-5fd80a8c9fdd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a666fed6-7e4e-434f-8992-5fd80a8c9fdd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migration DataFrame Descriptive Statistics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               YEAR  total_population    median_age  housing_total  \\\n",
              "count  34232.000000      3.423200e+04  34232.000000   3.423200e+04   \n",
              "mean    2016.000000      1.022781e+05     40.994070   3.803719e+04   \n",
              "std        3.162324      3.257760e+05      5.273044   1.147825e+05   \n",
              "min     2011.000000      6.200000e+01     21.400000   2.700000e+01   \n",
              "25%     2013.000000      1.120350e+04     37.900000   4.314750e+03   \n",
              "50%     2016.000000      2.600200e+04     40.900000   9.967500e+03   \n",
              "75%     2019.000000      6.814325e+04     44.000000   2.612200e+04   \n",
              "max     2021.000000      1.010572e+07     68.100000   3.342811e+06   \n",
              "\n",
              "              vacant  median_home_value  family_households  marital_total  \\\n",
              "count   34232.000000       3.422900e+04       3.423200e+04   3.423200e+04   \n",
              "mean     5259.126548       1.423021e+05       2.507476e+04   8.266592e+04   \n",
              "std     13028.854824       8.839044e+04       7.509575e+04   2.626099e+05   \n",
              "min        17.000000       2.130000e+04       1.500000e+01   5.200000e+01   \n",
              "25%       945.000000       8.890000e+04       2.889000e+03   9.122000e+03   \n",
              "50%      2003.000000       1.181000e+05       6.721500e+03   2.127300e+04   \n",
              "75%      4602.000000       1.640000e+05       1.744050e+04   5.532775e+04   \n",
              "max    245069.000000       1.225900e+06       2.216821e+06   8.246401e+06   \n",
              "\n",
              "       under_18_in_hh  education_total_sex  ...  Pop_Loss_2010  \\\n",
              "count    3.423200e+04         3.423200e+04  ...   34232.000000   \n",
              "mean     2.362357e+04         6.866025e+04  ...       0.168706   \n",
              "std      7.660182e+04         2.178339e+05  ...       0.374492   \n",
              "min      0.000000e+00         5.200000e+01  ...       0.000000   \n",
              "25%      2.495000e+03         7.755000e+03  ...       0.000000   \n",
              "50%      5.911500e+03         1.788750e+04  ...       0.000000   \n",
              "75%      1.529725e+04         4.593650e+04  ...       0.000000   \n",
              "max      2.421031e+06         6.922061e+06  ...       1.000000   \n",
              "\n",
              "       Retire_dest_cnty  Persistent_Pov_cnty  Pers_chld_pov_cnty  \\\n",
              "count      34232.000000         34232.000000        34232.000000   \n",
              "mean           0.141753             0.112472            0.225593   \n",
              "std            0.348748             0.315945            0.417962   \n",
              "min            0.000000             0.000000            0.000000   \n",
              "25%            0.000000             0.000000            0.000000   \n",
              "50%            0.000000             0.000000            0.000000   \n",
              "75%            0.000000             0.000000            0.000000   \n",
              "max            1.000000             1.000000            1.000000   \n",
              "\n",
              "       unemploy_rate        BEA_pci       BEA_gdp           RPP  \\\n",
              "count   34144.000000   33671.000000  3.367100e+04  33671.000000   \n",
              "mean        5.893737   42388.026170  6.157636e+06     90.907251   \n",
              "std         2.594445   12738.850917  2.683210e+07      6.518921   \n",
              "min         1.100000   14197.000000  5.420000e+03      0.000000   \n",
              "25%         4.000000   34371.000000  3.767765e+05     86.102000   \n",
              "50%         5.400000   40085.000000  9.699330e+05     89.009000   \n",
              "75%         7.300000   47392.500000  2.839994e+06     94.558000   \n",
              "max        28.900000  353263.000000  7.735713e+08    122.740000   \n",
              "\n",
              "          net_movers       net_agi  \n",
              "count   31656.000000  3.165600e+04  \n",
              "mean        9.493429  2.423986e+02  \n",
              "std      3323.523891  2.304635e+05  \n",
              "min   -141321.000000 -1.605755e+07  \n",
              "25%       -72.000000 -1.885000e+03  \n",
              "50%         8.000000  1.070000e+02  \n",
              "75%       143.000000  4.380000e+03  \n",
              "max    108999.000000  5.419300e+06  \n",
              "\n",
              "[8 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5fa5361-63c0-410b-8a73-2d179529222b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>total_population</th>\n",
              "      <th>median_age</th>\n",
              "      <th>housing_total</th>\n",
              "      <th>vacant</th>\n",
              "      <th>median_home_value</th>\n",
              "      <th>family_households</th>\n",
              "      <th>marital_total</th>\n",
              "      <th>under_18_in_hh</th>\n",
              "      <th>education_total_sex</th>\n",
              "      <th>...</th>\n",
              "      <th>Pop_Loss_2010</th>\n",
              "      <th>Retire_dest_cnty</th>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <th>unemploy_rate</th>\n",
              "      <th>BEA_pci</th>\n",
              "      <th>BEA_gdp</th>\n",
              "      <th>RPP</th>\n",
              "      <th>net_movers</th>\n",
              "      <th>net_agi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.422900e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34144.000000</td>\n",
              "      <td>33671.000000</td>\n",
              "      <td>3.367100e+04</td>\n",
              "      <td>33671.000000</td>\n",
              "      <td>31656.000000</td>\n",
              "      <td>3.165600e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>1.022781e+05</td>\n",
              "      <td>40.994070</td>\n",
              "      <td>3.803719e+04</td>\n",
              "      <td>5259.126548</td>\n",
              "      <td>1.423021e+05</td>\n",
              "      <td>2.507476e+04</td>\n",
              "      <td>8.266592e+04</td>\n",
              "      <td>2.362357e+04</td>\n",
              "      <td>6.866025e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.168706</td>\n",
              "      <td>0.141753</td>\n",
              "      <td>0.112472</td>\n",
              "      <td>0.225593</td>\n",
              "      <td>5.893737</td>\n",
              "      <td>42388.026170</td>\n",
              "      <td>6.157636e+06</td>\n",
              "      <td>90.907251</td>\n",
              "      <td>9.493429</td>\n",
              "      <td>2.423986e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.162324</td>\n",
              "      <td>3.257760e+05</td>\n",
              "      <td>5.273044</td>\n",
              "      <td>1.147825e+05</td>\n",
              "      <td>13028.854824</td>\n",
              "      <td>8.839044e+04</td>\n",
              "      <td>7.509575e+04</td>\n",
              "      <td>2.626099e+05</td>\n",
              "      <td>7.660182e+04</td>\n",
              "      <td>2.178339e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.374492</td>\n",
              "      <td>0.348748</td>\n",
              "      <td>0.315945</td>\n",
              "      <td>0.417962</td>\n",
              "      <td>2.594445</td>\n",
              "      <td>12738.850917</td>\n",
              "      <td>2.683210e+07</td>\n",
              "      <td>6.518921</td>\n",
              "      <td>3323.523891</td>\n",
              "      <td>2.304635e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2011.000000</td>\n",
              "      <td>6.200000e+01</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>2.700000e+01</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>2.130000e+04</td>\n",
              "      <td>1.500000e+01</td>\n",
              "      <td>5.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.200000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>14197.000000</td>\n",
              "      <td>5.420000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-141321.000000</td>\n",
              "      <td>-1.605755e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.120350e+04</td>\n",
              "      <td>37.900000</td>\n",
              "      <td>4.314750e+03</td>\n",
              "      <td>945.000000</td>\n",
              "      <td>8.890000e+04</td>\n",
              "      <td>2.889000e+03</td>\n",
              "      <td>9.122000e+03</td>\n",
              "      <td>2.495000e+03</td>\n",
              "      <td>7.755000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>34371.000000</td>\n",
              "      <td>3.767765e+05</td>\n",
              "      <td>86.102000</td>\n",
              "      <td>-72.000000</td>\n",
              "      <td>-1.885000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>2.600200e+04</td>\n",
              "      <td>40.900000</td>\n",
              "      <td>9.967500e+03</td>\n",
              "      <td>2003.000000</td>\n",
              "      <td>1.181000e+05</td>\n",
              "      <td>6.721500e+03</td>\n",
              "      <td>2.127300e+04</td>\n",
              "      <td>5.911500e+03</td>\n",
              "      <td>1.788750e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>40085.000000</td>\n",
              "      <td>9.699330e+05</td>\n",
              "      <td>89.009000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.070000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>6.814325e+04</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.612200e+04</td>\n",
              "      <td>4602.000000</td>\n",
              "      <td>1.640000e+05</td>\n",
              "      <td>1.744050e+04</td>\n",
              "      <td>5.532775e+04</td>\n",
              "      <td>1.529725e+04</td>\n",
              "      <td>4.593650e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>47392.500000</td>\n",
              "      <td>2.839994e+06</td>\n",
              "      <td>94.558000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>4.380000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2021.000000</td>\n",
              "      <td>1.010572e+07</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.342811e+06</td>\n",
              "      <td>245069.000000</td>\n",
              "      <td>1.225900e+06</td>\n",
              "      <td>2.216821e+06</td>\n",
              "      <td>8.246401e+06</td>\n",
              "      <td>2.421031e+06</td>\n",
              "      <td>6.922061e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>353263.000000</td>\n",
              "      <td>7.735713e+08</td>\n",
              "      <td>122.740000</td>\n",
              "      <td>108999.000000</td>\n",
              "      <td>5.419300e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5fa5361-63c0-410b-8a73-2d179529222b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d5fa5361-63c0-410b-8a73-2d179529222b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d5fa5361-63c0-410b-8a73-2d179529222b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9748ea9d-b388-445a-bae3-b0d641eb3609\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9748ea9d-b388-445a-bae3-b0d641eb3609')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9748ea9d-b388-445a-bae3-b0d641eb3609 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migration DataFrame Null Values:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "net_movers             2576\n",
              "net_agi                2576\n",
              "BEA_pci                 561\n",
              "RPP                     561\n",
              "BEA_gdp                 561\n",
              "                       ... \n",
              "Low_Ed_cnty               0\n",
              "Nonspec                   0\n",
              "Rec                       0\n",
              "Persistent_Pov_cnty       0\n",
              "Pers_chld_pov_cnty        0\n",
              "Length: 86, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>net_movers</th>\n",
              "      <td>2576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>net_agi</th>\n",
              "      <td>2576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BEA_pci</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RPP</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BEA_gdp</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Low_Ed_cnty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nonspec</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rec</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b6d819da",
        "outputId": "4111c291-f73f-4c7b-d6d8-24c1bd23123d"
      },
      "source": [
        "print('--- Starting Consolidated Cleaning of migration_df ---')\n",
        "\n",
        "# Define columns for aggregation (for Alaska consolidation, etc.)\n",
        "count_cols = [\n",
        "    'BEA_gdp', 'total_population', 'housing_total', 'vacant',\n",
        "    'family_households', 'marital_total', 'under_18_in_hh',\n",
        "    'education_total_sex', 'employed', 'unemployed', 'not_in_labor_force',\n",
        "    'commute_less_5min', 'commute_5_9min', 'commute_10_14min',\n",
        "    'commute_15_19min', 'commute_20_24min', 'commute_25_29min',\n",
        "    'commute_30_34min', 'commute_35_39min', 'commute_40_44min',\n",
        "    'commute_45_59min', 'commute_60_89min', 'commute_90_plus_min',\n",
        "    'work_in_owned_home', 'work_in_rental', 'occupation_total',\n",
        "    'Mgmt_Biz_Sci_Arts', 'Services', 'Sales_Admin', 'Nat-rsrc_Constr_Maint',\n",
        "    'Prod_Transp_Mvng', 'complete_hs', 'some_college', 'associates',\n",
        "    'bachelors', 'masters', 'professional', 'doctorate',\n",
        "    'net_movers', 'net_agi', 'POP_2010', 'POP_2020'\n",
        "]\n",
        "\n",
        "rate_cols = [\n",
        "    'BEA_pci', 'RPP', 'unemploy_rate', 'median_age', 'median_home_value',\n",
        "    'median_hh_income', 'median_property_taxes', '%owner_occupied',\n",
        "    '%renter_occupied', '%never_married_male', '%now_married_male',\n",
        "    '%divorced_male', '%widowed_male', '%never_married_female',\n",
        "    '%now_married_female', '%divorced_female', '%widowed_female',\n",
        "    '%white', '%black', '%native', '%asian', '%pacific_islander',\n",
        "    '%other_race', '%mixed_non_h', '%hispanic', 'RUCC_2013', 'RUCC_2023',\n",
        "    'Amenity_score', 'Amenity_rank', 'Industry_type', 'Farming', 'Mining',\n",
        "    'Mfging', 'Govt', 'Rec', 'Nonspec', 'Low_Ed_cnty', 'Low_emp_cnty',\n",
        "    'Pop_Loss_2010', 'Retire_dest_cnty', 'Persistent_Pov_cnty',\n",
        "    'Pers_chld_pov_cnty', 'Incentive_CAT'\n",
        "]\n",
        "\n",
        "# Define the weighted_average function (for Alaska consolidation, etc.)\n",
        "def weighted_average(df_subset, columns, weight_col='total_population'):\n",
        "    valid_columns = [col for col in columns if col in df_subset.columns]\n",
        "    if df_subset[weight_col].sum() == 0 or df_subset[weight_col].isnull().all():\n",
        "        return pd.Series([np.nan] * len(valid_columns), index=valid_columns)\n",
        "    df_valid = df_subset.dropna(subset=[weight_col]).copy()\n",
        "    df_valid = df_valid[df_valid[weight_col] > 0]\n",
        "    if df_valid.empty:\n",
        "        return pd.Series([np.nan] * len(valid_columns), index=valid_columns)\n",
        "    weighted_sum = (df_valid[valid_columns].fillna(0).multiply(df_valid[weight_col], axis=0)).sum()\n",
        "    total_weight = df_valid[weight_col].sum()\n",
        "    return weighted_sum / total_weight\n",
        "\n",
        "\n",
        "# --- Cleaning Step 1: Replace placeholder values with NaN and fill NaNs with FIPS-specific averages ---\n",
        "placeholder_value = -6.66666666e+08\n",
        "median_cols = ['median_home_value', 'median_hh_income', 'median_property_taxes']\n",
        "\n",
        "# Function to replace placeholder and then fill NaNs with FIPS-specific average\n",
        "def clean_and_fill_median_values(df, columns, placeholder, start_year=2011, end_year=2021):\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            # Replace placeholder with NaN\n",
        "            df[col] = df[col].replace(placeholder, np.nan)\n",
        "\n",
        "            # Group by FIPS and calculate the mean for each FIPS across the specified years\n",
        "            # Use a copy of the grouped data to avoid SettingWithCopyWarning\n",
        "            fips_yearly_mean = df[(df['YEAR'] >= start_year) & (df['YEAR'] <= end_year)].groupby('FIPS')[col].mean()\n",
        "\n",
        "            # Fill NaN values with the FIPS-specific mean\n",
        "            for fips_code in fips_yearly_mean.index:\n",
        "                df.loc[\n",
        "                    (df['FIPS'] == fips_code) & df[col].isnull(),\n",
        "                    col\n",
        "                ] = fips_yearly_mean[fips_code]\n",
        "            print(f\"  Cleaned and filled NaNs for '{col}'.\")\n",
        "    return df\n",
        "\n",
        "migration_df = clean_and_fill_median_values(migration_df.copy(), median_cols, placeholder_value)\n",
        "print('Replaced placeholder values with NaN and filled NaNs with FIPS-specific averages.')\n",
        "\n",
        "# --- Cleaning Step 2: Specific aggregation for 51515 into 51019 for 2011-2012 ---\n",
        "print('Aggregating FIPS 51515 into 51019 for 2011-2012...')\n",
        "for year in range(2011, 2013): # Process 2011 and 2012\n",
        "    city_data_51515 = migration_df[(migration_df['FIPS'] == '51515') & (migration_df['YEAR'] == year)]\n",
        "    county_data_51019 = migration_df[(migration_df['FIPS'] == '51019') & (migration_df['YEAR'] == year)]\n",
        "\n",
        "    if not city_data_51515.empty and not county_data_51019.empty:\n",
        "        county_idx = county_data_51019.index[0]\n",
        "\n",
        "        for col in ['net_movers', 'net_agi']:\n",
        "            if col in migration_df.columns:\n",
        "                city_val = city_data_51515[col].iloc[0] if pd.notna(city_data_51515[col].iloc[0]) else 0\n",
        "                county_val = county_data_51019[col].iloc[0] if pd.notna(county_data_51019[col].iloc[0]) else 0\n",
        "                migration_df.loc[county_idx, col] = city_val + county_val\n",
        "        print(f\"  Aggregated net_movers/agi for 51515 into 51019 for year {year}.\")\n",
        "\n",
        "# --- Cleaning Step 3: FIPS Remapping and Dropping ---\n",
        "print('Applying FIPS remapping and dropping...')\n",
        "# Remap FIPS '15901' to '15009'\n",
        "migration_df['FIPS'] = migration_df['FIPS'].replace({'15901': '15009'})\n",
        "print(\"  Remapped FIPS '15901' to '15009'.\")\n",
        "\n",
        "# Remap FIPS '46102' to '46113'\n",
        "migration_df['FIPS'] = migration_df['FIPS'].replace({'46102': '46113'})\n",
        "print(\"  Remapped FIPS '46102' to '46113'.\")\n",
        "\n",
        "fips_to_drop = [\n",
        "    '15005', # Kalawao, HI\n",
        "    '97000'  # Special FIPS, often Alaska-related for aggregate state data\n",
        "]\n",
        "# Add the range 09110-09190\n",
        "for i in range(9110, 9191):\n",
        "    fips_to_drop.append(f'0{i}')\n",
        "# Add 51515 to drop after aggregation (for all years) - crucial to drop AFTER aggregation\n",
        "fips_to_drop.append('51515')\n",
        "\n",
        "original_rows = len(migration_df)\n",
        "migration_df = migration_df[~migration_df['FIPS'].isin(fips_to_drop)].copy()\n",
        "print(f\"  Dropped {original_rows - len(migration_df)} rows corresponding to FIPS codes: {fips_to_drop}.\")\n",
        "\n",
        "# --- Cleaning Step 4: Specific fixes for FIPS '48261' and '35039' ---\n",
        "\n",
        "# Fill '48261' median_home_value with average 2011-2015\n",
        "fips_48261_mask = (migration_df['FIPS'] == '48261')\n",
        "avg_mhv_48261_2011_2015 = migration_df[fips_48261_mask & (migration_df['YEAR'].between(2011, 2015))]['median_home_value'].mean()\n",
        "migration_df.loc[fips_48261_mask & (migration_df['YEAR'].between(2011, 2015)), 'median_home_value'] = migration_df.loc[fips_48261_mask & (migration_df['YEAR'].between(2011, 2015)), 'median_home_value'].fillna(avg_mhv_48261_2011_2015)\n",
        "print(f\"Filled median_home_value for FIPS '48261' (2011-2015) with average: {avg_mhv_48261_2011_2015:.2f}\")\n",
        "\n",
        "# Re-run fix for FIPS '35039' (Rio Arriba, NM) - fill 2018 NaNs with avg of 2017 and 2019\n",
        "print('Applying fix for FIPS 35039...')\n",
        "fips_35039_mask = (migration_df['FIPS'] == '35039')\n",
        "rows_2018_35039 = migration_df[fips_35039_mask & (migration_df['YEAR'] == 2018)]\n",
        "if not rows_2018_35039.empty:\n",
        "    for col in rows_2018_35039.columns:\n",
        "        if rows_2018_35039[col].isnull().any():\n",
        "            val_2017 = migration_df[fips_35039_mask & (migration_df['YEAR'] == 2017)][col].iloc[0] if not migration_df[fips_35039_mask & (migration_df['YEAR'] == 2017)].empty else np.nan\n",
        "            val_2019 = migration_df[fips_35039_mask & (migration_df['YEAR'] == 2019)][col].iloc[0] if not migration_df[fips_35039_mask & (migration_df['YEAR'] == 2019)].empty else np.nan\n",
        "            if pd.notna(val_2017) and pd.notna(val_2019):\n",
        "                imputed_value = (val_2017 + val_2019) / 2\n",
        "                migration_df.loc[fips_35039_mask & (migration_df['YEAR'] == 2018), col] = imputed_value\n",
        "                print(f\"  Filled NaN in column '{col}' for FIPS '35039' in 2018 with {imputed_value:.2f}\")\n",
        "\n",
        "# --- Cleaning Step 5: Alaska FIPS Consolidation ---\n",
        "print('Starting Alaska FIPS Consolidation...')\n",
        "alaska_fips_to_consolidate = migration_df[\n",
        "    migration_df['FIPS'].astype(str).str.startswith('02') &\n",
        "    (migration_df['FIPS'] != '02000')\n",
        "]['FIPS'].unique()\n",
        "\n",
        "alaska_consolidated_data = []\n",
        "for year in sorted(migration_df['YEAR'].unique()):\n",
        "    alaska_yearly_data = migration_df[\n",
        "        (migration_df['FIPS'].isin(alaska_fips_to_consolidate)) &\n",
        "        (migration_df['YEAR'] == year)\n",
        "    ].copy()\n",
        "    if not alaska_yearly_data.empty:\n",
        "        consolidated_row = {'FIPS': '02000', 'YEAR': year}\n",
        "        for col in count_cols:\n",
        "            if col in alaska_yearly_data.columns:\n",
        "                consolidated_row[col] = alaska_yearly_data[col].sum()\n",
        "        for col in rate_cols:\n",
        "            if col in alaska_yearly_data.columns:\n",
        "                consolidated_row[col] = weighted_average(\n",
        "alaska_yearly_data, [col], 'total_population').iloc[0]\n",
        "        alaska_consolidated_data.append(consolidated_row)\n",
        "alaska_df = pd.DataFrame(alaska_consolidated_data)\n",
        "migration_df = migration_df[~migration_df['FIPS'].isin(alaska_fips_to_consolidate)].copy()\n",
        "migration_df = pd.concat([migration_df, alaska_df], ignore_index=True)\n",
        "print(f\"Consolidated {len(alaska_fips_to_consolidate)} Alaska FIPS codes into '02000'.\")\n",
        "\n",
        "print('\\n--- Comprehensive Cleaning Complete. Re-running final inspection ---')\n",
        "\n",
        "print('\\nMigration DataFrame Info:')\n",
        "print(migration_df.info())\n",
        "\n",
        "print('\\nMigration DataFrame Head:')\n",
        "display(migration_df.head())\n",
        "\n",
        "print('\\nMigration DataFrame Descriptive Statistics:')\n",
        "display(migration_df.describe())\n",
        "\n",
        "print('\\nMigration DataFrame Null Values:')\n",
        "display(migration_df.isnull().sum().sort_values(ascending=False))"
      ],
      "id": "b6d819da",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Consolidated Cleaning of migration_df ---\n",
            "  Cleaned and filled NaNs for 'median_home_value'.\n",
            "  Cleaned and filled NaNs for 'median_hh_income'.\n",
            "  Cleaned and filled NaNs for 'median_property_taxes'.\n",
            "Replaced placeholder values with NaN and filled NaNs with FIPS-specific averages.\n",
            "Aggregating FIPS 51515 into 51019 for 2011-2012...\n",
            "Applying FIPS remapping and dropping...\n",
            "  Remapped FIPS '15901' to '15009'.\n",
            "  Remapped FIPS '46102' to '46113'.\n",
            "  Dropped 0 rows corresponding to FIPS codes: ['15005', '97000', '09110', '09111', '09112', '09113', '09114', '09115', '09116', '09117', '09118', '09119', '09120', '09121', '09122', '09123', '09124', '09125', '09126', '09127', '09128', '09129', '09130', '09131', '09132', '09133', '09134', '09135', '09136', '09137', '09138', '09139', '09140', '09141', '09142', '09143', '09144', '09145', '09146', '09147', '09148', '09149', '09150', '09151', '09152', '09153', '09154', '09155', '09156', '09157', '09158', '09159', '09160', '09161', '09162', '09163', '09164', '09165', '09166', '09167', '09168', '09169', '09170', '09171', '09172', '09173', '09174', '09175', '09176', '09177', '09178', '09179', '09180', '09181', '09182', '09183', '09184', '09185', '09186', '09187', '09188', '09189', '09190', '51515'].\n",
            "Filled median_home_value for FIPS '48261' (2011-2015) with average: 56051.43\n",
            "Applying fix for FIPS 35039...\n",
            "Starting Alaska FIPS Consolidation...\n",
            "Consolidated 0 Alaska FIPS codes into '02000'.\n",
            "\n",
            "--- Comprehensive Cleaning Complete. Re-running final inspection ---\n",
            "\n",
            "Migration DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34232 entries, 0 to 34231\n",
            "Data columns (total 86 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   FIPS                   34232 non-null  object \n",
            " 1   YEAR                   34232 non-null  int64  \n",
            " 2   total_population       34232 non-null  float64\n",
            " 3   median_age             34232 non-null  float64\n",
            " 4   housing_total          34232 non-null  float64\n",
            " 5   vacant                 34232 non-null  float64\n",
            " 6   median_home_value      34232 non-null  float64\n",
            " 7   family_households      34232 non-null  float64\n",
            " 8   marital_total          34232 non-null  float64\n",
            " 9   under_18_in_hh         34232 non-null  float64\n",
            " 10  education_total_sex    34232 non-null  float64\n",
            " 11  median_hh_income       34232 non-null  float64\n",
            " 12  employed               34232 non-null  float64\n",
            " 13  unemployed             34232 non-null  float64\n",
            " 14  not_in_labor_force     34232 non-null  float64\n",
            " 15  commute_less_5min      34232 non-null  float64\n",
            " 16  commute_5_9min         34232 non-null  float64\n",
            " 17  commute_10_14min       34232 non-null  float64\n",
            " 18  commute_15_19min       34232 non-null  float64\n",
            " 19  commute_20_24min       34232 non-null  float64\n",
            " 20  commute_25_29min       34232 non-null  float64\n",
            " 21  commute_30_34min       34232 non-null  float64\n",
            " 22  commute_35_39min       34232 non-null  float64\n",
            " 23  commute_40_44min       34232 non-null  float64\n",
            " 24  commute_45_59min       34232 non-null  float64\n",
            " 25  commute_60_89min       34232 non-null  float64\n",
            " 26  commute_90_plus_min    34232 non-null  float64\n",
            " 27  work_in_owned_home     34232 non-null  float64\n",
            " 28  work_in_rental         34232 non-null  float64\n",
            " 29  median_property_taxes  34232 non-null  float64\n",
            " 30  occupation_total       34232 non-null  float64\n",
            " 31  Mgmt_Biz_Sci_Arts      34232 non-null  float64\n",
            " 32  Services               34232 non-null  float64\n",
            " 33  Sales_Admin            34232 non-null  float64\n",
            " 34  Nat-rsrc_Constr_Maint  34232 non-null  float64\n",
            " 35  Prod_Transp_Mvng       34232 non-null  float64\n",
            " 36  %owner_occupied        34232 non-null  float64\n",
            " 37  %renter_occupied       34232 non-null  float64\n",
            " 38  %never_married_male    34232 non-null  float64\n",
            " 39  %now_married_male      34232 non-null  float64\n",
            " 40  %divorced_male         34232 non-null  float64\n",
            " 41  %widowed_male          34232 non-null  float64\n",
            " 42  %never_married_female  34232 non-null  float64\n",
            " 43  %now_married_female    34232 non-null  float64\n",
            " 44  %divorced_female       34232 non-null  float64\n",
            " 45  %widowed_female        34232 non-null  float64\n",
            " 46  %white                 34232 non-null  float64\n",
            " 47  %black                 34232 non-null  float64\n",
            " 48  %native                34232 non-null  float64\n",
            " 49  %asian                 34232 non-null  float64\n",
            " 50  %pacific_islander      34232 non-null  float64\n",
            " 51  %other_race            34232 non-null  float64\n",
            " 52  %mixed_non_h           34232 non-null  float64\n",
            " 53  %hispanic              34232 non-null  float64\n",
            " 54  complete_hs            34232 non-null  float64\n",
            " 55  some_college           34232 non-null  float64\n",
            " 56  associates             34232 non-null  float64\n",
            " 57  bachelors              34232 non-null  float64\n",
            " 58  masters                34232 non-null  float64\n",
            " 59  professional           34232 non-null  float64\n",
            " 60  doctorate              34232 non-null  float64\n",
            " 61  POP_2010               34232 non-null  float64\n",
            " 62  RUCC_2013              34232 non-null  float64\n",
            " 63  POP_2020               34232 non-null  float64\n",
            " 64  RUCC_2023              34232 non-null  float64\n",
            " 65  Amenity_score          34232 non-null  float64\n",
            " 66  Amenity_rank           34232 non-null  float64\n",
            " 67  Industry_type          34232 non-null  float64\n",
            " 68  Farming                34232 non-null  float64\n",
            " 69  Mining                 34232 non-null  float64\n",
            " 70  Mfging                 34232 non-null  float64\n",
            " 71  Govt                   34232 non-null  float64\n",
            " 72  Rec                    34232 non-null  float64\n",
            " 73  Nonspec                34232 non-null  float64\n",
            " 74  Low_Ed_cnty            34232 non-null  float64\n",
            " 75  Low_emp_cnty           34232 non-null  float64\n",
            " 76  Pop_Loss_2010          34232 non-null  float64\n",
            " 77  Retire_dest_cnty       34232 non-null  float64\n",
            " 78  Persistent_Pov_cnty    34232 non-null  float64\n",
            " 79  Pers_chld_pov_cnty     34232 non-null  float64\n",
            " 80  unemploy_rate          34144 non-null  float64\n",
            " 81  BEA_pci                33671 non-null  float64\n",
            " 82  BEA_gdp                33671 non-null  float64\n",
            " 83  RPP                    33671 non-null  float64\n",
            " 84  net_movers             31656 non-null  float64\n",
            " 85  net_agi                31656 non-null  float64\n",
            "dtypes: float64(84), int64(1), object(1)\n",
            "memory usage: 22.5+ MB\n",
            "None\n",
            "\n",
            "Migration DataFrame Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    FIPS  YEAR  total_population  median_age  housing_total  vacant  \\\n",
              "0  01001  2011           53944.0        36.4        19998.0  1861.0   \n",
              "1  01001  2012           54590.0        37.0        19934.0  2143.0   \n",
              "2  01001  2013           54907.0        37.5        20071.0  2149.0   \n",
              "3  01001  2014           55136.0        37.9        20304.0  2127.0   \n",
              "4  01001  2015           55221.0        37.7        20396.0  2186.0   \n",
              "\n",
              "   median_home_value  family_households  marital_total  under_18_in_hh  ...  \\\n",
              "0           137500.0            14631.0        42072.0         14708.0  ...   \n",
              "1           137900.0            14258.0        42705.0         14637.0  ...   \n",
              "2           136200.0            14132.0        43115.0         14392.0  ...   \n",
              "3           136600.0            14272.0        43469.0         14214.0  ...   \n",
              "4           141300.0            14213.0        43775.0         14044.0  ...   \n",
              "\n",
              "   Pop_Loss_2010  Retire_dest_cnty  Persistent_Pov_cnty  Pers_chld_pov_cnty  \\\n",
              "0            0.0               1.0                  0.0                 0.0   \n",
              "1            0.0               1.0                  0.0                 0.0   \n",
              "2            0.0               1.0                  0.0                 0.0   \n",
              "3            0.0               1.0                  0.0                 0.0   \n",
              "4            0.0               1.0                  0.0                 0.0   \n",
              "\n",
              "   unemploy_rate  BEA_pci    BEA_gdp     RPP  net_movers  net_agi  \n",
              "0            8.3  34430.0  1493906.0  91.098      -191.0  -5545.0  \n",
              "1            7.1  35151.0  1726577.0  93.269       348.0   5266.0  \n",
              "2            6.3  35348.0  1618151.0  91.394      -156.0  -2643.0  \n",
              "3            5.8  36329.0  1629762.0  90.675       252.0   1456.0  \n",
              "4            5.2  38107.0  1765826.0  90.622       144.0  -2565.0  \n",
              "\n",
              "[5 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-653af222-b012-43e4-93d7-bd0844df2fbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIPS</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>total_population</th>\n",
              "      <th>median_age</th>\n",
              "      <th>housing_total</th>\n",
              "      <th>vacant</th>\n",
              "      <th>median_home_value</th>\n",
              "      <th>family_households</th>\n",
              "      <th>marital_total</th>\n",
              "      <th>under_18_in_hh</th>\n",
              "      <th>...</th>\n",
              "      <th>Pop_Loss_2010</th>\n",
              "      <th>Retire_dest_cnty</th>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <th>unemploy_rate</th>\n",
              "      <th>BEA_pci</th>\n",
              "      <th>BEA_gdp</th>\n",
              "      <th>RPP</th>\n",
              "      <th>net_movers</th>\n",
              "      <th>net_agi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01001</td>\n",
              "      <td>2011</td>\n",
              "      <td>53944.0</td>\n",
              "      <td>36.4</td>\n",
              "      <td>19998.0</td>\n",
              "      <td>1861.0</td>\n",
              "      <td>137500.0</td>\n",
              "      <td>14631.0</td>\n",
              "      <td>42072.0</td>\n",
              "      <td>14708.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>34430.0</td>\n",
              "      <td>1493906.0</td>\n",
              "      <td>91.098</td>\n",
              "      <td>-191.0</td>\n",
              "      <td>-5545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01001</td>\n",
              "      <td>2012</td>\n",
              "      <td>54590.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>19934.0</td>\n",
              "      <td>2143.0</td>\n",
              "      <td>137900.0</td>\n",
              "      <td>14258.0</td>\n",
              "      <td>42705.0</td>\n",
              "      <td>14637.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>35151.0</td>\n",
              "      <td>1726577.0</td>\n",
              "      <td>93.269</td>\n",
              "      <td>348.0</td>\n",
              "      <td>5266.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01001</td>\n",
              "      <td>2013</td>\n",
              "      <td>54907.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>20071.0</td>\n",
              "      <td>2149.0</td>\n",
              "      <td>136200.0</td>\n",
              "      <td>14132.0</td>\n",
              "      <td>43115.0</td>\n",
              "      <td>14392.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>35348.0</td>\n",
              "      <td>1618151.0</td>\n",
              "      <td>91.394</td>\n",
              "      <td>-156.0</td>\n",
              "      <td>-2643.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01001</td>\n",
              "      <td>2014</td>\n",
              "      <td>55136.0</td>\n",
              "      <td>37.9</td>\n",
              "      <td>20304.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>136600.0</td>\n",
              "      <td>14272.0</td>\n",
              "      <td>43469.0</td>\n",
              "      <td>14214.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>36329.0</td>\n",
              "      <td>1629762.0</td>\n",
              "      <td>90.675</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1456.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01001</td>\n",
              "      <td>2015</td>\n",
              "      <td>55221.0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>20396.0</td>\n",
              "      <td>2186.0</td>\n",
              "      <td>141300.0</td>\n",
              "      <td>14213.0</td>\n",
              "      <td>43775.0</td>\n",
              "      <td>14044.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>38107.0</td>\n",
              "      <td>1765826.0</td>\n",
              "      <td>90.622</td>\n",
              "      <td>144.0</td>\n",
              "      <td>-2565.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-653af222-b012-43e4-93d7-bd0844df2fbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-653af222-b012-43e4-93d7-bd0844df2fbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-653af222-b012-43e4-93d7-bd0844df2fbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-416e5fee-c5f4-43fe-a459-3d029d946dc9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-416e5fee-c5f4-43fe-a459-3d029d946dc9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-416e5fee-c5f4-43fe-a459-3d029d946dc9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migration DataFrame Descriptive Statistics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               YEAR  total_population    median_age  housing_total  \\\n",
              "count  34232.000000      3.423200e+04  34232.000000   3.423200e+04   \n",
              "mean    2016.000000      1.022781e+05     40.994070   3.803719e+04   \n",
              "std        3.162324      3.257760e+05      5.273044   1.147825e+05   \n",
              "min     2011.000000      6.200000e+01     21.400000   2.700000e+01   \n",
              "25%     2013.000000      1.120350e+04     37.900000   4.314750e+03   \n",
              "50%     2016.000000      2.600200e+04     40.900000   9.967500e+03   \n",
              "75%     2019.000000      6.814325e+04     44.000000   2.612200e+04   \n",
              "max     2021.000000      1.010572e+07     68.100000   3.342811e+06   \n",
              "\n",
              "              vacant  median_home_value  family_households  marital_total  \\\n",
              "count   34232.000000       3.423200e+04       3.423200e+04   3.423200e+04   \n",
              "mean     5259.126548       1.422936e+05       2.507476e+04   8.266592e+04   \n",
              "std     13028.854824       8.839130e+04       7.509575e+04   2.626099e+05   \n",
              "min        17.000000       2.130000e+04       1.500000e+01   5.200000e+01   \n",
              "25%       945.000000       8.890000e+04       2.889000e+03   9.122000e+03   \n",
              "50%      2003.000000       1.181000e+05       6.721500e+03   2.127300e+04   \n",
              "75%      4602.000000       1.640000e+05       1.744050e+04   5.532775e+04   \n",
              "max    245069.000000       1.225900e+06       2.216821e+06   8.246401e+06   \n",
              "\n",
              "       under_18_in_hh  education_total_sex  ...  Pop_Loss_2010  \\\n",
              "count    3.423200e+04         3.423200e+04  ...   34232.000000   \n",
              "mean     2.362357e+04         6.866025e+04  ...       0.168706   \n",
              "std      7.660182e+04         2.178339e+05  ...       0.374492   \n",
              "min      0.000000e+00         5.200000e+01  ...       0.000000   \n",
              "25%      2.495000e+03         7.755000e+03  ...       0.000000   \n",
              "50%      5.911500e+03         1.788750e+04  ...       0.000000   \n",
              "75%      1.529725e+04         4.593650e+04  ...       0.000000   \n",
              "max      2.421031e+06         6.922061e+06  ...       1.000000   \n",
              "\n",
              "       Retire_dest_cnty  Persistent_Pov_cnty  Pers_chld_pov_cnty  \\\n",
              "count      34232.000000         34232.000000        34232.000000   \n",
              "mean           0.141753             0.112472            0.225593   \n",
              "std            0.348748             0.315945            0.417962   \n",
              "min            0.000000             0.000000            0.000000   \n",
              "25%            0.000000             0.000000            0.000000   \n",
              "50%            0.000000             0.000000            0.000000   \n",
              "75%            0.000000             0.000000            0.000000   \n",
              "max            1.000000             1.000000            1.000000   \n",
              "\n",
              "       unemploy_rate        BEA_pci       BEA_gdp           RPP  \\\n",
              "count   34144.000000   33671.000000  3.367100e+04  33671.000000   \n",
              "mean        5.893737   42388.026170  6.157636e+06     90.907251   \n",
              "std         2.594445   12738.850917  2.683210e+07      6.518921   \n",
              "min         1.100000   14197.000000  5.420000e+03      0.000000   \n",
              "25%         4.000000   34371.000000  3.767765e+05     86.102000   \n",
              "50%         5.400000   40085.000000  9.699330e+05     89.009000   \n",
              "75%         7.300000   47392.500000  2.839994e+06     94.558000   \n",
              "max        28.900000  353263.000000  7.735713e+08    122.740000   \n",
              "\n",
              "          net_movers       net_agi  \n",
              "count   31656.000000  3.165600e+04  \n",
              "mean        9.493429  2.423986e+02  \n",
              "std      3323.523891  2.304635e+05  \n",
              "min   -141321.000000 -1.605755e+07  \n",
              "25%       -72.000000 -1.885000e+03  \n",
              "50%         8.000000  1.070000e+02  \n",
              "75%       143.000000  4.380000e+03  \n",
              "max    108999.000000  5.419300e+06  \n",
              "\n",
              "[8 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-faf52d48-a787-4fec-95f1-83ed0ad064b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>total_population</th>\n",
              "      <th>median_age</th>\n",
              "      <th>housing_total</th>\n",
              "      <th>vacant</th>\n",
              "      <th>median_home_value</th>\n",
              "      <th>family_households</th>\n",
              "      <th>marital_total</th>\n",
              "      <th>under_18_in_hh</th>\n",
              "      <th>education_total_sex</th>\n",
              "      <th>...</th>\n",
              "      <th>Pop_Loss_2010</th>\n",
              "      <th>Retire_dest_cnty</th>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <th>unemploy_rate</th>\n",
              "      <th>BEA_pci</th>\n",
              "      <th>BEA_gdp</th>\n",
              "      <th>RPP</th>\n",
              "      <th>net_movers</th>\n",
              "      <th>net_agi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34144.000000</td>\n",
              "      <td>33671.000000</td>\n",
              "      <td>3.367100e+04</td>\n",
              "      <td>33671.000000</td>\n",
              "      <td>31656.000000</td>\n",
              "      <td>3.165600e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>1.022781e+05</td>\n",
              "      <td>40.994070</td>\n",
              "      <td>3.803719e+04</td>\n",
              "      <td>5259.126548</td>\n",
              "      <td>1.422936e+05</td>\n",
              "      <td>2.507476e+04</td>\n",
              "      <td>8.266592e+04</td>\n",
              "      <td>2.362357e+04</td>\n",
              "      <td>6.866025e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.168706</td>\n",
              "      <td>0.141753</td>\n",
              "      <td>0.112472</td>\n",
              "      <td>0.225593</td>\n",
              "      <td>5.893737</td>\n",
              "      <td>42388.026170</td>\n",
              "      <td>6.157636e+06</td>\n",
              "      <td>90.907251</td>\n",
              "      <td>9.493429</td>\n",
              "      <td>2.423986e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.162324</td>\n",
              "      <td>3.257760e+05</td>\n",
              "      <td>5.273044</td>\n",
              "      <td>1.147825e+05</td>\n",
              "      <td>13028.854824</td>\n",
              "      <td>8.839130e+04</td>\n",
              "      <td>7.509575e+04</td>\n",
              "      <td>2.626099e+05</td>\n",
              "      <td>7.660182e+04</td>\n",
              "      <td>2.178339e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.374492</td>\n",
              "      <td>0.348748</td>\n",
              "      <td>0.315945</td>\n",
              "      <td>0.417962</td>\n",
              "      <td>2.594445</td>\n",
              "      <td>12738.850917</td>\n",
              "      <td>2.683210e+07</td>\n",
              "      <td>6.518921</td>\n",
              "      <td>3323.523891</td>\n",
              "      <td>2.304635e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2011.000000</td>\n",
              "      <td>6.200000e+01</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>2.700000e+01</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>2.130000e+04</td>\n",
              "      <td>1.500000e+01</td>\n",
              "      <td>5.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.200000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>14197.000000</td>\n",
              "      <td>5.420000e+03</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-141321.000000</td>\n",
              "      <td>-1.605755e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.120350e+04</td>\n",
              "      <td>37.900000</td>\n",
              "      <td>4.314750e+03</td>\n",
              "      <td>945.000000</td>\n",
              "      <td>8.890000e+04</td>\n",
              "      <td>2.889000e+03</td>\n",
              "      <td>9.122000e+03</td>\n",
              "      <td>2.495000e+03</td>\n",
              "      <td>7.755000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>34371.000000</td>\n",
              "      <td>3.767765e+05</td>\n",
              "      <td>86.102000</td>\n",
              "      <td>-72.000000</td>\n",
              "      <td>-1.885000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>2.600200e+04</td>\n",
              "      <td>40.900000</td>\n",
              "      <td>9.967500e+03</td>\n",
              "      <td>2003.000000</td>\n",
              "      <td>1.181000e+05</td>\n",
              "      <td>6.721500e+03</td>\n",
              "      <td>2.127300e+04</td>\n",
              "      <td>5.911500e+03</td>\n",
              "      <td>1.788750e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>40085.000000</td>\n",
              "      <td>9.699330e+05</td>\n",
              "      <td>89.009000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.070000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>6.814325e+04</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.612200e+04</td>\n",
              "      <td>4602.000000</td>\n",
              "      <td>1.640000e+05</td>\n",
              "      <td>1.744050e+04</td>\n",
              "      <td>5.532775e+04</td>\n",
              "      <td>1.529725e+04</td>\n",
              "      <td>4.593650e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>47392.500000</td>\n",
              "      <td>2.839994e+06</td>\n",
              "      <td>94.558000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>4.380000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2021.000000</td>\n",
              "      <td>1.010572e+07</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.342811e+06</td>\n",
              "      <td>245069.000000</td>\n",
              "      <td>1.225900e+06</td>\n",
              "      <td>2.216821e+06</td>\n",
              "      <td>8.246401e+06</td>\n",
              "      <td>2.421031e+06</td>\n",
              "      <td>6.922061e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>353263.000000</td>\n",
              "      <td>7.735713e+08</td>\n",
              "      <td>122.740000</td>\n",
              "      <td>108999.000000</td>\n",
              "      <td>5.419300e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-faf52d48-a787-4fec-95f1-83ed0ad064b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-faf52d48-a787-4fec-95f1-83ed0ad064b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-faf52d48-a787-4fec-95f1-83ed0ad064b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dc1800c7-9fce-4211-90bb-1d2d6b384665\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc1800c7-9fce-4211-90bb-1d2d6b384665')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dc1800c7-9fce-4211-90bb-1d2d6b384665 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migration DataFrame Null Values:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "net_movers             2576\n",
              "net_agi                2576\n",
              "BEA_pci                 561\n",
              "RPP                     561\n",
              "BEA_gdp                 561\n",
              "                       ... \n",
              "Low_Ed_cnty               0\n",
              "Nonspec                   0\n",
              "Rec                       0\n",
              "Persistent_Pov_cnty       0\n",
              "Pers_chld_pov_cnty        0\n",
              "Length: 86, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>net_movers</th>\n",
              "      <td>2576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>net_agi</th>\n",
              "      <td>2576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BEA_pci</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RPP</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BEA_gdp</th>\n",
              "      <td>561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Low_Ed_cnty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Nonspec</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Rec</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyG-tZe4bNXW"
      },
      "source": [
        "migration_df.to_csv('migration_df3.csv', index=False)"
      ],
      "id": "gyG-tZe4bNXW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d61eae5e",
        "outputId": "a06f733e-4fc9-45d2-ac06-b417912a6739"
      },
      "source": [
        "print('--- Applying final imputations to migration_df ---')\n",
        "\n",
        "# Impute RPP values where it is 0 with 91\n",
        "migration_df.loc[migration_df['RPP'] == 0, 'RPP'] = 91\n",
        "\n",
        "# Impute specified NaN values\n",
        "migration_df['net_movers'] = migration_df['net_movers'].fillna(0)\n",
        "migration_df['net_agi'] = migration_df['net_agi'].fillna(0)\n",
        "migration_df['BEA_pci'] = migration_df['BEA_pci'].fillna(44463)\n",
        "migration_df['BEA_gdp'] = migration_df['BEA_gdp'].fillna(3559994)\n",
        "migration_df['RPP'] = migration_df['RPP'].fillna(94)\n",
        "\n",
        "print('\\n--- Final Imputations Complete. Re-running final inspection ---')\n",
        "\n",
        "print('\\nMigration DataFrame Info:')\n",
        "print(migration_df.info())\n",
        "\n",
        "print('\\nMigration DataFrame Head:')\n",
        "display(migration_df.head())\n",
        "\n",
        "print('\\nMigration DataFrame Descriptive Statistics:')\n",
        "display(migration_df.describe())\n",
        "\n",
        "print('\\nMigration DataFrame Null Values:')\n",
        "display(migration_df.isnull().sum().sort_values(ascending=False))"
      ],
      "id": "d61eae5e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Applying final imputations to migration_df ---\n",
            "\n",
            "--- Final Imputations Complete. Re-running final inspection ---\n",
            "\n",
            "Migration DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34232 entries, 0 to 34231\n",
            "Data columns (total 86 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   FIPS                   34232 non-null  object \n",
            " 1   YEAR                   34232 non-null  int64  \n",
            " 2   total_population       34232 non-null  float64\n",
            " 3   median_age             34232 non-null  float64\n",
            " 4   housing_total          34232 non-null  float64\n",
            " 5   vacant                 34232 non-null  float64\n",
            " 6   median_home_value      34232 non-null  float64\n",
            " 7   family_households      34232 non-null  float64\n",
            " 8   marital_total          34232 non-null  float64\n",
            " 9   under_18_in_hh         34232 non-null  float64\n",
            " 10  education_total_sex    34232 non-null  float64\n",
            " 11  median_hh_income       34232 non-null  float64\n",
            " 12  employed               34232 non-null  float64\n",
            " 13  unemployed             34232 non-null  float64\n",
            " 14  not_in_labor_force     34232 non-null  float64\n",
            " 15  commute_less_5min      34232 non-null  float64\n",
            " 16  commute_5_9min         34232 non-null  float64\n",
            " 17  commute_10_14min       34232 non-null  float64\n",
            " 18  commute_15_19min       34232 non-null  float64\n",
            " 19  commute_20_24min       34232 non-null  float64\n",
            " 20  commute_25_29min       34232 non-null  float64\n",
            " 21  commute_30_34min       34232 non-null  float64\n",
            " 22  commute_35_39min       34232 non-null  float64\n",
            " 23  commute_40_44min       34232 non-null  float64\n",
            " 24  commute_45_59min       34232 non-null  float64\n",
            " 25  commute_60_89min       34232 non-null  float64\n",
            " 26  commute_90_plus_min    34232 non-null  float64\n",
            " 27  work_in_owned_home     34232 non-null  float64\n",
            " 28  work_in_rental         34232 non-null  float64\n",
            " 29  median_property_taxes  34232 non-null  float64\n",
            " 30  occupation_total       34232 non-null  float64\n",
            " 31  Mgmt_Biz_Sci_Arts      34232 non-null  float64\n",
            " 32  Services               34232 non-null  float64\n",
            " 33  Sales_Admin            34232 non-null  float64\n",
            " 34  Nat-rsrc_Constr_Maint  34232 non-null  float64\n",
            " 35  Prod_Transp_Mvng       34232 non-null  float64\n",
            " 36  %owner_occupied        34232 non-null  float64\n",
            " 37  %renter_occupied       34232 non-null  float64\n",
            " 38  %never_married_male    34232 non-null  float64\n",
            " 39  %now_married_male      34232 non-null  float64\n",
            " 40  %divorced_male         34232 non-null  float64\n",
            " 41  %widowed_male          34232 non-null  float64\n",
            " 42  %never_married_female  34232 non-null  float64\n",
            " 43  %now_married_female    34232 non-null  float64\n",
            " 44  %divorced_female       34232 non-null  float64\n",
            " 45  %widowed_female        34232 non-null  float64\n",
            " 46  %white                 34232 non-null  float64\n",
            " 47  %black                 34232 non-null  float64\n",
            " 48  %native                34232 non-null  float64\n",
            " 49  %asian                 34232 non-null  float64\n",
            " 50  %pacific_islander      34232 non-null  float64\n",
            " 51  %other_race            34232 non-null  float64\n",
            " 52  %mixed_non_h           34232 non-null  float64\n",
            " 53  %hispanic              34232 non-null  float64\n",
            " 54  complete_hs            34232 non-null  float64\n",
            " 55  some_college           34232 non-null  float64\n",
            " 56  associates             34232 non-null  float64\n",
            " 57  bachelors              34232 non-null  float64\n",
            " 58  masters                34232 non-null  float64\n",
            " 59  professional           34232 non-null  float64\n",
            " 60  doctorate              34232 non-null  float64\n",
            " 61  POP_2010               34232 non-null  float64\n",
            " 62  RUCC_2013              34232 non-null  float64\n",
            " 63  POP_2020               34232 non-null  float64\n",
            " 64  RUCC_2023              34232 non-null  float64\n",
            " 65  Amenity_score          34232 non-null  float64\n",
            " 66  Amenity_rank           34232 non-null  float64\n",
            " 67  Industry_type          34232 non-null  float64\n",
            " 68  Farming                34232 non-null  float64\n",
            " 69  Mining                 34232 non-null  float64\n",
            " 70  Mfging                 34232 non-null  float64\n",
            " 71  Govt                   34232 non-null  float64\n",
            " 72  Rec                    34232 non-null  float64\n",
            " 73  Nonspec                34232 non-null  float64\n",
            " 74  Low_Ed_cnty            34232 non-null  float64\n",
            " 75  Low_emp_cnty           34232 non-null  float64\n",
            " 76  Pop_Loss_2010          34232 non-null  float64\n",
            " 77  Retire_dest_cnty       34232 non-null  float64\n",
            " 78  Persistent_Pov_cnty    34232 non-null  float64\n",
            " 79  Pers_chld_pov_cnty     34232 non-null  float64\n",
            " 80  unemploy_rate          34144 non-null  float64\n",
            " 81  BEA_pci                34232 non-null  float64\n",
            " 82  BEA_gdp                34232 non-null  float64\n",
            " 83  RPP                    34232 non-null  float64\n",
            " 84  net_movers             34232 non-null  float64\n",
            " 85  net_agi                34232 non-null  float64\n",
            "dtypes: float64(84), int64(1), object(1)\n",
            "memory usage: 22.5+ MB\n",
            "None\n",
            "\n",
            "Migration DataFrame Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    FIPS  YEAR  total_population  median_age  housing_total  vacant  \\\n",
              "0  01001  2011           53944.0        36.4        19998.0  1861.0   \n",
              "1  01001  2012           54590.0        37.0        19934.0  2143.0   \n",
              "2  01001  2013           54907.0        37.5        20071.0  2149.0   \n",
              "3  01001  2014           55136.0        37.9        20304.0  2127.0   \n",
              "4  01001  2015           55221.0        37.7        20396.0  2186.0   \n",
              "\n",
              "   median_home_value  family_households  marital_total  under_18_in_hh  ...  \\\n",
              "0           137500.0            14631.0        42072.0         14708.0  ...   \n",
              "1           137900.0            14258.0        42705.0         14637.0  ...   \n",
              "2           136200.0            14132.0        43115.0         14392.0  ...   \n",
              "3           136600.0            14272.0        43469.0         14214.0  ...   \n",
              "4           141300.0            14213.0        43775.0         14044.0  ...   \n",
              "\n",
              "   Pop_Loss_2010  Retire_dest_cnty  Persistent_Pov_cnty  Pers_chld_pov_cnty  \\\n",
              "0            0.0               1.0                  0.0                 0.0   \n",
              "1            0.0               1.0                  0.0                 0.0   \n",
              "2            0.0               1.0                  0.0                 0.0   \n",
              "3            0.0               1.0                  0.0                 0.0   \n",
              "4            0.0               1.0                  0.0                 0.0   \n",
              "\n",
              "   unemploy_rate  BEA_pci    BEA_gdp     RPP  net_movers  net_agi  \n",
              "0            8.3  34430.0  1493906.0  91.098      -191.0  -5545.0  \n",
              "1            7.1  35151.0  1726577.0  93.269       348.0   5266.0  \n",
              "2            6.3  35348.0  1618151.0  91.394      -156.0  -2643.0  \n",
              "3            5.8  36329.0  1629762.0  90.675       252.0   1456.0  \n",
              "4            5.2  38107.0  1765826.0  90.622       144.0  -2565.0  \n",
              "\n",
              "[5 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2e7af4f-db90-4f02-9722-fb868e416190\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIPS</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>total_population</th>\n",
              "      <th>median_age</th>\n",
              "      <th>housing_total</th>\n",
              "      <th>vacant</th>\n",
              "      <th>median_home_value</th>\n",
              "      <th>family_households</th>\n",
              "      <th>marital_total</th>\n",
              "      <th>under_18_in_hh</th>\n",
              "      <th>...</th>\n",
              "      <th>Pop_Loss_2010</th>\n",
              "      <th>Retire_dest_cnty</th>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <th>unemploy_rate</th>\n",
              "      <th>BEA_pci</th>\n",
              "      <th>BEA_gdp</th>\n",
              "      <th>RPP</th>\n",
              "      <th>net_movers</th>\n",
              "      <th>net_agi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01001</td>\n",
              "      <td>2011</td>\n",
              "      <td>53944.0</td>\n",
              "      <td>36.4</td>\n",
              "      <td>19998.0</td>\n",
              "      <td>1861.0</td>\n",
              "      <td>137500.0</td>\n",
              "      <td>14631.0</td>\n",
              "      <td>42072.0</td>\n",
              "      <td>14708.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>34430.0</td>\n",
              "      <td>1493906.0</td>\n",
              "      <td>91.098</td>\n",
              "      <td>-191.0</td>\n",
              "      <td>-5545.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01001</td>\n",
              "      <td>2012</td>\n",
              "      <td>54590.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>19934.0</td>\n",
              "      <td>2143.0</td>\n",
              "      <td>137900.0</td>\n",
              "      <td>14258.0</td>\n",
              "      <td>42705.0</td>\n",
              "      <td>14637.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.1</td>\n",
              "      <td>35151.0</td>\n",
              "      <td>1726577.0</td>\n",
              "      <td>93.269</td>\n",
              "      <td>348.0</td>\n",
              "      <td>5266.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01001</td>\n",
              "      <td>2013</td>\n",
              "      <td>54907.0</td>\n",
              "      <td>37.5</td>\n",
              "      <td>20071.0</td>\n",
              "      <td>2149.0</td>\n",
              "      <td>136200.0</td>\n",
              "      <td>14132.0</td>\n",
              "      <td>43115.0</td>\n",
              "      <td>14392.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.3</td>\n",
              "      <td>35348.0</td>\n",
              "      <td>1618151.0</td>\n",
              "      <td>91.394</td>\n",
              "      <td>-156.0</td>\n",
              "      <td>-2643.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01001</td>\n",
              "      <td>2014</td>\n",
              "      <td>55136.0</td>\n",
              "      <td>37.9</td>\n",
              "      <td>20304.0</td>\n",
              "      <td>2127.0</td>\n",
              "      <td>136600.0</td>\n",
              "      <td>14272.0</td>\n",
              "      <td>43469.0</td>\n",
              "      <td>14214.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.8</td>\n",
              "      <td>36329.0</td>\n",
              "      <td>1629762.0</td>\n",
              "      <td>90.675</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1456.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01001</td>\n",
              "      <td>2015</td>\n",
              "      <td>55221.0</td>\n",
              "      <td>37.7</td>\n",
              "      <td>20396.0</td>\n",
              "      <td>2186.0</td>\n",
              "      <td>141300.0</td>\n",
              "      <td>14213.0</td>\n",
              "      <td>43775.0</td>\n",
              "      <td>14044.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>38107.0</td>\n",
              "      <td>1765826.0</td>\n",
              "      <td>90.622</td>\n",
              "      <td>144.0</td>\n",
              "      <td>-2565.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2e7af4f-db90-4f02-9722-fb868e416190')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d2e7af4f-db90-4f02-9722-fb868e416190 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d2e7af4f-db90-4f02-9722-fb868e416190');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4dabc9fb-7fd3-4d0f-bde7-ade946172c22\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4dabc9fb-7fd3-4d0f-bde7-ade946172c22')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4dabc9fb-7fd3-4d0f-bde7-ade946172c22 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migration DataFrame Descriptive Statistics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               YEAR  total_population    median_age  housing_total  \\\n",
              "count  34232.000000      3.423200e+04  34232.000000   3.423200e+04   \n",
              "mean    2016.000000      1.022781e+05     40.994070   3.803719e+04   \n",
              "std        3.162324      3.257760e+05      5.273044   1.147825e+05   \n",
              "min     2011.000000      6.200000e+01     21.400000   2.700000e+01   \n",
              "25%     2013.000000      1.120350e+04     37.900000   4.314750e+03   \n",
              "50%     2016.000000      2.600200e+04     40.900000   9.967500e+03   \n",
              "75%     2019.000000      6.814325e+04     44.000000   2.612200e+04   \n",
              "max     2021.000000      1.010572e+07     68.100000   3.342811e+06   \n",
              "\n",
              "              vacant  median_home_value  family_households  marital_total  \\\n",
              "count   34232.000000       3.423200e+04       3.423200e+04   3.423200e+04   \n",
              "mean     5259.126548       1.422936e+05       2.507476e+04   8.266592e+04   \n",
              "std     13028.854824       8.839130e+04       7.509575e+04   2.626099e+05   \n",
              "min        17.000000       2.130000e+04       1.500000e+01   5.200000e+01   \n",
              "25%       945.000000       8.890000e+04       2.889000e+03   9.122000e+03   \n",
              "50%      2003.000000       1.181000e+05       6.721500e+03   2.127300e+04   \n",
              "75%      4602.000000       1.640000e+05       1.744050e+04   5.532775e+04   \n",
              "max    245069.000000       1.225900e+06       2.216821e+06   8.246401e+06   \n",
              "\n",
              "       under_18_in_hh  education_total_sex  ...  Pop_Loss_2010  \\\n",
              "count    3.423200e+04         3.423200e+04  ...   34232.000000   \n",
              "mean     2.362357e+04         6.866025e+04  ...       0.168706   \n",
              "std      7.660182e+04         2.178339e+05  ...       0.374492   \n",
              "min      0.000000e+00         5.200000e+01  ...       0.000000   \n",
              "25%      2.495000e+03         7.755000e+03  ...       0.000000   \n",
              "50%      5.911500e+03         1.788750e+04  ...       0.000000   \n",
              "75%      1.529725e+04         4.593650e+04  ...       0.000000   \n",
              "max      2.421031e+06         6.922061e+06  ...       1.000000   \n",
              "\n",
              "       Retire_dest_cnty  Persistent_Pov_cnty  Pers_chld_pov_cnty  \\\n",
              "count      34232.000000         34232.000000        34232.000000   \n",
              "mean           0.141753             0.112472            0.225593   \n",
              "std            0.348748             0.315945            0.417962   \n",
              "min            0.000000             0.000000            0.000000   \n",
              "25%            0.000000             0.000000            0.000000   \n",
              "50%            0.000000             0.000000            0.000000   \n",
              "75%            0.000000             0.000000            0.000000   \n",
              "max            1.000000             1.000000            1.000000   \n",
              "\n",
              "       unemploy_rate        BEA_pci       BEA_gdp           RPP  \\\n",
              "count   34144.000000   34232.000000  3.423200e+04  34232.000000   \n",
              "mean        5.893737   42422.031204  6.115065e+06     90.984519   \n",
              "std         2.594445   12636.779840  2.661337e+07      6.287801   \n",
              "min         1.100000   14197.000000  5.420000e+03     80.236000   \n",
              "25%         4.000000   34465.750000  3.840980e+05     86.128000   \n",
              "50%         5.400000   40287.000000  1.001810e+06     89.162000   \n",
              "75%         7.300000   47224.250000  3.072656e+06     94.468500   \n",
              "max        28.900000  353263.000000  7.735713e+08    122.740000   \n",
              "\n",
              "          net_movers       net_agi  \n",
              "count   34232.000000  3.423200e+04  \n",
              "mean        8.779037  2.241578e+02  \n",
              "std      3196.026003  2.216224e+05  \n",
              "min   -141321.000000 -1.605755e+07  \n",
              "25%       -62.000000 -1.622000e+03  \n",
              "50%         0.000000  0.000000e+00  \n",
              "75%       122.000000  3.511000e+03  \n",
              "max    108999.000000  5.419300e+06  \n",
              "\n",
              "[8 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d608acb-f2df-4fe4-bb1b-eca267855e96\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YEAR</th>\n",
              "      <th>total_population</th>\n",
              "      <th>median_age</th>\n",
              "      <th>housing_total</th>\n",
              "      <th>vacant</th>\n",
              "      <th>median_home_value</th>\n",
              "      <th>family_households</th>\n",
              "      <th>marital_total</th>\n",
              "      <th>under_18_in_hh</th>\n",
              "      <th>education_total_sex</th>\n",
              "      <th>...</th>\n",
              "      <th>Pop_Loss_2010</th>\n",
              "      <th>Retire_dest_cnty</th>\n",
              "      <th>Persistent_Pov_cnty</th>\n",
              "      <th>Pers_chld_pov_cnty</th>\n",
              "      <th>unemploy_rate</th>\n",
              "      <th>BEA_pci</th>\n",
              "      <th>BEA_gdp</th>\n",
              "      <th>RPP</th>\n",
              "      <th>net_movers</th>\n",
              "      <th>net_agi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34144.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>34232.000000</td>\n",
              "      <td>3.423200e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>1.022781e+05</td>\n",
              "      <td>40.994070</td>\n",
              "      <td>3.803719e+04</td>\n",
              "      <td>5259.126548</td>\n",
              "      <td>1.422936e+05</td>\n",
              "      <td>2.507476e+04</td>\n",
              "      <td>8.266592e+04</td>\n",
              "      <td>2.362357e+04</td>\n",
              "      <td>6.866025e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.168706</td>\n",
              "      <td>0.141753</td>\n",
              "      <td>0.112472</td>\n",
              "      <td>0.225593</td>\n",
              "      <td>5.893737</td>\n",
              "      <td>42422.031204</td>\n",
              "      <td>6.115065e+06</td>\n",
              "      <td>90.984519</td>\n",
              "      <td>8.779037</td>\n",
              "      <td>2.241578e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3.162324</td>\n",
              "      <td>3.257760e+05</td>\n",
              "      <td>5.273044</td>\n",
              "      <td>1.147825e+05</td>\n",
              "      <td>13028.854824</td>\n",
              "      <td>8.839130e+04</td>\n",
              "      <td>7.509575e+04</td>\n",
              "      <td>2.626099e+05</td>\n",
              "      <td>7.660182e+04</td>\n",
              "      <td>2.178339e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.374492</td>\n",
              "      <td>0.348748</td>\n",
              "      <td>0.315945</td>\n",
              "      <td>0.417962</td>\n",
              "      <td>2.594445</td>\n",
              "      <td>12636.779840</td>\n",
              "      <td>2.661337e+07</td>\n",
              "      <td>6.287801</td>\n",
              "      <td>3196.026003</td>\n",
              "      <td>2.216224e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2011.000000</td>\n",
              "      <td>6.200000e+01</td>\n",
              "      <td>21.400000</td>\n",
              "      <td>2.700000e+01</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>2.130000e+04</td>\n",
              "      <td>1.500000e+01</td>\n",
              "      <td>5.200000e+01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>5.200000e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>14197.000000</td>\n",
              "      <td>5.420000e+03</td>\n",
              "      <td>80.236000</td>\n",
              "      <td>-141321.000000</td>\n",
              "      <td>-1.605755e+07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2013.000000</td>\n",
              "      <td>1.120350e+04</td>\n",
              "      <td>37.900000</td>\n",
              "      <td>4.314750e+03</td>\n",
              "      <td>945.000000</td>\n",
              "      <td>8.890000e+04</td>\n",
              "      <td>2.889000e+03</td>\n",
              "      <td>9.122000e+03</td>\n",
              "      <td>2.495000e+03</td>\n",
              "      <td>7.755000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>34465.750000</td>\n",
              "      <td>3.840980e+05</td>\n",
              "      <td>86.128000</td>\n",
              "      <td>-62.000000</td>\n",
              "      <td>-1.622000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2016.000000</td>\n",
              "      <td>2.600200e+04</td>\n",
              "      <td>40.900000</td>\n",
              "      <td>9.967500e+03</td>\n",
              "      <td>2003.000000</td>\n",
              "      <td>1.181000e+05</td>\n",
              "      <td>6.721500e+03</td>\n",
              "      <td>2.127300e+04</td>\n",
              "      <td>5.911500e+03</td>\n",
              "      <td>1.788750e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>40287.000000</td>\n",
              "      <td>1.001810e+06</td>\n",
              "      <td>89.162000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2019.000000</td>\n",
              "      <td>6.814325e+04</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.612200e+04</td>\n",
              "      <td>4602.000000</td>\n",
              "      <td>1.640000e+05</td>\n",
              "      <td>1.744050e+04</td>\n",
              "      <td>5.532775e+04</td>\n",
              "      <td>1.529725e+04</td>\n",
              "      <td>4.593650e+04</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.300000</td>\n",
              "      <td>47224.250000</td>\n",
              "      <td>3.072656e+06</td>\n",
              "      <td>94.468500</td>\n",
              "      <td>122.000000</td>\n",
              "      <td>3.511000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2021.000000</td>\n",
              "      <td>1.010572e+07</td>\n",
              "      <td>68.100000</td>\n",
              "      <td>3.342811e+06</td>\n",
              "      <td>245069.000000</td>\n",
              "      <td>1.225900e+06</td>\n",
              "      <td>2.216821e+06</td>\n",
              "      <td>8.246401e+06</td>\n",
              "      <td>2.421031e+06</td>\n",
              "      <td>6.922061e+06</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>353263.000000</td>\n",
              "      <td>7.735713e+08</td>\n",
              "      <td>122.740000</td>\n",
              "      <td>108999.000000</td>\n",
              "      <td>5.419300e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 85 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d608acb-f2df-4fe4-bb1b-eca267855e96')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9d608acb-f2df-4fe4-bb1b-eca267855e96 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9d608acb-f2df-4fe4-bb1b-eca267855e96');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fc21695c-7ae3-4731-8111-ec04e633e7ec\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fc21695c-7ae3-4731-8111-ec04e633e7ec')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fc21695c-7ae3-4731-8111-ec04e633e7ec button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Migration DataFrame Null Values:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unemploy_rate       88\n",
              "FIPS                 0\n",
              "total_population     0\n",
              "median_age           0\n",
              "housing_total        0\n",
              "                    ..\n",
              "BEA_pci              0\n",
              "BEA_gdp              0\n",
              "RPP                  0\n",
              "net_movers           0\n",
              "net_agi              0\n",
              "Length: 86, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>unemploy_rate</th>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIPS</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_population</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>median_age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing_total</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BEA_pci</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BEA_gdp</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RPP</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>net_movers</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>net_agi</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>86 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛⚛  \n",
        "All Below is from a different project, here for coding reference"
      ],
      "metadata": {
        "id": "TYQWrLl4ALNE"
      },
      "id": "TYQWrLl4ALNE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import MEDSL data (3 of 3)\n",
        "2020 general election results for most* (46) of the 50 states and D.C. downloaded from MEDSL (the MIT Election Data and Science Lab) https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/NT66Z3  \n",
        "\n",
        "* ALASKA: voting data is not gathered by county, MEDSL 'county_fips' is empty. Used https://www.elections.alaska.gov/results/20GENR/Map/ Votes aggregated to state senate districts (1 - 40). See accompanying 'Alaska County' amalgamation file on github for method used to match 30 census areas to 40 state senate districts. MEDSL datafile uses 14 County_fips created for this analysis. Datafile only has the 4 variables that will be utilized here.\n",
        "\n",
        "* INDIANA: MEDSL missing multiple county results. Used https://indianavoters.in.gov/ENRHistorical/ElectionResults  Datafile only has the 4 variables that will be utilized here, aggregated to the county level  \n",
        "\n",
        "* NEW MEXICO: To protect the privacy of voters, New Mexico 'masks' vote totals in precinct results for candidates with small vote tallies. Used https://electionstats.sos.nm.gov/contest/13250  Datafile only has the 4 variables that will be utilized here, aggregated to the county level  \n",
        "\n",
        "* NEVADA: To protect the privacy of voters, Nevada 'masks' vote totals in precinct results for candidates with 1-10 vote tallies. Used https://www.nvsos.gov/SOSelectionPages/results/2020StateWideGeneral/ElectionSummary.aspx  Datafile only has the 4 variables that will be utilized here, aggregated to the county level\n",
        "\n",
        "##Pre-import processing Notes:  \n",
        "The below adjustments were made to the MEDSL datafiles to standardize cleaning and processing.   \n",
        "\n",
        "1. HAWAII: Adjusted DHC and PUR data regarding Kalawao County, Hawaii. Both have fips 15005, but there are no official votes cast, removed so all files align  \n",
        "\n",
        "1. MAINE: Uniformed and Overseas Citizens Absentee Voting tallied seperately in 23000 fips, 23000 deleted to match DHC and PUR with votes added to 23005 (most populous county)  \n",
        "\n",
        "1. MICHIGAN: MEDSL precinct data contains precinct '9999', which are 'statistical adjustments' rows. There were minor corrections needed to match official results at https://www.michigan.gov/sos/elections/election-results-and-data/candidate-listings-and-election-results-by-county  \n",
        "\n",
        "1. MINNESOTA: 'DEMOCRATIC FARMER LABOR' party changed to 'DEMOCRAT'  \n",
        "\n",
        "1. MISSOURI: MEDSL tallied Kansas City votes seperately in 36000 fips. Utillized https://www.sos.mo.gov/CMSImages/ElectionResultsStatistics/November3_2020GeneralElection.pdf to aportion some votes to Jackson County with remainder assigned to Clay County (official results not available on https://www.voteclaycountymo.gov/election-results), but totals match State official numbers  \n",
        "\n",
        "1.  NEW YORK: 'CONSERVATIVE' party changed to 'REPUBLICAN'  \n",
        "'WORKING FAMILIES' party changed to 'DEMOCRAT'  \n",
        "\n",
        "1.  NORTH DAKOTA: 'DEMOCRATIC-NPL' party changed to 'DEMOCRAT' and 'county_fips' for OGLALA LAKOTA County changed from 46113 to 46102 to match data from DHC and PUR  \n",
        "\n",
        "1.  OREGON: Sherman County included cadidate 'BALLOTS CAST' which totaled all votes in each precinct: Deleted  \n",
        "\n",
        "1.  PENNSYLVANIA: 1 blank 'party_detailed' vote cast for Trump, party changed to 'REPUBLICAN'  \n",
        "\n",
        "1.  VERMONT: 3 blank 'party_detailed' votes cast for Trump, party changed to 'REPUBLICAN'  \n",
        "6 blank 'party_detailed' votes cast for Biden, party changed to 'DEMOCRAT'  \n",
        "\n",
        "##Post-import cleaning Notes:\n",
        "1.  All blanks in 'party_detailed' have been verified as writein votes cast for 'THIRD' party candidates  \n",
        "\n",
        "2.  In Nov 2020, there were over 50 recognized political parties in the US.  \n",
        "DEM and REP ballots accounted for 96% of total votes. Third parties accounted for 1-4% of the vote in each state. 'THIRD' will combine any vote NOT for Presidents Biden or Trump.  \n",
        "\n"
      ],
      "metadata": {
        "id": "3BLXE3tAg-ZV"
      },
      "id": "3BLXE3tAg-ZV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (with MERGED_DF)"
      ],
      "metadata": {
        "id": "Db35tTfshpfU"
      },
      "id": "Db35tTfshpfU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup exploration environment\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "print('Environment Ready')"
      ],
      "metadata": {
        "id": "vCHwEDBjtOhJ"
      },
      "id": "vCHwEDBjtOhJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6416223-79d2-4eea-8253-104ed250f502",
      "metadata": {
        "id": "d6416223-79d2-4eea-8253-104ed250f502",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "MERGED_DF = pd.read_csv('MERGED_DF.csv')\n",
        "# ensure GEOID is an object\n",
        "MERGED_DF['GEOID'] = MERGED_DF['GEOID'].astype(str)\n",
        "\n",
        "# Confirm\n",
        "print(MERGED_DF.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Information"
      ],
      "metadata": {
        "id": "digFEi-Pf4-E"
      },
      "id": "digFEi-Pf4-E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0b7a653"
      },
      "source": [
        "# Display descriptive statistics for numerical columns\n",
        "print('Number of rows:', MERGED_DF.shape[0], '(Number of counties)')\n",
        "print('Number of columns:', MERGED_DF.shape[1])\n",
        "print('\\nMissing Values: None')\n",
        "print(MERGED_DF.isna().sum().sort_values(ascending=False))\n",
        "\n",
        "print('\\nDescriptive Statistics for Numerical Columns:')\n",
        "display(MERGED_DF.describe())\n",
        "\n",
        "# Display value counts for categorical column (PARTY_WIN)\n",
        "print('\\nValue Counts for 'PARTY_WIN' \\n0: Republican Win\\n1: Democrat Win:')\n",
        "display(MERGED_DF['PARTY_WIN'].value_counts())"
      ],
      "id": "a0b7a653",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizations"
      ],
      "metadata": {
        "id": "6U447_NdnbvO"
      },
      "id": "6U447_NdnbvO"
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the distribution of the target variable 'PARTY_WIN'\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='PARTY_WIN', data=MERGED_DF)\n",
        "plt.title('Distribution of PARTY_WIN (0: Republican Win, 1: Democrat Win)')\n",
        "plt.xlabel('Party Win')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks([0, 1], ['Republican Win', 'Democrat Win'])\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "# Visualize the distribution of 'PARTY_LEAD'\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
        "sns.histplot(MERGED_DF['DEM_SHARE'], bins=30, kde=True, ax=axes[0], color='blue')\n",
        "axes[0].set_title('Democratic Vote Share')\n",
        "sns.histplot(MERGED_DF['REP_SHARE'], bins=30, kde=True, ax=axes[1], color='red')\n",
        "axes[1].set_title('Republican Vote Share')\n",
        "sns.histplot(MERGED_DF['PARTY_LEAD'], bins=30, kde=True, ax=axes[2], color='purple')\n",
        "axes[2].set_title('Margin of Victory (Party Lead)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.histplot(MERGED_DF['Pop_total'], bins=50, kde=True)\n",
        "plt.title('County Population Distribution')\n",
        "plt.xlabel('Population')\n",
        "plt.ylabel('Number of Counties')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.histplot(MERGED_DF['%Urban_pop'], bins=30, kde=True)\n",
        "plt.title('Urban Population Share by County')\n",
        "plt.xlabel('% Urban Population')\n",
        "plt.ylabel('Number of Counties')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.histplot(MERGED_DF['MED_AGE'], bins=30, kde=True)\n",
        "plt.title('Median Age Distribution')\n",
        "plt.xlabel('Median Age')\n",
        "plt.ylabel('Number of Counties')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "race_cols = ['%RACE_White', '%RACE_Black', '%RACE_Latino', '%RACE_Asian']\n",
        "MERGED_DF[race_cols].plot(kind='box', figsize=(8,6))\n",
        "plt.title('Distribution of Racial Composition by County')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.scatterplot(x='%OWN_HOME', y='%RENT_HOME', data=MERGED_DF)\n",
        "plt.title('Own vs Rent in Counties')\n",
        "plt.xlabel('% Own Home')\n",
        "plt.ylabel('% Rent Home')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.scatterplot(x='%Urban_pop', y='DEM_SHARE', data=MERGED_DF, alpha=0.6)\n",
        "plt.title('Urban Population vs Democratic Vote Share')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.scatterplot(x='%RACE_White', y='REP_SHARE', data=MERGED_DF, alpha=0.6, color='red')\n",
        "plt.title('% White Population vs Republican Vote Share')\n",
        "plt.show()\n",
        "\n",
        "print('')\n",
        "sns.scatterplot(x='MED_AGE', y='REP_SHARE', data=MERGED_DF, alpha=0.6, color='green')\n",
        "plt.title('Median Age vs Republican Vote Share')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "71v2mSxuncdD"
      },
      "id": "71v2mSxuncdD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation checks on separated groups of features"
      ],
      "metadata": {
        "id": "bu3scl36eF51"
      },
      "id": "bu3scl36eF51"
    },
    {
      "cell_type": "code",
      "source": [
        "#corr_vars = ['Pop_total', 'MED_AGE', '%Urban_pop',\n",
        "#             '%RACE_White', '%RACE_Black', '%RACE_Latino',\n",
        "#             '%OWN_HOME', '%RENT_HOME',\n",
        "#             'DEM_SHARE', 'REP_SHARE', 'PARTY_LEAD']\n",
        "\n",
        "#corr = MERGED_DF[corr_vars].corr()\n",
        "MERGED_num = MERGED_DF.select_dtypes(include=np.number)\n",
        "\n",
        "corr = MERGED_num.corr()\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=False, fmt='.2f', cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LmiEfl2TP3ZD"
      },
      "id": "LmiEfl2TP3ZD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze Age data"
      ],
      "metadata": {
        "id": "T6sApGow-rrc"
      },
      "id": "T6sApGow-rrc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0cb92f9"
      },
      "source": [
        "# Create new working dataframe\n",
        "MERGED_trform = MERGED_DF.copy()\n",
        "\n",
        "# Define column groups for total, male, and female age percentages\n",
        "age_total_cols = [\n",
        "    col for col in MERGED_trform.columns if col.startswith('%TOTAL_')]\n",
        "age_male_cols  = [\n",
        "    col for col in MERGED_trform.columns if col.startswith('%MALE_')]\n",
        "age_female_cols = [\n",
        "    col for col in MERGED_trform.columns if col.startswith('%FEMALE_')]\n",
        "\n",
        "# Combine all percentage age columns and the target variables\n",
        "features_for_age = age_total_cols + age_male_cols + age_female_cols + [\n",
        "    'PARTY_WIN', 'PARTY_LEAD']\n",
        "\n",
        "# Calculate the correlation matrix for the selected features\n",
        "corr_age = MERGED_trform[features_for_age].corr()\n",
        "\n",
        "# Select and display only the correlations with PARTY_WIN and PARTY_LEAD\n",
        "corr_age_subset = corr_age[['PARTY_WIN', 'PARTY_LEAD']].loc[\n",
        "    age_total_cols + age_male_cols + age_female_cols]\n",
        "\n",
        "# Plot heatmap for better visualization of correlations\n",
        "plt.figure(figsize=(10, 15)) # Adjust figure size as needed\n",
        "sns.heatmap(corr_age_subset,\n",
        "            cmap='seismic_r',\n",
        "            annot=True, fmt='.2f',\n",
        "            vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap: Percentage Age Groups vs PARTY_WIN and PARTY_LEAD')\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "id": "d0cb92f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With a clear divergence around age 55, compare 2 vs 3 age groupings  \n",
        "- yng, mid, old: Looks to break groups into pos, neutral (between -0.1 and 0.1), neg  \n",
        "- young, older: Looks to break age groups into positive and negative only  "
      ],
      "metadata": {
        "id": "StFYlTn8-4pI"
      },
      "id": "StFYlTn8-4pI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4506464d",
        "collapsed": true
      },
      "source": [
        "# Define lists of age columns for young, middle (cutoff is |0.1|), and old\n",
        "age_male_yng = [col for col in MERGED_trform.columns if col.startswith('%MALE_') and any(age in col for age in ['18_19', '20_24', '25_29', '30_34', '35_39'])]\n",
        "age_male_mid = [col for col in MERGED_trform.columns if col.startswith('%MALE_') and any(age in col for age in ['40_44', '45_49', '50_54'])]\n",
        "age_male_old = [col for col in MERGED_trform.columns if col.startswith('%MALE_') and any(age in col for age in ['55_59', '60_64', '65_69', '70_74', '75_79', '80_84', '85+'])]\n",
        "age_female_yng = [col for col in MERGED_trform.columns if col.startswith('%FEMALE_') and any(age in col for age in ['18_19', '20_24', '25_29', '30_34', '35_39', '40_44'])]\n",
        "age_female_mid = [col for col in MERGED_trform.columns if col.startswith('%FEMALE_') and any(age in col for age in ['45_49', '50_54'])]\n",
        "age_female_old = [col for col in MERGED_trform.columns if col.startswith('%FEMALE_') and any(age in col for age in ['55_59', '60_64', '65_69', '70_74', '75_79', '80_84', '85+'])]\n",
        "\n",
        "# Define lists of age columns for young (cutoff is 0) and older\n",
        "age_male_young = [col for col in MERGED_trform.columns if col.startswith('%MALE_') and any(age in col for age in ['18_19', '20_24', '25_29', '30_34', '35_39', '40_44', '45_49'])]\n",
        "age_male_older = [col for col in MERGED_trform.columns if col.startswith('%MALE_') and any(age in col for age in ['50_54', '55_59', '60_64', '65_69', '70_74', '75_79', '80_84', '85+'])]\n",
        "age_female_young = [col for col in MERGED_trform.columns if col.startswith('%FEMALE_') and any(age in col for age in ['18_19', '20_24', '25_29', '30_34', '35_39', '40_44', '45_49', '50_54'])]\n",
        "age_female_older = [col for col in MERGED_trform.columns if col.startswith('%FEMALE_') and any(age in col for age in ['55_59', '60_64', '65_69', '70_74', '75_79', '80_84', '85+'])]\n",
        "\n",
        "# Calculate the new aggregated percentage age groups\n",
        "MERGED_trform['%AGE_MALE_YNG'] = MERGED_trform[age_male_yng].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_MALE_MID'] = MERGED_trform[age_male_mid].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_MALE_OLD'] = MERGED_trform[age_male_old].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_MALE_YOUNG'] = MERGED_trform[age_male_young].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_MALE_OLDER'] = MERGED_trform[age_male_older].sum(axis=1).round(2)\n",
        "\n",
        "MERGED_trform['%AGE_FEMALE_YNG'] = MERGED_trform[age_female_yng].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_FEMALE_MID'] = MERGED_trform[age_female_mid].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_FEMALE_OLD'] = MERGED_trform[age_female_old].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_FEMALE_YOUNG'] = MERGED_trform[age_female_young].sum(axis=1).round(2)\n",
        "MERGED_trform['%AGE_FEMALE_OLDER'] = MERGED_trform[age_female_older].sum(axis=1).round(2)\n",
        "\n",
        "# Confirm\n",
        "print(MERGED_trform.info())\n",
        "print(MERGED_trform.head())"
      ],
      "id": "4506464d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze race groups"
      ],
      "metadata": {
        "id": "7iSBoE5IFpZ2"
      },
      "id": "7iSBoE5IFpZ2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61a03ee5"
      },
      "source": [
        "# Define the list of race percentage columns\n",
        "race_cols = [col for col in MERGED_trform.columns if col.startswith('%RACE_')]\n",
        "\n",
        "# Combine race percentage columns and the target variables\n",
        "features_for_race = race_cols + ['PARTY_WIN', 'PARTY_LEAD']\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_race = MERGED_trform[features_for_race].corr()\n",
        "\n",
        "# Select and display only the correlations with PARTY_WIN and PARTY_LEAD\n",
        "corr_race_subset = corr_race[['PARTY_WIN', 'PARTY_LEAD']].loc[race_cols]\n",
        "\n",
        "# Display the correlations\n",
        "print('Correlation of Race/Ethnic Group Percentages with PARTY_WIN and PARTY_LEAD:')\n",
        "display(corr_race_subset.sort_values(by='PARTY_LEAD', key=abs, ascending=False))\n",
        "\n",
        "# Plot heatmap for better visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_race_subset, cmap='seismic_r', annot=True, fmt='.2f', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap: Race/Ethnic Group Percentages vs PARTY_WIN and PARTY_LEAD')\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "id": "61a03ee5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With clear racial differences, I will try two variations of race groups  \n",
        "- White and Non-White  \n",
        "- White, strong political lean, more neutral lean"
      ],
      "metadata": {
        "id": "emS9onA2FBET"
      },
      "id": "emS9onA2FBET"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define lists to compare 2 groups: non-whites or with a cutoff of |0.2|\n",
        "RACE_NonWhite = [col for col in MERGED_trform.columns if col.startswith('%RACE_') and any(race in col for race in ['Asian', 'Black', 'Other', 'Latino', 'Native', 'HI_PI', 'Mixed'])]\n",
        "RACE_BAO = [col for col in MERGED_trform.columns if col.startswith('%RACE_') and any(race in col for race in ['Black', 'Asian', 'Other'])]\n",
        "RACE_LNHM = [col for col in MERGED_trform.columns if col.startswith('%RACE_') and any(race in col for race in ['Latino', 'Native', 'HI_PI', 'Mixed'])]\n",
        "\n",
        "# Calculate the new aggregated percentage race groups\n",
        "MERGED_trform['%RACE_NonWhite'] = MERGED_trform[RACE_NonWhite].sum(axis=1).round(2)\n",
        "MERGED_trform['%RACE_BAO'] = MERGED_trform[RACE_BAO].sum(axis=1).round(2)\n",
        "MERGED_trform['%RACE_LNHM'] = MERGED_trform[RACE_LNHM].sum(axis=1).round(2)"
      ],
      "metadata": {
        "id": "6UnXrijUFOiU"
      },
      "id": "6UnXrijUFOiU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze relationship groups"
      ],
      "metadata": {
        "id": "lFf97gr-gqR_"
      },
      "id": "lFf97gr-gqR_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc56dff3"
      },
      "source": [
        "# Filter for columns starting with '%REL_'\n",
        "rel_cols = [col for col in MERGED_trform.columns if col.startswith('%REL_')]\n",
        "\n",
        "# Calculate the correlation of these columns with PARTY_WIN and PARTY_LEAD\n",
        "corr_rel = MERGED_trform[rel_cols + ['PARTY_WIN', 'PARTY_LEAD']].corr()\n",
        "\n",
        "# Select and display only the correlations with PARTY_WIN and PARTY_LEAD\n",
        "corr_rel_subset = corr_rel[['PARTY_WIN', 'PARTY_LEAD']].loc[rel_cols]\n",
        "\n",
        "# Display the correlations\n",
        "print('Correlation of Relationship Variables with PARTY_WIN and PARTY_LEAD:')\n",
        "display(corr_rel_subset.sort_values(by='PARTY_LEAD', key=abs, ascending=False))\n",
        "\n",
        "# Optional: Visualize correlations as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_rel_subset,\n",
        "            cmap='seismic_r',\n",
        "            annot=True, fmt='.2f',\n",
        "            vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap: Relationship Variables vs PARTY_WIN and PARTY_LEAD')\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "id": "dc56dff3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyze household groups"
      ],
      "metadata": {
        "id": "Yodje20Rg4cx"
      },
      "id": "Yodje20Rg4cx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for columns starting with '%HH_'\n",
        "hh_cols = [col for col in MERGED_trform.columns if col.startswith('%HH_')]\n",
        "\n",
        "# Add own and urban columns\n",
        "hh_cols.extend(['%OWN_HOME', '%Urban_pop'])\n",
        "\n",
        "# Correlate these columns with PARTY_WIN and PARTY_LEAD\n",
        "corr_hh = MERGED_trform[hh_cols + ['PARTY_WIN', 'PARTY_LEAD']].corr()\n",
        "\n",
        "# Select and display only the correlations with PARTY_WIN and PARTY_LEAD\n",
        "corr_hh_subset = corr_hh[['PARTY_WIN', 'PARTY_LEAD']].loc[hh_cols]\n",
        "\n",
        "# Display the correlations\n",
        "print('Correlation of Household, Ownership, and Urban Variables with PARTY_WIN and PARTY_LEAD:')\n",
        "display(corr_hh_subset.sort_values(by='PARTY_LEAD', key=abs, ascending=False))\n",
        "\n",
        "# Optional: Visualize correlations as a heatmap\n",
        "plt.figure(figsize=(8, 10)) # Adjusted figure size\n",
        "sns.heatmap(corr_hh_subset,\n",
        "            cmap='seismic_r',\n",
        "            annot=True, fmt='.2f',\n",
        "            vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap: Household, Ownership, and Urban Variables vs PARTY_WIN and PARTY_LEAD')\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OpxhE7HlN6D3"
      },
      "id": "OpxhE7HlN6D3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save VOTE_DF"
      ],
      "metadata": {
        "id": "XQzEWtOiy6hj"
      },
      "id": "XQzEWtOiy6hj"
    },
    {
      "cell_type": "code",
      "source": [
        "# List columns to keep (drop HH_totals, only keep M_total and F_total as ref)\n",
        "columns_to_keep = [\n",
        "    'GEOID', 'Male_total', 'Female_total', '%AGE_MALE_YNG', '%AGE_MALE_MID', '%AGE_MALE_OLD', '%AGE_MALE_YOUNG', '%AGE_MALE_OLDER', '%AGE_FEMALE_YNG', '%AGE_FEMALE_MID', '%AGE_FEMALE_OLD', '%AGE_FEMALE_YOUNG', '%AGE_FEMALE_OLDER', '%RACE_White', '%RACE_Black', '%RACE_Latino', '%RACE_Native', '%RACE_Asian', '%RACE_HI_PI', '%RACE_Other', '%RACE_Mixed', '%RACE_NonWhite', '%RACE_BAO', '%RACE_LNHM', '%REL_OP_SEX_MAR', '%REL_OP_SEX_UNMAR', '%REL_S_SEX_MAR', '%REL_S_SEX_UNMAR', '%REL_W_RELATIVES', '%REL_NON_REL', '%REL_MALE_JAILED', '%REL_FEMALE_JAILED', '%REL_MALE_GRP_DORM', '%REL_FEMALE_GRP_DORM', '%HH_MARRIED', '%HH_MAR_W_KIDS','%HH_NOT_MAR',  '%HH_NOT_MAR_W_KIDS', '%HH_MALE_ALONE', '%HH_MALE_65+', '%HH_MALE_W_KIDS', '%HH_FEMALE_ALONE', '%HH_FEMALE_65+', '%HH_FEMALE_W_KIDS', '%OWN_HOME', '%Urban_pop', 'PARTY_WIN', 'PARTY_LEAD']\n",
        "\n",
        "# Create VOTE dataframe\n",
        "VOTE_DF = MERGED_trform[columns_to_keep].copy()\n",
        "\n",
        "VOTE_DF.to_csv('VOTE_DF.csv', index=False)"
      ],
      "metadata": {
        "id": "GcrFAQVraqCb",
        "collapsed": true
      },
      "id": "GcrFAQVraqCb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA complete; dataframe cleaned, merged, transformed, partially reduced, and ready for analysis"
      ],
      "metadata": {
        "id": "DVfNdSAXw94R"
      },
      "id": "DVfNdSAXw94R"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature analysis (with VOTE_DF)"
      ],
      "metadata": {
        "id": "02vUwlYly7Bl"
      },
      "id": "02vUwlYly7Bl"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import numpy.typing as npt\n",
        "import statsmodels.api as sm\n",
        "from typing import Literal, Tuple, Union\n",
        "from scipy.stats import shapiro, mannwhitneyu, rankdata, norm\n",
        "from sklearn.linear_model import LogisticRegression, LassoCV\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error, r2_score, mean_absolute_error, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.inspection import permutation_importance, PartialDependenceDisplay\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.multivariate.manova import MANOVA\n",
        "from collections import Counter\n",
        "%matplotlib inline\n",
        "print('Environment Ready')"
      ],
      "metadata": {
        "id": "SkOYUXVGtj34"
      },
      "id": "SkOYUXVGtj34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import VOTE_DF file here for analysis of features\n",
        "(Looked at feature interactions as well, but opted to keep simple as few improved modeling)"
      ],
      "metadata": {
        "id": "AiJlPNEASeb_"
      },
      "id": "AiJlPNEASeb_"
    },
    {
      "cell_type": "code",
      "source": [
        "VOTE_DF = pd.read_csv('VOTE_DF.csv')\n",
        "# ensure GEOID is an object\n",
        "VOTE_DF['GEOID'] = VOTE_DF['GEOID'].astype(str)\n",
        "\n",
        "# Inspect\n",
        "#print(VOTE_DF.info())"
      ],
      "metadata": {
        "id": "-3Mwukkuy-ex"
      },
      "id": "-3Mwukkuy-ex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variance check"
      ],
      "metadata": {
        "id": "fzazFZcGgG69"
      },
      "id": "fzazFZcGgG69"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numerical columns\n",
        "VOTE_num = VOTE_DF.select_dtypes(include=np.number)\n",
        "\n",
        "variances = VOTE_num.var()\n",
        "\n",
        "# Sort variances in descending order\n",
        "var_sorted = variances.sort_values(ascending=True)\n",
        "\n",
        "# Set pandas display option to show float format\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "# Confirm (Consider dropping features with low variance >0.05)\n",
        "print('\\nFeature Variances (sorted):')\n",
        "print(var_sorted.head(20))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-MYZcsF3-A2l"
      },
      "execution_count": null,
      "outputs": [],
      "id": "-MYZcsF3-A2l"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0ddeafb"
      },
      "source": [
        "## Compute VIF for VOTE_DF"
      ],
      "id": "b0ddeafb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98e045b4"
      },
      "source": [
        "# Remove independent variables\n",
        "VOTE_features = VOTE_num.drop(columns=['PARTY_WIN', 'PARTY_LEAD'])\n",
        "\n",
        "# Add required constant\n",
        "VOTE_features = sm.add_constant(VOTE_features)\n",
        "\n",
        "# Compute Variance Inflation Factor for each feature\n",
        "VOTE_VIF = pd.DataFrame()\n",
        "VOTE_VIF['Feature'] = VOTE_features.columns\n",
        "# Compute VIF, handling potential inf values which occur with perfect multicollinearity\n",
        "VOTE_VIF['VIF'] = [variance_inflation_factor(VOTE_features.values, i) for i in range(VOTE_features.shape[1])]\n",
        "\n",
        "# Sort by VIF in descending order for easier analysis\n",
        "VOTE_VIF = VOTE_VIF.sort_values(by='VIF', ascending=False)\n",
        "\n",
        "# Set display to show float format\n",
        "pd.set_option('display.float_format', '{:.2f}'.format)\n",
        "\n",
        "print('VIF for VOTE_DF:')\n",
        "display(VOTE_VIF)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "98e045b4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlations"
      ],
      "metadata": {
        "id": "x0ZNe24WqY2G"
      },
      "id": "x0ZNe24WqY2G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "946999ad"
      },
      "source": [
        "## Pearson Correlation Matrix"
      ],
      "id": "946999ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "20233d7d"
      },
      "source": [
        "# Compute Pearson correlation matrix\n",
        "pearson_corr_matrix = VOTE_DF.corr(method='pearson')\n",
        "\n",
        "# Display the correlations\n",
        "print('Pearson Correlation Matrix:')\n",
        "display(pearson_corr_matrix)\n",
        "\n",
        "# Sort Pearson correlations with PARTY_WIN and PARTY_LEAD\n",
        "pearson_corr_win = pearson_corr_matrix['PARTY_WIN'].sort_values(ascending=False)\n",
        "pearson_corr_lead = pearson_corr_matrix['PARTY_LEAD'].sort_values(ascending=False)"
      ],
      "id": "20233d7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf3b66a"
      },
      "source": [
        "## Spearman Correlation Matrix"
      ],
      "id": "2bf3b66a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "a6cc88d6"
      },
      "source": [
        "# Compute Spearman correlation matrix\n",
        "spearman_corr_matrix = VOTE_DF.corr(method='spearman')\n",
        "\n",
        "# Display the correlations\n",
        "print('\\nSpearman Correlation Matrix:')\n",
        "display(spearman_corr_matrix)\n",
        "\n",
        "# Sort and store Spearman correlation results\n",
        "spearman_corr_win = spearman_corr_matrix['PARTY_WIN'].sort_values(ascending=False)\n",
        "spearman_corr_lead = spearman_corr_matrix['PARTY_LEAD'].sort_values(ascending=False)"
      ],
      "id": "a6cc88d6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatterjee's Correlation  \n",
        "In 2020, a paper titled 'A New Coefficient of Correlation' introduced a new coefficient measure ξ (“Xi”) which measures how much the dependent variable is a function of the independent. The result equals 0 if the two variables are independent and will be closer to 1 as the relationship strengthens. Also includes some theoretical properties that allow for hypothesis testing prior to making assumptions about the data.  \n",
        "\n",
        "Along with the article, the R package 'XICOR' was released which contains the function xicor() which calculates ξ when X and Y vectors or matrices are provided (provides p-values for hypothesis testing).\n",
        "\n",
        "S. Chatterjee, *A New Coefficient of Correlation* (2020), Journal of the American Statistical Association.\n",
        "https://doi.org/10.48550/arXiv.1909.10140\n",
        "\n",
        "The below code is a python xicor function based on one written by Tim Sumner https://medium.com/data-science/a-new-coefficient-of-correlation-64ae4f260310"
      ],
      "metadata": {
        "id": "UyZcNq2_fayo"
      },
      "id": "UyZcNq2_fayo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Chatterjee's Correlation\n",
        "def xicor(X, Y, ties='auto', return_p=True):\n",
        "    np.random.seed(1)\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    Y_sorted = Y[np.argsort(X)]\n",
        "    n = len(X)\n",
        "\n",
        "    if ties == 'auto':\n",
        "        ties = len(np.unique(Y)) < n\n",
        "\n",
        "    if ties:\n",
        "        r = rankdata(Y_sorted, method='ordinal')\n",
        "        l = rankdata(Y_sorted, method='max')\n",
        "        xi = 1 - n * np.sum(np.abs(np.diff(r))) / (2 * np.sum(l * (n - l)))\n",
        "    else:\n",
        "        r = rankdata(Y_sorted, method='ordinal')\n",
        "        xi = 1 - 3 * np.sum(np.abs(np.diff(r))) / (n**2 - 1)\n",
        "\n",
        "# p-value approximation\n",
        "    p_value = norm.sf(xi, scale=2/5/np.sqrt(n))\n",
        "\n",
        "    if return_p:\n",
        "        return xi, p_value\n",
        "    else:\n",
        "        return xi\n",
        "\n",
        "# Define the independent and dependent variables\n",
        "features = [col for col in VOTE_DF.columns if col not in [\n",
        "    'PARTY_WIN', 'PARTY_LEAD',\n",
        "    'Male_total', 'Female_total']]\n",
        "\n",
        "target_win = VOTE_DF['PARTY_WIN']\n",
        "target_lead = VOTE_DF['PARTY_LEAD']\n",
        "\n",
        "# Store xicor results\n",
        "xicor_results_win = {}\n",
        "xicor_results_lead = {}\n",
        "\n",
        "# Compute xicor for each feature against PARTY_WIN\n",
        "for feature in features:\n",
        "    x_data = VOTE_DF[feature]\n",
        "    xi_stat, xi_p_value = xicor(x_data, target_win)\n",
        "    xicor_results_win[feature] = {'statistic': xi_stat, 'p_value': xi_p_value}\n",
        "    #print(f'{feature}: Statistic={xi_stat:.2f}, P-value={xi_p_value:.2f}')\n",
        "\n",
        "# Compute xicor for each feature against PARTY_LEAD\n",
        "for feature in features:\n",
        "    x_data = VOTE_DF[feature]\n",
        "    xi_stat, xi_p_value = xicor(x_data, target_lead)\n",
        "    xicor_results_lead[feature] = {'statistic': xi_stat, 'p_value': xi_p_value}\n",
        "    #print(f'{feature}: Statistic={xi_stat:.2f}, P-value={xi_p_value:.2f}')\n",
        "\n",
        "# Store Chatterjee correlation results\n",
        "xi_corr_win = pd.DataFrame.from_dict(xicor_results_win, orient='index')\n",
        "xi_corr_lead = pd.DataFrame.from_dict(xicor_results_lead, orient='index')"
      ],
      "metadata": {
        "id": "jN_NUj06zQc1"
      },
      "id": "jN_NUj06zQc1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Correlation Coefficients"
      ],
      "metadata": {
        "id": "GWZ-52yYuVVY"
      },
      "id": "GWZ-52yYuVVY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all correlation results into a single DataFrame\n",
        "correlation_comparison = pd.concat([\n",
        "    xi_corr_lead['statistic'].rename('Xi_Corr_LEAD'),\n",
        "    xi_corr_win['statistic'].rename('Xi_Corr_WIN'),\n",
        "    pearson_corr_lead,\n",
        "    pearson_corr_win,\n",
        "    spearman_corr_lead,\n",
        "    spearman_corr_win,\n",
        "], axis=1)\n",
        "\n",
        "# Remove the target variables  if included\n",
        "correlation_comparison.drop(['PARTY_WIN', 'PARTY_LEAD'], errors='ignore', inplace=True)\n",
        "\n",
        "# Rename features\n",
        "Correlation_Table = correlation_comparison.rename(columns={\n",
        "    'Pearson_Corr_PARTY_LEAD': 'Pearson_LEAD',\n",
        "    'Pearson_Corr_PARTY_WIN': 'Pearson_WIN',\n",
        "    'Spearman_Corr_PARTY_LEAD': 'Spearman_LEAD',\n",
        "    'Spearman_Corr_PARTY_WIN': 'Spearman_WIN'})\n",
        "\n",
        "# Display all correlations\n",
        "print('Comparison of Xi, Pearson, and Spearman Correlations:')\n",
        "display(Correlation_Table.round(4).sort_values(by='Xi_Corr_LEAD', ascending=False))"
      ],
      "metadata": {
        "id": "TeAT4snMuSuQ"
      },
      "id": "TeAT4snMuSuQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d525c65"
      },
      "source": [
        "# Statistical test (Test for normality first)  \n"
      ],
      "id": "6d525c65"
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the dataframe into two groups based on PARTY_WIN\n",
        "group_Republican = VOTE_num[VOTE_num['PARTY_WIN'] == 0]\n",
        "group_Democrat = VOTE_num[VOTE_num['PARTY_WIN'] == 1]\n",
        "\n",
        "features_for_norm = VOTE_num.columns.tolist()\n",
        "features_for_norm.remove('PARTY_WIN')\n",
        "\n",
        "normality_results = {}\n",
        "\n",
        "for feature in features_for_norm:\n",
        "    data1 = group_Republican[feature]\n",
        "    data2 = group_Democrat[feature]\n",
        "\n",
        "    if len(data1) > 2 and len(data2) > 2:\n",
        "        stat1, p_norm1 = shapiro(data1)\n",
        "        stat2, p_norm2 = shapiro(data2)\n",
        "\n",
        "        normality_results[feature] = {\n",
        "            'Rep_p': f'{p_norm1:.2f}',\n",
        "            'Dem_p': f'{p_norm2:.2f}'}\n",
        "    else:\n",
        "        normality_results[feature] = {\n",
        "            'Rep_p': None,\n",
        "            'Dem_p': None}\n",
        "\n",
        "# Convert to DataFrame\n",
        "normality_df = pd.DataFrame(normality_results).T\n",
        "\n",
        "# Confirm (Normality will be defined as above a threshhold of 0.05)\n",
        "print(normality_df)"
      ],
      "metadata": {
        "id": "PB0iFHm4Gbl4"
      },
      "id": "PB0iFHm4Gbl4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Almost every feature is way below 0.05 in both groups: normality is violated with one exception: Will not use T-test.\n",
        "\n",
        "## Run Mann-Whitney U Test"
      ],
      "metadata": {
        "id": "hxMHyq_zIdAs"
      },
      "id": "hxMHyq_zIdAs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0988c1d4"
      },
      "source": [
        "mannwhit_results = []\n",
        "\n",
        "for feature in features_for_norm:\n",
        "    if feature == 'PARTY_LEAD':\n",
        "        continue\n",
        "\n",
        "    data1 = group_Republican[feature]\n",
        "    data2 = group_Democrat[feature]\n",
        "\n",
        "    if len(data1) < 2 or len(data2) < 2:\n",
        "        continue\n",
        "\n",
        "    U_stat, p_value = mannwhitneyu(data1, data2, alternative='two-sided')\n",
        "\n",
        "    if p_value < 0.05:\n",
        "        mannwhit_results.append({\n",
        "            'Feature': feature,\n",
        "            'DEM_median': data2.median(),\n",
        "            'REP_median': data1.median(),\n",
        "            'U_stat': U_stat,\n",
        "            'p_value': p_value,\n",
        "            'n_dem': len(data2),\n",
        "            'n_rep': len(data1)})\n",
        "\n",
        "mannwhit_df = pd.DataFrame(mannwhit_results)\n",
        "\n",
        "# Derive additional stats\n",
        "mannwhit_df['diff_median'] = mannwhit_df['DEM_median'] - mannwhit_df['REP_median']\n",
        "\n",
        "mannwhit_df['R_biserial'] = 1 - (2 * mannwhit_df['U_stat'] / (\n",
        "                            mannwhit_df['n_dem'] * mannwhit_df['n_rep']))\n",
        "\n",
        "mannwhit_df['Cohens_d'] = (2 * mannwhit_df['R_biserial']\n",
        "                          ) / np.sqrt(1 - mannwhit_df['R_biserial']**2)\n",
        "\n",
        "# Add qualitative labels\n",
        "def label_effect_size(d):\n",
        "    d = abs(d)\n",
        "    if d < 0.2:\n",
        "        return 'Negligible'\n",
        "    elif d < 0.5:\n",
        "        return 'Small'\n",
        "    elif d < 0.8:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Large'\n",
        "\n",
        "mannwhit_df['Effect_size'] = mannwhit_df['Cohens_d'].astype(float).apply(label_effect_size)\n",
        "\n",
        "# Reorder columns for priority in table (consider dropping n_ features)\n",
        "cols = mannwhit_df.columns.tolist()\n",
        "cols.insert(3, cols.pop(cols.index('diff_median')))\n",
        "cols.insert(5, cols.pop(cols.index('Cohens_d')))\n",
        "cols.insert(6, cols.pop(cols.index('Effect_size')))\n",
        "cols.insert(7, cols.pop(cols.index('R_biserial')))\n",
        "mannwhit_df = mannwhit_df[cols]\n",
        "\n",
        "# Format after sorting\n",
        "mannwhit_df['DEM_median'] = mannwhit_df['DEM_median'].map(lambda x: f'{x:.2f}')\n",
        "mannwhit_df['REP_median'] = mannwhit_df['REP_median'].map(lambda x: f'{x:.2f}')\n",
        "mannwhit_df['diff_median'] = mannwhit_df['diff_median'].map(lambda x: f'{x:.2f}')\n",
        "mannwhit_df['Cohens_d'] = mannwhit_df['Cohens_d'].map(lambda x: f'{x:.2f}')\n",
        "mannwhit_df['R_biserial'] = mannwhit_df['R_biserial'].map(lambda x: f'{x:.2f}')\n",
        "mannwhit_df['p_value'] = mannwhit_df['p_value'].map(lambda x: f'{x:.2f}')\n",
        "\n",
        "# Confirm\n",
        "display(mannwhit_df.sort_values(by='Cohens_d', ascending=False))"
      ],
      "id": "0988c1d4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature importance"
      ],
      "metadata": {
        "id": "s0z6-6WJqrFL"
      },
      "id": "s0z6-6WJqrFL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4a180b4"
      },
      "source": [
        "## Feature Importance for PARTY_WIN from Logistic Regression"
      ],
      "id": "e4a180b4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "072737b3",
        "collapsed": true
      },
      "source": [
        "# Define the features to exclude based on p-values\n",
        "# Could drop Same_Sex features, but not ready to drop yet\n",
        "features_to_exclude = ['']\n",
        "\n",
        "# Select features for logistic regression, excluding the specified ones\n",
        "features_for_logit = [col for col in VOTE_DF.columns if col not in features_to_exclude + ['GEOID', 'Male_total', 'Female_total', 'PARTY_WIN', 'PARTY_LEAD']]\n",
        "\n",
        "X0 = VOTE_DF[features_for_logit]\n",
        "y0 = VOTE_DF['PARTY_WIN']\n",
        "\n",
        "# Split data into training and testing sets (recommended for model evaluation)\n",
        "X0_train, X0_test, y0_train, y0_test = train_test_split(\n",
        "    X0, y0, test_size=0.2, random_state=1,\n",
        "    stratify=y0) # To maintain class distribution\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X0_train_scaled = scaler.fit_transform(X0_train)\n",
        "X0_test_scaled = scaler.transform(X0_test)\n",
        "\n",
        "# Initialize and train the Logistic Regression model with regularization\n",
        "# Using default L2 penalty and balanced class weight\n",
        "logit_model_sklearn = LogisticRegression(\n",
        "    random_state=1,\n",
        "    class_weight='balanced',\n",
        "    max_iter=1000) # Increased max_iter for convergence\n",
        "logit_model_sklearn.fit(X0_train_scaled, y0_train)\n",
        "\n",
        "# Confirm feature importances from the trained model (coefficients)\n",
        "print('Feature Importance (Coefficients from Regularized Logistic Regression):')\n",
        "logit_feature_importance = pd.Series(\n",
        "    logit_model_sklearn.coef_[0], index=features_for_logit)\n",
        "print(logit_feature_importance.sort_values(ascending=False))\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 8)) # Adjusted figure size for better readability\n",
        "logit_feature_importance.sort_values().plot(kind='barh')\n",
        "plt.title('Feature Importance from Logistic Regression(WIN)')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y0_pred_logit = logit_model_sklearn.predict(X0_test_scaled)\n",
        "\n",
        "print('\\nLogistic Regression Model Evaluation (on test set):')\n",
        "print(f'Accuracy: {accuracy_score(y0_test, y0_pred_logit):.2f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y0_test, y0_pred_logit))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y0_test, y0_pred_logit))"
      ],
      "id": "072737b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance for PARTY_WIN from Decision Tree Classifier"
      ],
      "metadata": {
        "id": "vay-KdHNsueQ"
      },
      "id": "vay-KdHNsueQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the features (X) and the target variable (y)\n",
        "# Exclude the target variables themselves from the features\n",
        "features_for_dtc = [col for col in VOTE_DF.columns if col not in [\n",
        "    'GEOID', 'Male_total', 'Female_total', 'PARTY_WIN', 'PARTY_LEAD']]\n",
        "\n",
        "# Define the features (X) and the target variable (y)\n",
        "X1 = VOTE_DF[features_for_dtc]\n",
        "y1 = VOTE_DF['PARTY_WIN']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(\n",
        "    X1, y1, test_size=0.2, random_state=1)\n",
        "\n",
        "# Initialize and train the Decision Tree Regressor model\n",
        "dtc_model = DecisionTreeClassifier(\n",
        "    random_state=1,\n",
        "    max_depth=5,\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=10)\n",
        "\n",
        "dtc_model.fit(X1_train, y1_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y1_pred_dtc = dtc_model.predict(X1_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y1_test, y1_pred_dtc)\n",
        "rmse = np.sqrt(mse) # Calculate RMSE manually\n",
        "mae = mean_absolute_error(y1_test, y1_pred_dtc)\n",
        "r2 = r2_score(y1_test, y1_pred_dtc)\n",
        "\n",
        "print('Decision Tree Regressor Model Evaluation (on test set):')\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
        "print(f'R-squared (R2): {r2:.2f}')\n",
        "\n",
        "# Plot feature importances from the trained model\n",
        "print('\\nFeature Importance from Decision Tree Regressor:')\n",
        "dtc_feature_importance = pd.Series(dtc_model.feature_importances_, index=features_for_dtc)\n",
        "\n",
        "# Sort and print feature importances\n",
        "print(dtc_feature_importance.sort_values(ascending=False).head(15))\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 8)) # Adjusted figure size\n",
        "dtc_feature_importance.sort_values().plot(kind='barh')\n",
        "plt.title('Feature Importance from Decision Tree Regressor(WIN)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JmMVTcvCXKfp",
        "collapsed": true
      },
      "id": "JmMVTcvCXKfp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Importance for PARTY_LEAD from Decision Tree Regressor"
      ],
      "metadata": {
        "id": "mrMYzNbQXDr7"
      },
      "id": "mrMYzNbQXDr7"
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = VOTE_DF[features_for_dtc]\n",
        "y2 = VOTE_DF['PARTY_LEAD']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
        "    X2, y2, test_size=0.2, random_state=1)\n",
        "\n",
        "# Initialize and train the Decision Tree Regressor model\n",
        "dtr_model = DecisionTreeRegressor(\n",
        "    random_state=1,\n",
        "    max_depth=5,\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=10)\n",
        "\n",
        "dtr_model.fit(X2_train, y2_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y2_pred_dtr = dtr_model.predict(X2_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y2_test, y2_pred_dtr)\n",
        "rmse = np.sqrt(mse) # Calculate RMSE manually\n",
        "mae = mean_absolute_error(y2_test, y2_pred_dtr)\n",
        "r2 = r2_score(y2_test, y2_pred_dtr)\n",
        "\n",
        "print('Decision Tree Regressor Model Evaluation (on test set):')\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
        "print(f'R-squared (R2): {r2:.2f}')\n",
        "\n",
        "# Get and plot feature importances from the trained model\n",
        "print('\\nFeature Importance from Decision Tree Regressor:')\n",
        "dtr_feature_importance = pd.Series(dtr_model.feature_importances_, index=features_for_dtc)\n",
        "\n",
        "# Sort and print feature importances\n",
        "print(dtr_feature_importance.sort_values(ascending=False).head(20))\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 8)) # Adjusted figure size\n",
        "dtr_feature_importance.sort_values().plot(kind='barh')\n",
        "plt.title('Feature Importance from Decision Tree Regressor(LEAD)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UB8RDvm8s4KO",
        "collapsed": true
      },
      "id": "UB8RDvm8s4KO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c30e6de"
      },
      "source": [
        "## Feature Importance for PARTY_WIN from Random Forest"
      ],
      "id": "2c30e6de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4469fad4"
      },
      "source": [
        "# Select features for the Random Forest model\n",
        "# We can use the same set of features that worked for the logistic regression.\n",
        "features_for_rf = features_for_logit\n",
        "\n",
        "X3 = VOTE_DF[features_for_rf]\n",
        "y3 = VOTE_DF['PARTY_WIN']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
        "    X3, y3, test_size=0.2, random_state=1, stratify=y3)\n",
        "\n",
        "# Initialize and train the Random Forest Classifier\n",
        "# Use a reasonable number of estimators (n_estimators) and a random state for reproducibility\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=None,        # control/avoid overfitting\n",
        "    min_samples_split=10,  # avoid tiny splits\n",
        "    min_samples_leaf=5,    # smoother trees\n",
        "    random_state=1,\n",
        "    class_weight='balanced')\n",
        "rf_model.fit(X3_train, y3_train)\n",
        "\n",
        "# Get feature importances from the trained model\n",
        "rf_feature_importance = pd.Series(\n",
        "    rf_model.feature_importances_, index=features_for_rf)\n",
        "\n",
        "# Sort and print feature importances\n",
        "print('Feature Importance from Random Forest:')\n",
        "print(rf_feature_importance.sort_values(ascending=False))\n",
        "\n",
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "rf_feature_importance.sort_values().plot(kind='barh')\n",
        "plt.title('Feature Importance from Random Forest(WIN)')\n",
        "plt.xlabel('Importance Score (Mean Decrease in Impurity)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "y3_pred_rf = rf_model.predict(X3_test)\n",
        "\n",
        "print('\\nRandom Forest Model Evaluation (on test set):')\n",
        "print(f'Accuracy: {accuracy_score(y3_test, y3_pred_rf):.2f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y3_test, y3_pred_rf))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y3_test, y3_pred_rf))"
      ],
      "id": "4469fad4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define permutation importance function (with optional cross-validation)"
      ],
      "metadata": {
        "id": "n7YXZMIne-zS"
      },
      "id": "n7YXZMIne-zS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute permutation importance (PI) or cross-validated PI (CV-PI)\n",
        "def get_PI(model, X3, y3, cv=False, n_splits=5, n_repeats=10, random_state=1):\n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    model : estimator\n",
        "        Trained model (must support predict).\n",
        "    X : DataFrame\n",
        "        Features used for prediction.\n",
        "    y : Series or array-like\n",
        "        Target values.\n",
        "    cv : bool, default=False\n",
        "        If True, performs cross-validated permutation importance.\n",
        "    n_splits : int, default=5\n",
        "        Number of CV folds (only used if cv=True).\n",
        "    n_repeats : int, default=10\n",
        "        Number of shuffles for permutation importance.\n",
        "    random_state : int, default=1\n",
        "        Random seed for reproducibility.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    importance_df : DataFrame\n",
        "        Feature importances sorted by mean decrease in score.\n",
        "    '''\n",
        "\n",
        "    if not cv:\n",
        "# Standard PI on a single fitted model\n",
        "        result = permutation_importance(model, X3, y3,\n",
        "                                        n_repeats=n_repeats,\n",
        "                                        random_state=random_state,\n",
        "                                        n_jobs=-1)\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': X3.columns,\n",
        "            'Importance Mean': result.importances_mean,\n",
        "            'Importance Std': result.importances_std\n",
        "        }).sort_values(by='Importance Mean', ascending=False)\n",
        "\n",
        "    else:\n",
        "# Cross-validated PI\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "        importances = []\n",
        "\n",
        "        for train_idx, test_idx in skf.split(X3, y3):\n",
        "            X3_train, X3_test = X3.iloc[train_idx], X3.iloc[test_idx]\n",
        "            y3_train, y3_test = y3.iloc[train_idx], y3.iloc[test_idx]\n",
        "\n",
        "            model.fit(X3_train, y3_train)\n",
        "            result = permutation_importance(model, X3_test, y3_test,\n",
        "                                            n_repeats=n_repeats,\n",
        "                                            random_state=random_state,\n",
        "                                            n_jobs=-1)\n",
        "            importances.append(result.importances_mean)\n",
        "\n",
        "        mean_importances = np.mean(importances, axis=0)\n",
        "        std_importances = np.std(importances, axis=0)\n",
        "\n",
        "        importance_df = pd.DataFrame({\n",
        "            'Feature': X3.columns,\n",
        "            'Importance Mean': mean_importances,\n",
        "            'Importance Std': std_importances\n",
        "        }).sort_values(by='Importance Mean', ascending=False)\n",
        "    return importance_df\n",
        "\n",
        "# Confirm\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.reset_option('display.float_format')\n",
        "\n",
        "RF_PI = get_PI(rf_model, X3_test, y3_test, cv=False)\n",
        "print(RF_PI)\n",
        "\n",
        "# Plot permutation importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "# Convert 'Importance Mean' to numeric before plotting\n",
        "RF_PI['Importance Mean'] = pd.to_numeric(RF_PI['Importance Mean'])\n",
        "RF_PI.sort_values(by='Importance Mean', ascending=True).plot(kind='barh')\n",
        "plt.title('Permutation Importance from Random Forest(WIN)')\n",
        "plt.xlabel('Importance Score (Importance decrease in Mean)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tX3KCh5yfLWn"
      },
      "id": "tX3KCh5yfLWn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run RFECV with Random Forest to confirm best features"
      ],
      "metadata": {
        "id": "Wd1SSWaExjpc"
      },
      "id": "Wd1SSWaExjpc"
    },
    {
      "cell_type": "code",
      "source": [
        "# Utillize X, y, train, test from Logit (X0, y0)\n",
        "# RFECV with Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=500, random_state=1, class_weight='balanced')\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "selector = RFECV(estimator=rf, step=1, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "selector.fit(X0_train, y0_train)\n",
        "\n",
        "# Best features\n",
        "best_features = X0.columns[selector.support_].tolist()\n",
        "print('Best feature subset:')\n",
        "print(best_features)\n",
        "\n",
        "# Retrain final model with best features\n",
        "rf_ECV = RandomForestClassifier(n_estimators=500, random_state=1, class_weight='balanced')\n",
        "rf_ECV.fit(X0_train[best_features], y0_train)\n",
        "y_pred_ECV = rf_ECV.predict(X0_test[best_features])\n",
        "\n",
        "print('\\nFinal Model Evaluation with Best Features:')\n",
        "print(f'Accuracy: {accuracy_score(y0_test, y_pred_ECV):.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y0_test, y_pred_ECV))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y0_test, y_pred_ECV))"
      ],
      "metadata": {
        "id": "ROv9Mv8C7d2_"
      },
      "id": "ROv9Mv8C7d2_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature importance for PARTY_LEAD from Lasso Regression after Cross-validate Alpha"
      ],
      "metadata": {
        "id": "wKZL1KAiwy4W"
      },
      "id": "wKZL1KAiwy4W"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and exclude target variables\n",
        "features_for_lasso_cv = [col for col in VOTE_DF.columns if col not in ['GEOID', 'PARTY_WIN', 'PARTY_LEAD']]\n",
        "X4 = VOTE_DF[features_for_lasso_cv]\n",
        "y4 = VOTE_DF['PARTY_LEAD']\n",
        "\n",
        "# Split into train and test sets\n",
        "X4_train, X4_test, y4_train, y4_test = train_test_split(\n",
        "    X4, y4, test_size=0.2, random_state=1)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X4_train_scaled = scaler.fit_transform(X4_train)\n",
        "X4_test_scaled = scaler.transform(X4_test)\n",
        "\n",
        "# Let LassoCV automatically generates an alpha grid to test\n",
        "lasso_cv_model = LassoCV(cv=5, random_state=1, max_iter=10000)\n",
        "lasso_cv_model.fit(X4_train_scaled, y4_train)\n",
        "\n",
        "# Confirm the optimal alpha found by LassoCV\n",
        "optimal_alpha = lasso_cv_model.alpha_\n",
        "print(f'Optimal alpha found by LassoCV: {optimal_alpha:.4f}')\n",
        "print('')\n",
        "# Plot the MSE as a function of alpha\n",
        "mse_path = lasso_cv_model.mse_path_\n",
        "alphas = lasso_cv_model.alphas_\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(alphas, mse_path, linestyle='-', marker='o')\n",
        "plt.xscale('log') # Often useful to plot alpha on a log scale\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('Mean Squared Error (across folds)')\n",
        "plt.title('Mean Squared Error vs. Alpha during Cross-validation')\n",
        "plt.axvline(optimal_alpha, color='red', linestyle='--', label=f'Optimal Alpha = {optimal_alpha:.4f}')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# List the coefficients with the optimal alpha\n",
        "print('\\nFeature Importance from LassoCV (CV = 0.0002):')\n",
        "feature_importance_lasso_cv = pd.Series(lasso_cv_model.coef_, index=features_for_lasso_cv)\n",
        "print(feature_importance_lasso_cv.sort_values(ascending=False))\n",
        "\n",
        "# Plot feature importances with optimal alpha\n",
        "plt.figure(figsize=(10, 10))\n",
        "feature_importance_lasso_cv.sort_values().plot(kind='barh')\n",
        "plt.title(f'Feature Importance from Lasso Regression(LEAD) with Optimal Alpha = {optimal_alpha:.4f}')\n",
        "plt.xlabel('Coefficient Value')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the final Lasso model with the optimal alpha on the test set\n",
        "y4_pred_lasso_cv = lasso_cv_model.predict(X4_test_scaled)\n",
        "\n",
        "print('\\nLasso Regression Model Evaluation (with Optimal Alpha):')\n",
        "mse_test = mean_squared_error(y4_test, y4_pred_lasso_cv)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "r2_test = r2_score(y4_test, y4_pred_lasso_cv)\n",
        "\n",
        "print(f'Mean Squared Error (MSE) on test set: {mse_test:.4f}')\n",
        "print(f'Root Mean Squared Error (RMSE) on test set: {rmse_test:.4f}')\n",
        "print(f'R-squared (R2) on test set: {r2_test:.4f}')"
      ],
      "metadata": {
        "id": "is2-5D_DQUxz",
        "collapsed": true
      },
      "id": "is2-5D_DQUxz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare feature importance"
      ],
      "metadata": {
        "id": "zP3rnW8z6VkD"
      },
      "id": "zP3rnW8z6VkD"
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_series(s, keep_sign=True):\n",
        "    '''Normalize feature importance to 0–1 scale, optionally keeping sign.'''\n",
        "    s = s.fillna(0)\n",
        "    if keep_sign:\n",
        "        return s / s.abs().max()  # scale to -1..1, preserving sign\n",
        "    else:\n",
        "        scaler = MinMaxScaler()\n",
        "        return pd.Series(scaler.fit_transform(s.values.reshape(-1, 1)).flatten(), index=s.index)\n",
        "\n",
        "# Collect raw importances into a DataFrame\n",
        "feature_importances = pd.DataFrame({\n",
        "    'LogReg': logit_feature_importance,\n",
        "    'DecTreeClass': dtc_feature_importance,\n",
        "    'DecTreeReg': dtr_feature_importance,\n",
        "    'RandomForest': rf_feature_importance,\n",
        "    'RF_PI': RF_PI.set_index('Feature')['Importance Mean'],  # permutation importance\n",
        "    'Lasso_LogReg': feature_importance_lasso_cv})\n",
        "\n",
        "# Normalize each column (preserving signs)\n",
        "for col in feature_importances.columns:\n",
        "    if col in ['LogReg', 'Lasso_LogReg']:  # signed coefficients\n",
        "        feature_importances[col] = normalize_series(feature_importances[col], keep_sign=True)\n",
        "    else:  # tree-based importances are ≥ 0\n",
        "        feature_importances[col] = normalize_series(feature_importances[col], keep_sign=False)\n",
        "\n",
        "# Compute mean rank or average importance across models\n",
        "feature_importances['Avg_Importance'] = feature_importances.abs().mean(axis=1)\n",
        "\n",
        "# Sort by average importance\n",
        "feature_importances = feature_importances.sort_values(by='Avg_Importance', ascending=False)\n",
        "\n",
        "# Print the top features\n",
        "print('\\nTop 25 Features Across Models (normalized):')\n",
        "display(feature_importances.round(4))"
      ],
      "metadata": {
        "id": "TPFzdRAd-SB7"
      },
      "id": "TPFzdRAd-SB7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RFECV Feature Selection for final model"
      ],
      "metadata": {
        "id": "eBwGovenQL60"
      },
      "id": "eBwGovenQL60"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data, drop reference and overlap features\n",
        "drop_features = [\n",
        "    'Male_total', 'Female_total', # reference only\n",
        "    '%AGE_MALE_YNG', '%AGE_MALE_MID', '%AGE_MALE_OLD', # overlap\n",
        "    '%AGE_FEMALE_YNG', '%AGE_FEMALE_MID', '%AGE_FEMALE_OLD', # overlap\n",
        "    '%RACE_NonWhite', '%RACE_BAO', '%RACE_LNHM'] # overlap\n",
        "\n",
        "VOTE_FULL = VOTE_DF.drop(\n",
        "    columns=drop_features,\n",
        "    errors='ignore')\n",
        "\n",
        "X = VOTE_FULL.drop(\n",
        "    columns=['GEOID', 'PARTY_WIN', 'PARTY_LEAD'])\n",
        "y = VOTE_FULL['PARTY_WIN']\n",
        "\n",
        "# Train/test split\n",
        "XF_train, XF_test, yF_train, yF_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=1, stratify=y)\n",
        "\n",
        "# Recursive Feature Elimination with Cross-Validation\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=400, random_state=1, class_weight='balanced')\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "selector = RFECV(\n",
        "    estimator=rf, step=1, cv=cv, scoring='accuracy', n_jobs=-1)\n",
        "selector.fit(XF_train, yF_train)\n",
        "\n",
        "# Plot accuracy vs. number of features\n",
        "n_features = np.arange(\n",
        "    1, len(selector.cv_results_['mean_test_score']) + 1)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(n_features, selector.cv_results_['mean_test_score'], marker='o')\n",
        "plt.axhline(0.93, color='red', linestyle='--', label='93% threshold')\n",
        "plt.axhline(max(selector.cv_results_['mean_test_score']), color='green', linestyle='--', label='Best Acc')\n",
        "plt.xlabel('Number of Features Selected')\n",
        "plt.ylabel('Cross-Validated Accuracy')\n",
        "plt.title('Accuracy vs. Number of Features (RFECV)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Retrain with Best Features\n",
        "best_features = X.columns[\n",
        "    selector.support_].tolist()\n",
        "print('\\nBest Feature Subset:')\n",
        "print(best_features)\n",
        "\n",
        "rf_final = RandomForestClassifier(\n",
        "    n_estimators=400, random_state=1, class_weight='balanced')\n",
        "rf_final.fit(\n",
        "    XF_train[best_features], yF_train)\n",
        "yF_pred = rf_final.predict(\n",
        "    XF_test[best_features])\n",
        "\n",
        "print('\\nFinal Model Evaluation with Best Features:')\n",
        "print(f'Accuracy: {accuracy_score(yF_test, yF_pred):.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(yF_test, yF_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(yF_test, yF_pred))\n",
        "\n",
        "# Plot Feature Importance\n",
        "importances = rf_final.feature_importances_\n",
        "feat_imp = pd.DataFrame({\n",
        "    'Feature': best_features,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print('\\nTop Features Driving Model Accuracy:')\n",
        "display(feat_imp)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.barh(feat_imp['Feature'], feat_imp['Importance'], color='steelblue')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlabel('Feature Importance (RF)')\n",
        "plt.title('Key Demographic Predictors of Voting Patterns')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K-T03hP9CCVo"
      },
      "id": "K-T03hP9CCVo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train FINAL MODEL"
      ],
      "metadata": {
        "id": "oeQkkBXBNWyn"
      },
      "id": "oeQkkBXBNWyn"
    },
    {
      "cell_type": "code",
      "source": [
        "# Select final features: From 'accuracy vs. number of features' plot, ideal number of features start at 8, 9, or 10, compare 8-10 features for accuracy and MANOVA scores (dropped HH_MARRIED due to correlation with REL_xxx_MAR)\n",
        "\n",
        "final_features = [ # Drop '%AGE_FEMALE_YOUNG', '%REL_W_RELATIVES' for best results\n",
        "    'GEOID', 'PARTY_WIN', 'PARTY_LEAD',\n",
        "    '%RACE_White', '%RACE_Asian', '%Urban_pop', '%REL_S_SEX_MAR',\n",
        "    '%REL_OP_SEX_MAR', '%OWN_HOME', '%REL_NON_REL', '%RACE_Black']\n",
        "VOTE_FINAL = VOTE_DF[final_features]\n",
        "\n",
        "# Set features for final model\n",
        "X_final = [col for col in VOTE_FINAL.columns if col not in [\n",
        "    'GEOID', 'PARTY_WIN', 'PARTY_LEAD']]\n",
        "y_final = VOTE_FINAL['PARTY_WIN']\n",
        "\n",
        "# Train/test split\n",
        "XF_train, XF_test, yF_train, yF_test = train_test_split(\n",
        "    VOTE_FINAL[X_final], y_final,\n",
        "    test_size=0.2, random_state=1,\n",
        "    stratify=y_final)\n",
        "\n",
        "# Train Random Forest\n",
        "rf_final = RandomForestClassifier(\n",
        "    n_estimators=500,\n",
        "    random_state=1,\n",
        "    class_weight='balanced')\n",
        "rf_final.fit(XF_train, yF_train)\n",
        "\n",
        "# Evaluate\n",
        "yF_pred = rf_final.predict(XF_test)\n",
        "\n",
        "print('\\nFinal Model Evaluation:')\n",
        "print(f'Accuracy: {accuracy_score(yF_test, yF_pred):.4f}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(yF_test, yF_pred))\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(yF_test, yF_pred))"
      ],
      "metadata": {
        "id": "isQiPuMBQVry"
      },
      "id": "isQiPuMBQVry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use MANOVA to assess whether multiple features jointly differ between Democrats and Republicans"
      ],
      "metadata": {
        "id": "ei1Fc3phWpsy"
      },
      "id": "ei1Fc3phWpsy"
    },
    {
      "cell_type": "code",
      "source": [
        "maov = MANOVA(endog=VOTE_FINAL[X_final], exog=VOTE_FINAL[[y_final.name]])\n",
        "print(maov.mv_test())"
      ],
      "metadata": {
        "id": "ubqRzPOShnav"
      },
      "id": "ubqRzPOShnav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run CV PI"
      ],
      "metadata": {
        "id": "wVVFLvVyNfIo"
      },
      "id": "wVVFLvVyNfIo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross-validate Permutation Importance\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "importances = []\n",
        "\n",
        "# Pass feature data to skf.split\n",
        "for train_fcv, test_fcv in skf.split(VOTE_FINAL[X_final], y_final):\n",
        "    XF_train, XF_test = VOTE_FINAL[X_final].iloc[train_fcv], VOTE_FINAL[X_final].iloc[test_fcv]\n",
        "    yF_train, yF_test = y_final.iloc[train_fcv], y_final.iloc[test_fcv]\n",
        "\n",
        "    rf_final.fit(XF_train, yF_train)\n",
        "    result = permutation_importance(\n",
        "        rf_final, XF_test, yF_test,\n",
        "        n_repeats=10, random_state=1, n_jobs=-1)\n",
        "    importances.append(result.importances_mean)\n",
        "\n",
        "mean_importances = np.mean(importances, axis=0)\n",
        "std_importances = np.std(importances, axis=0)\n",
        "\n",
        "# Build PI DF\n",
        "pi_df = pd.DataFrame({\n",
        "    'Feature': X_final, # Use X_final for feature names\n",
        "    'Importance Mean': mean_importances.round(4),\n",
        "    'Importance Std': std_importances.round(4)\n",
        "}).sort_values(by='Importance Mean', ascending=False)\n",
        "\n",
        "# Confirm\n",
        "print('\\nCross-validated Permutation Importance:')\n",
        "print(pi_df)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "pi_df.set_index('Feature')['Importance Mean'].sort_values().plot(kind='barh')\n",
        "plt.title('Final Model - CV Permutation Importance')\n",
        "plt.xlabel('Mean Importance (± CV variation)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OzKUEo_CXvz-"
      },
      "id": "OzKUEo_CXvz-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profile counties with **extremely high PARTY_LEAD** (-30 > LEAD > +30)  \n",
        "\n",
        "Do the demographics of partisan counties match final feature importance?"
      ],
      "metadata": {
        "id": "UW637VgsYaVd"
      },
      "id": "UW637VgsYaVd"
    },
    {
      "cell_type": "code",
      "source": [
        "VOTE_FINAL.to_csv('VOTE_FINAL.csv', index=False)"
      ],
      "metadata": {
        "id": "KcGlrFaJY5nN"
      },
      "id": "KcGlrFaJY5nN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Equal Cutoff Strongholds (±0.5)"
      ],
      "metadata": {
        "id": "OCqURRbheo9y"
      },
      "id": "OCqURRbheo9y"
    },
    {
      "cell_type": "code",
      "source": [
        "def profile_group(dataframe, name, features):\n",
        "    '''Calculates the mean of specified features for a group and returns a Series.'''\n",
        "# Ensure only numeric columns in features are selected for mean calculation\n",
        "    numeric_features = dataframe[features].select_dtypes(include=np.number).columns.tolist()\n",
        "    profile = dataframe[numeric_features].mean()\n",
        "    profile.name = name\n",
        "    return profile\n",
        "\n",
        "# Set cutoff value to 0.50\n",
        "cutoff_val = 0.50\n",
        "\n",
        "# Use _FIN to allow R and D access to all variables\n",
        "extreme_counties = VOTE_FULL[np.abs(VOTE_FULL['PARTY_LEAD']) > cutoff_val]\n",
        "\n",
        "# Republican strongholds\n",
        "extreme_R = extreme_counties[extreme_counties['PARTY_LEAD'] < -cutoff_val]\n",
        "\n",
        "# Democratic strongholds\n",
        "extreme_D = extreme_counties[extreme_counties['PARTY_LEAD'] > cutoff_val]\n",
        "\n",
        "print(f'Republican strongholds (cutoff -{cutoff_val}):', extreme_R.shape[0])\n",
        "print(f'Democratic strongholds (cutoff +{cutoff_val}):', extreme_D.shape[0])\n",
        "\n",
        "# Select demographic features only (drop outcomes and GEOID)\n",
        "demo_features = [col for col in VOTE_FULL.columns if col not in ['PARTY_WIN', 'PARTY_LEAD', 'GEOID']]\n",
        "\n",
        "# Profiles for cutoff-based groups\n",
        "cutoff_profiles_combined = pd.concat([\n",
        "    profile_group(extreme_R, 'R_characteristics', demo_features),\n",
        "    profile_group(extreme_D, 'D_characteristics', demo_features),\n",
        "], axis=1)\n",
        "\n",
        "# Add absolute difference column\n",
        "cutoff_profiles_combined['Abs_Diff'] = np.abs(cutoff_profiles_combined['R_characteristics'] - cutoff_profiles_combined['D_characteristics'])\n",
        "\n",
        "print(f'\\n=== Cutoff-based Stronghold Profiles (>{cutoff_val} Party Lead) ===')\n",
        "print(cutoff_profiles_combined.sort_values(by='Abs_Diff', ascending=False))"
      ],
      "metadata": {
        "id": "DG6o7sPmuJzq"
      },
      "id": "DG6o7sPmuJzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Balanced Strongholds (Top/Bottom 10% quantiles)"
      ],
      "metadata": {
        "id": "Ez_MMt7k1BmF"
      },
      "id": "Ez_MMt7k1BmF"
    },
    {
      "cell_type": "code",
      "source": [
        "# Set cutoff value\n",
        "lower_10 = VOTE_FULL['PARTY_LEAD'].quantile(0.10)   # bottom 10% cutoff\n",
        "upper_10 = VOTE_FULL['PARTY_LEAD'].quantile(0.90)   # top 10% cutoff\n",
        "\n",
        "R_stnghd_bal = VOTE_FULL[VOTE_FULL['PARTY_LEAD'] <= lower_10].copy()\n",
        "D_stnghd_bal = VOTE_FULL[VOTE_FULL['PARTY_LEAD'] >= upper_10].copy()\n",
        "\n",
        "print(f'Republican strongholds (quantile-based): {len(R_stnghd_bal)} counties (<= {lower_10:.2f})')\n",
        "print(f'Democratic strongholds (quantile-based): {len(D_stnghd_bal)} counties (>= {upper_10:.2f})')\n",
        "\n",
        "# Select demographic features only (drop outcomes and GEOID)\n",
        "demo_features = [col for col in VOTE_FULL.columns if col not in [\n",
        "    'GEOID', 'PARTY_WIN', 'PARTY_LEAD']]\n",
        "\n",
        "# Profiles for quantile-based groups\n",
        "balanced_profiles = pd.concat([\n",
        "    profile_group(R_stnghd_bal, 'R_characteristics', demo_features),\n",
        "    profile_group(D_stnghd_bal, 'D_characteristics', demo_features),\n",
        "], axis=1)\n",
        "\n",
        "# Add absolute difference column\n",
        "balanced_profiles['Abs_Diff'] = np.abs(balanced_profiles['R_characteristics'] - balanced_profiles['D_characteristics'])\n",
        "\n",
        "print('\\n=== Quantile-based Stronghold Profiles (Top/Bottom 10%) ===')\n",
        "print(balanced_profiles.sort_values(by='Abs_Diff', ascending=False))"
      ],
      "metadata": {
        "id": "CYEfEDEYqsmy"
      },
      "id": "CYEfEDEYqsmy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison Table"
      ],
      "metadata": {
        "id": "qPQOzyr65O31"
      },
      "id": "qPQOzyr65O31"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build combined comparison table\n",
        "\n",
        "# Profiles for cutoff-based groups\n",
        "# Select demographic features only (drop outcomes and GEOID)\n",
        "demo_features = [col for col in VOTE_FULL.columns if col not in ['PARTY_WIN', 'PARTY_LEAD', 'GEOID']]\n",
        "\n",
        "cutoff_profiles = pd.concat([\n",
        "    profile_group(extreme_R, 'R_cutoff', demo_features),\n",
        "    profile_group(extreme_D, 'D_cutoff', demo_features)\n",
        "], axis=1)\n",
        "\n",
        "# Profiles for quantile-based groups\n",
        "# Select demographic features only (drop outcomes and GEOID)\n",
        "demo_features = [col for col in VOTE_FULL.columns if col not in ['PARTY_WIN', 'PARTY_LEAD', 'GEOID']]\n",
        "\n",
        "balanced_profiles = pd.concat([\n",
        "    profile_group(R_stnghd_bal, 'R_quantile', demo_features),\n",
        "    profile_group(D_stnghd_bal, 'D_quantile', demo_features)\n",
        "], axis=1)\n",
        "\n",
        "# Combine both into one big table\n",
        "comparison_table = pd.concat([cutoff_profiles, balanced_profiles], axis=1)\n",
        "\n",
        "# Add difference columns (D – R) for clarity of spread\n",
        "comparison_table['Diff_cutoff'] = comparison_table['D_cutoff'] - comparison_table['R_cutoff']\n",
        "comparison_table['Diff_quantile'] = comparison_table['D_quantile'] - comparison_table['R_quantile']\n",
        "\n",
        "comparison_table = comparison_table.round(2)\n",
        "\n",
        "# Confirm\n",
        "print('\\n=== Combined Stronghold Profiles (Cutoff vs Quantile) ===')\n",
        "display(comparison_table.sort_values(by='R_cutoff', ascending=False))"
      ],
      "metadata": {
        "id": "vaz2G7a_5XT_"
      },
      "id": "vaz2G7a_5XT_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Locations of Extremes"
      ],
      "metadata": {
        "id": "HhW9Hq7yevwv"
      },
      "id": "HhW9Hq7yevwv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad GEOIDs with a leading zero if length is less than 5 and extract state FIPS\n",
        "R_geoids = [f'{int(geo):05d}' if len(geo) < 5 else geo for geo in extreme_R['GEOID'].unique()]\n",
        "D_geoids = [f'{int(geo):05d}' if len(geo) < 5 else geo for geo in extreme_D['GEOID'].unique()]\n",
        "\n",
        "R_fips = [geo[:2] for geo in R_geoids]\n",
        "D_fips = [geo[:2] for geo in D_geoids]\n",
        "\n",
        "R_counts = Counter(R_fips)\n",
        "D_counts = Counter(D_fips)\n",
        "\n",
        "print('\\nCounts for counties above 50% party lead (Min 75-25% split):')\n",
        "# Sort state_counts by 2-digit state FIPS)\n",
        "sorted_R_counts = dict(sorted(R_counts.items()))\n",
        "sorted_D_counts = dict(sorted(D_counts.items()))\n",
        "print(sorted_R_counts)\n",
        "print(sorted_D_counts)"
      ],
      "metadata": {
        "id": "S282Z_AkaweE"
      },
      "id": "S282Z_AkaweE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "kLLzTeuG7I89"
      },
      "id": "kLLzTeuG7I89"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Model Performance & Prediction Quality"
      ],
      "metadata": {
        "id": "grgTS-Nv7eAW"
      },
      "id": "grgTS-Nv7eAW"
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions: Use the subset of features that the model was trained on\n",
        "yF_pred = rf_final.predict(XF_test)\n",
        "y_pred_proba = rf_final.predict_proba(XF_test)[:, 1] if hasattr(\n",
        "               rf_final, 'predict_proba') else None\n",
        "\n",
        "# Collect metrics\n",
        "performance = {\n",
        "    'Accuracy': accuracy_score(yF_test, yF_pred),\n",
        "    'Precision': precision_score(yF_test, yF_pred, zero_division=0),\n",
        "    'Recall': recall_score(yF_test, yF_pred, zero_division=0),\n",
        "    'F1 Score': f1_score(yF_test, yF_pred, zero_division=0)}\n",
        "\n",
        "if y_pred_proba is not None:\n",
        "    performance['ROC-AUC'] = roc_auc_score(yF_test, y_pred_proba)\n",
        "\n",
        "# Create performance DataFrame\n",
        "perf_df = pd.DataFrame(performance, index=['Final Model']).T\n",
        "display(perf_df)"
      ],
      "metadata": {
        "id": "tqn0PurM7LXr"
      },
      "id": "tqn0PurM7LXr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature Importance"
      ],
      "metadata": {
        "id": "k7DxriQ87ahq"
      },
      "id": "k7DxriQ87ahq"
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nCross-validated Permutation Importance:')\n",
        "print(pi_df)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "pi_df.set_index('Feature')['Importance Mean'].sort_values().plot(kind='barh')\n",
        "plt.title('Final Model - CV Permutation Importance')\n",
        "plt.xlabel('Mean Importance (± CV variation)')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1ldgozQLupRO"
      },
      "id": "1ldgozQLupRO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "END"
      ],
      "metadata": {
        "id": "Ec1EelkQ_mYs"
      },
      "id": "Ec1EelkQ_mYs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Read Minimum Wage Data  \n",
        "Datafile manually compiled from  \n",
        "state law https://www.dol.gov/agencies/whd/state/minimum-wage/history  \n",
        "and local ordinances https://laborcenter.berkeley.edu/inventory-of-us-city-and-county-minimum-wage-ordinances/  \n",
        "Many exceptions exist for number of employees, annual receipts, type of work, tip workers, etc. Highest wage selected for study."
      ],
      "metadata": {
        "id": "_c46d1vowQlv"
      },
      "id": "_c46d1vowQlv"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUCnnGhyh5fJ"
      },
      "id": "wUCnnGhyh5fJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGZTzWykh5VA"
      },
      "id": "rGZTzWykh5VA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tr77l6dHh5DA"
      },
      "id": "tr77l6dHh5DA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f46da665"
      },
      "source": [
        "# Convert 'FIPS' to 5-digit string\n",
        "Census_clean['FIPS'] = Census_clean['FIPS'].astype(str).str.zfill(5)\n",
        "\n",
        "# 1. For FIPS '35039' (Rio Arriba, NM)\n",
        "fips_35039_mask = (Census_clean['FIPS'] == '35039')\n",
        "\n",
        "# Identify columns with NaNs in 2018 for this FIPS\n",
        "rows_2018_35039 = Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2018)]\n",
        "\n",
        "if not rows_2018_35039.empty:\n",
        "    for col in rows_2018_35039.columns:\n",
        "        if rows_2018_35039[col].isnull().any(): # Check if there is an NaN in this column for 2018\n",
        "            # Get values for 2017 and 2019\n",
        "            val_2017 = Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2017)][col].iloc[0] if not Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2017)].empty else np.nan\n",
        "            val_2019 = Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2019)][col].iloc[0] if not Census_clean[fips_35039_mask & (Census_clean['YEAR'] == 2019)].empty else np.nan\n",
        "\n",
        "            # Calculate average and fill if both values are available\n",
        "            if pd.notna(val_2017) and pd.notna(val_2019):\n",
        "                imputed_value = (val_2017 + val_2019) / 2\n",
        "                Census_clean.loc[fips_35039_mask & (Census_clean['YEAR'] == 2018), col] = imputed_value\n",
        "\n",
        "# 2. For FIPS '46017' (Buffalo, SD)\n",
        "fips_46017_mask = (Census_clean['FIPS'] == '46017')\n",
        "\n",
        "# Calculate average for median_home_value (2011-2021)\n",
        "avg_mhv_46017 = Census_clean[fips_46017_mask & (Census_clean['YEAR'].between(2011, 2021))]['median_home_value'].mean()\n",
        "Census_clean.loc[fips_46017_mask & (Census_clean['YEAR'] == 2020), 'median_home_value'] = avg_mhv_46017\n",
        "\n",
        "# Calculate average for median_property_taxes (2011-2021)\n",
        "avg_mpt_46017 = Census_clean[fips_46017_mask & (Census_clean['YEAR'].between(2011, 2021))]['median_property_taxes'].mean()\n",
        "Census_clean.loc[fips_46017_mask & (Census_clean['YEAR'] == 2020), 'median_property_taxes'] = avg_mpt_46017\n",
        "\n",
        "# 3. For FIPS '46095' (Mellette, SD)\n",
        "fips_46095_mask = (Census_clean['FIPS'] == '46095')\n",
        "\n",
        "# median_home_value in 2020: average of 2019 and 2021\n",
        "val_mhv_2019_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2019)]['median_home_value'].iloc[0]\n",
        "val_mhv_2021_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2021)]['median_home_value'].iloc[0]\n",
        "imputed_mhv_2020_46095 = (val_mhv_2019_46095 + val_mhv_2021_46095) / 2\n",
        "Census_clean.loc[fips_46095_mask & (Census_clean['YEAR'] == 2020), 'median_home_value'] = imputed_mhv_2020_46095\n",
        "\n",
        "# median_property_taxes in 2019 and 2020: average of 2018 and 2021\n",
        "val_mpt_2018_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2018)]['median_property_taxes'].iloc[0]\n",
        "val_mpt_2021_46095 = Census_clean[fips_46095_mask & (Census_clean['YEAR'] == 2021)]['median_property_taxes'].iloc[0]\n",
        "imputed_mpt_46095 = (val_mpt_2018_46095 + val_mpt_2021_46095) / 2\n",
        "Census_clean.loc[fips_46095_mask & (Census_clean['YEAR'].isin([2019, 2020])), 'median_property_taxes'] = imputed_mpt_46095\n",
        "\n",
        "# 4. For FIPS '48243' (Jeff Davis, TX)\n",
        "fips_48243_mask = (Census_clean['FIPS'] == '48243')\n",
        "\n",
        "# median_hh_income (2011-2019 average) for 2020\n",
        "avg_mhi_48243 = Census_clean[fips_48243_mask & (Census_clean['YEAR'].between(2011, 2019))]['median_hh_income'].mean()\n",
        "Census_clean.loc[fips_48243_mask & (Census_clean['YEAR'] == 2020), 'median_hh_income'] = avg_mhi_48243\n",
        "\n",
        "# median_property_taxes (2011-2019 average) for 2020\n",
        "avg_mpt_48243 = Census_clean[fips_48243_mask & (Census_clean['YEAR'].between(2011, 2019))]['median_property_taxes'].mean()\n",
        "Census_clean.loc[fips_48243_mask & (Census_clean['YEAR'] == 2020), 'median_property_taxes'] = avg_mpt_48243\n",
        "\n",
        "# 5. For FIPS '48261' (Kenedy, TX)\n",
        "fips_48261_mask = (Census_clean['FIPS'] == '48261')\n",
        "\n",
        "# Calculate average for median_home_value (2011-2019)\n",
        "avg_mhv_48261 = Census_clean[fips_48261_mask & (Census_clean['YEAR'].between(2011, 2019))]['median_home_value'].mean()\n",
        "\n",
        "# Replace 2014 median_home_value if 166700.0\n",
        "if not Census_clean[fips_48261_mask & (Census_clean['YEAR'] == 2014) & (Census_clean['median_home_value'] == 166700.0)].empty:\n",
        "    Census_clean.loc[fips_48261_mask & (Census_clean['YEAR'] == 2014), 'median_home_value'] = avg_mhv_48261\n",
        "\n",
        "# Fill 2015-2021 missing median_home_value with the same average\n",
        "Census_clean.loc[fips_48261_mask & (Census_clean['YEAR'].between(2015, 2021)), 'median_home_value'] = Census_clean.loc[fips_48261_mask & (Census_clean['YEAR'].between(2015, 2021)), 'median_home_value'].fillna(avg_mhv_48261)\n",
        "\n",
        "# 6. For FIPS '48301' (Loving, TX)\n",
        "fips_48301_mask = (Census_clean['FIPS'] == '48301')\n",
        "\n",
        "# a. median_hh_income\n",
        "# Fill 2015 with average of 2014 and 2016\n",
        "val_mhi_2014_48301 = Census_clean[fips_48301_mask & (Census_clean['YEAR'] == 2014)]['median_hh_income'].iloc[0]\n",
        "val_mhi_2016_48301 = Census_clean[fips_48301_mask & (Census_clean['YEAR'] == 2016)]['median_hh_income'].iloc[0]\n",
        "imputed_mhi_2015_48301 = (val_mhi_2014_48301 + val_mhi_2016_48301) / 2\n",
        "Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == 2015), 'median_hh_income'] = imputed_mhi_2015_48301\n",
        "\n",
        "# Fill 2021 with average of 2011-2020\n",
        "avg_mhi_2011_2020_48301 = Census_clean[fips_48301_mask & (Census_clean['YEAR'].between(2011, 2020))]['median_hh_income'].mean()\n",
        "Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == 2021), 'median_hh_income'] = avg_mhi_2011_2020_48301\n",
        "\n",
        "# b. median_home_value (impute specific values)\n",
        "imputed_mhv_values_48301 = {2016: 101750, 2017: 119100, 2018: 131700, 2019: 128300, 2020: 169400, 2021: 178700}\n",
        "for year, value in imputed_mhv_values_48301.items():\n",
        "    Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == year), 'median_home_value'] = value\n",
        "\n",
        "# c. median_property_taxes (impute specific values)\n",
        "imputed_mpt_values_48301 = {2015: 1350, 2016: 1480, 2017: 1568, 2018: 1960, 2019: 2156, 2020: 2105, 2021: 2200}\n",
        "for year, value in imputed_mpt_values_48301.items():\n",
        "    Census_clean.loc[fips_48301_mask & (Census_clean['YEAR'] == year), 'median_property_taxes'] = value\n",
        "\n",
        "# Display null counts after imputation\n",
        "print('\\nCensus nulls after imputation:')\n",
        "print(Census_clean.isnull().sum())\n",
        "\n",
        "# Display info after imputation to check data types and non-null counts\n",
        "print('\\nCensus info after imputation:')\n",
        "print(Census_clean.info())"
      ],
      "id": "f46da665",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84059e03"
      },
      "source": [
        "print('--- Starting FIPS Remapping and Dropping ---')\n",
        "\n",
        "# Remap FIPS '15901' to '15009'\n",
        "migration_df['FIPS'] = migration_df['FIPS'].replace({'15901': '15009'})\n",
        "print(\"Remapped FIPS '15901' to '15009'.\")\n",
        "\n",
        "# Remove all rows where FIPS is '15005' (Kalawao, HI)\n",
        "migration_df = migration_df[migration_df['FIPS'] != '15005'].copy()\n",
        "print(\"Removed rows with FIPS '15005' (Kalawao, HI).\")\n",
        "\n",
        "# Remap FIPS '46102' to '46113'\n",
        "migration_df['FIPS'] = migration_df['FIPS'].replace({'46102': '46113'})\n",
        "print(\"Remapped FIPS '46102' to '46113'.\")\n",
        "\n",
        "# Remove all rows where FIPS is '51515' and YEAR > 2014\n",
        "migration_df = migration_df[~((migration_df['FIPS'] == '51515') & (migration_df['YEAR'] > 2014))].copy()\n",
        "print(\"Removed rows for FIPS '51515' (Bedford City) where YEAR > 2014.\")\n",
        "\n",
        "print('\\n--- FIPS Remapping and Dropping Complete ---')\n",
        "print(f\"New DataFrame shape after FIPS remapping/dropping: {migration_df.shape}\")\n",
        "print(migration_df.head())"
      ],
      "id": "84059e03",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d17beaae",
        "outputId": "b2209402-558e-47f4-b5d2-cec96d72a6b0"
      },
      "source": [
        "print('--- Starting Alaska FIPS Consolidation ---')\n",
        "\n",
        "# Identify Alaska FIPS codes (starting with '02' but not '02000')\n",
        "alaska_fips_to_consolidate = migration_df[\n",
        "    migration_df['FIPS'].astype(str).str.startswith('02') &\n",
        "    (migration_df['FIPS'] != '02000')\n",
        "]['FIPS'].unique()\n",
        "\n",
        "def weighted_average(df_subset, columns, weight_col='total_population'):\n",
        "    # Ensure we only work with columns present in the subset\n",
        "    valid_columns = [col for col in columns if col in df_subset.columns]\n",
        "\n",
        "    # Handle cases where all populations are NaN or zero in the subset\n",
        "    if df_subset[weight_col].sum() == 0 or df_subset[weight_col].isnull().all():\n",
        "        # If weights are all zero or NaN, return NaN for rates or the simple mean if population isn't applicable\n",
        "        # For this specific task, if total_population is invalid, we return NaN\n",
        "        return pd.Series([np.nan] * len(valid_columns), index=valid_columns)\n",
        "\n",
        "    # For accurate weighted average, only consider rows where population is not NaN and positive\n",
        "    df_valid = df_subset.dropna(subset=[weight_col]).copy()\n",
        "    df_valid = df_valid[df_valid[weight_col] > 0]\n",
        "\n",
        "    if df_valid.empty:\n",
        "        return pd.Series([np.nan] * len(valid_columns), index=valid_columns)\n",
        "\n",
        "    # Replace NaNs in the value columns with 0 only for the calculation, to avoid NaN * population = NaN\n",
        "    # but we need to be careful not to introduce zeros where data genuinely wasn't present.\n",
        "    # A better approach is to drop NaNs from the value columns *before* weighting, or impute carefully.\n",
        "    # For the purpose of aggregation into a county, if a city has a NaN rate, it should not contribute to the average.\n",
        "    # So, we fill NaNs in data columns with 0 if population is present, so they don't break the sum/division.\n",
        "\n",
        "    weighted_sum = (df_valid[valid_columns].fillna(0).multiply(df_valid[weight_col], axis=0)).sum()\n",
        "    total_weight = df_valid[weight_col].sum()\n",
        "\n",
        "    return weighted_sum / total_weight\n",
        "\n",
        "\n",
        "# Prepare an empty DataFrame to store consolidated Alaska data\n",
        "alaska_consolidated_data = []\n",
        "\n",
        "for year in sorted(migration_df['YEAR'].unique()):\n",
        "    alaska_yearly_data = migration_df[\n",
        "        (migration_df['FIPS'].isin(alaska_fips_to_consolidate)) &\n",
        "        (migration_df['YEAR'] == year)\n",
        "    ].copy()\n",
        "\n",
        "    if not alaska_yearly_data.empty:\n",
        "        consolidated_row = {'FIPS': '02000', 'YEAR': year}\n",
        "\n",
        "        # Aggregate count_cols by summing\n",
        "        for col in count_cols:\n",
        "            if col in alaska_yearly_data.columns:\n",
        "                consolidated_row[col] = alaska_yearly_data[col].sum()\n",
        "\n",
        "        # Aggregate rate_cols using population-weighted average\n",
        "        for col in rate_cols:\n",
        "            if col in alaska_yearly_data.columns:\n",
        "                consolidated_row[col] = weighted_average(\n",
        "alaska_yearly_data, [col], 'total_population').iloc[0]\n",
        "\n",
        "        alaska_consolidated_data.append(consolidated_row)\n",
        "\n",
        "# Create a DataFrame from consolidated Alaska data\n",
        "alaska_df = pd.DataFrame(alaska_consolidated_data)\n",
        "\n",
        "# Remove original Alaska FIPS rows from migration_df\n",
        "migration_df = migration_df[~migration_df['FIPS'].isin(alaska_fips_to_consolidate)].copy()\n",
        "\n",
        "# Add the consolidated Alaska data back to migration_df\n",
        "migration_df = pd.concat([migration_df, alaska_df], ignore_index=True)\n",
        "\n",
        "print(f\"Consolidated {len(alaska_fips_to_consolidate)} Alaska FIPS codes into '02000'.\")\n",
        "print(f\"New DataFrame shape after Alaska consolidation: {migration_df.shape}\")\n",
        "print(migration_df.head())"
      ],
      "id": "d17beaae",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Alaska FIPS Consolidation ---\n",
            "Consolidated 35 Alaska FIPS codes into '02000'.\n",
            "New DataFrame shape after Alaska consolidation: (35840, 87)\n",
            "    FIPS  YEAR  BEA_pci    BEA_gdp     RPP  unemploy_rate  total_population  \\\n",
            "0  01000  2019      NaN        NaN     NaN            NaN               NaN   \n",
            "1  01000  2020      NaN        NaN     NaN            NaN               NaN   \n",
            "2  01000  2021      NaN        NaN     NaN            NaN               NaN   \n",
            "3  01001  2011  34430.0  1493906.0  91.098            8.3           53944.0   \n",
            "4  01001  2012  35151.0  1726577.0  93.269            7.1           54590.0   \n",
            "\n",
            "   median_age  housing_total  vacant  ...  Govt  Rec  Nonspec  Low_Ed_cnty  \\\n",
            "0         NaN            NaN     NaN  ...   NaN  NaN      NaN          NaN   \n",
            "1         NaN            NaN     NaN  ...   NaN  NaN      NaN          NaN   \n",
            "2         NaN            NaN     NaN  ...   NaN  NaN      NaN          NaN   \n",
            "3        36.4        19998.0  1861.0  ...   0.0  0.0      1.0          0.0   \n",
            "4        37.0        19934.0  2143.0  ...   0.0  0.0      1.0          0.0   \n",
            "\n",
            "   Low_emp_cnty  Pop_Loss_2010  Retire_dest_cnty  Persistent_Pov_cnty  \\\n",
            "0           NaN            NaN               NaN                  NaN   \n",
            "1           NaN            NaN               NaN                  NaN   \n",
            "2           NaN            NaN               NaN                  NaN   \n",
            "3           0.0            0.0               1.0                  0.0   \n",
            "4           0.0            0.0               1.0                  0.0   \n",
            "\n",
            "   Pers_chld_pov_cnty  Incentive_CAT  \n",
            "0                 NaN            2.0  \n",
            "1                 NaN            2.0  \n",
            "2                 NaN            2.0  \n",
            "3                 0.0            NaN  \n",
            "4                 0.0            NaN  \n",
            "\n",
            "[5 rows x 87 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}